{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YLn5Gh1YiUH",
    "outputId": "8c141a45-926b-49a7-f3f4-04b112451cce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'adopt' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/iShohei220/adopt.git\n",
    "\n",
    "# CLONE REPO GITHUB NÀY ĐỂ SỬ DỤNG ADOPT OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuCcgJdxYiUI"
   },
   "outputs": [],
   "source": [
    "!conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia --yes\n",
    "\n",
    "# DÒNG NÀY TÔI SỬ DỤNG ĐỂ CÀI CÁC THƯ VIỆN CẦN THIẾT TRÊN KAGGLE ĐIỂN HÌNH LÀ PYTORCH 2.5.1\n",
    "# VÌ ADOPT BẮT BUỘC PYTORCH > 2.5\n",
    "\n",
    "# NẾU SỬ DỤNG GOOGLE COLAB THÌ CÓ THỂ BỎ QUA DÒNG NÀY "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "K5cBwgGGYiUI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ST6h2u0KYiUJ",
    "outputId": "23365963-62ea-436f-c896-b8a28e981012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7GzlQUOYiUJ",
    "outputId": "96e3df8a-66d3-484b-cd28-f457d98e1216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "CUDA version from PyTorch: 12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA version from PyTorch:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJ8_CWJVYiUJ"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/adopt')\n",
    "\n",
    "from adopt import ADOPT\n",
    "\n",
    "# DÒNG NÀY THÊM ĐƯỜNG DẪN /content/adopt VÀO DANH SÁCH ĐƯỜNG DẪN MÀ PYTHON SỬ DỤNG ĐỂ TÌM KIẾM CÁC MODULE\n",
    "# Ở TRÊN ĐANG APPEND MỘT DIRECTORY adopt TRÊN GOOGLE COLAB, adopt NẰM TRONG GITHUB REPO MÀ TA CLONE VỀ\n",
    "# NẾU DÙNG GOOGLE COLAB THÌ SẼ LÀ sys.path.append('/kaggle/working/adopt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHtk3Kj0YiUJ"
   },
   "source": [
    "# CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WB1zYJgPYiUK",
    "outputId": "48c2597d-3539-4d6b-946b-f72ae928c8fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :  (40000, 32, 32, 3)\n",
      "Y_train shape :  (40000,)\n",
      "X_val shape :  (10000, 32, 32, 3)\n",
      "Y_val shape :  (10000,)\n",
      "X_test shape :  (10000, 32, 32, 3)\n",
      "Y_test shape :  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the data (scaling the pixel values to the range [0, 1])\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Flatten the labels (CIFAR-10 labels are in shape (n, 1))\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes of the datasets\n",
    "print(\"X_train shape : \", x_train.shape)\n",
    "print(\"Y_train shape : \", y_train.shape)\n",
    "print(\"X_val shape : \", x_val.shape)\n",
    "print(\"Y_val shape : \", y_val.shape)\n",
    "print(\"X_test shape : \", x_test.shape)\n",
    "print(\"Y_test shape : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TI7Gt0_IYiUK",
    "outputId": "7519c209-9662-41a8-f11b-78109952ace4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số loại nhãn trong y_train: 10\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(y_train))\n",
    "print(f\"Số loại nhãn trong y_train: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "7yiaWAEbYiUK"
   },
   "outputs": [],
   "source": [
    "def transform_data(data, label, batch_size=32):\n",
    "    \"\"\"\n",
    "    Chuyển dữ liệu từ NumPy array sang PyTorch tensor và tạo DataLoader cho CIFAR-10.\n",
    "\n",
    "    Args:\n",
    "        data (numpy.ndarray): Dữ liệu đầu vào (hình ảnh).\n",
    "        label (numpy.ndarray): Nhãn tương ứng.\n",
    "        batch_size (int): Kích thước batch khi huấn luyện.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: DataLoader để huấn luyện hoặc kiểm tra.\n",
    "    \"\"\"\n",
    "    # Chuyển `data` từ NumPy array sang PyTorch tensor kiểu float32 và định dạng (N, C, H, W)\n",
    "    data = torch.from_numpy(data).float().permute(0, 3, 1, 2)  # Chuyển (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "    # Chuyển `label` từ NumPy array sang tensor kiểu long\n",
    "    label = torch.from_numpy(label).long().squeeze()  # Xóa trục dư thừa nếu nhãn ở dạng (N, 1)\n",
    "\n",
    "    # Tạo TensorDataset và DataLoader\n",
    "    _data = TensorDataset(data, label)\n",
    "    data_loader = DataLoader(_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "pEySBHesYiUK"
   },
   "outputs": [],
   "source": [
    "train_loader = transform_data(x_train, y_train)\n",
    "test_loader = transform_data(x_test, y_test)\n",
    "val_loader = transform_data(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoBdSQO3YiUK",
    "outputId": "493aec83-9efc-469b-ba18-c02932e19b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loader:\n",
      "  Batch 1:\n",
      "    Data shape: torch.Size([32, 3, 32, 32])\n",
      "    Labels shape: torch.Size([32])\n",
      "\n",
      "Test Loader:\n",
      "  Batch 1:\n",
      "    Data shape: torch.Size([32, 3, 32, 32])\n",
      "    Labels shape: torch.Size([32])\n",
      "\n",
      "Validation Loader:\n",
      "  Batch 1:\n",
      "    Data shape: torch.Size([32, 3, 32, 32])\n",
      "    Labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Hàm để in kích thước của data và label trong DataLoader\n",
    "def print_loader_shapes(data_loader, loader_name):\n",
    "    print(f\"\\n{loader_name}:\")\n",
    "\n",
    "    for batch_idx, (data, labels) in enumerate(data_loader):\n",
    "        print(f\"  Batch {batch_idx + 1}:\")\n",
    "        print(f\"    Data shape: {data.shape}\")   # Kích thước của dữ liệu\n",
    "        print(f\"    Labels shape: {labels.shape}\")  # Kích thước của nhãn\n",
    "        break  # Dừng sau batch đầu tiên (nếu chỉ cần kiểm tra một batch)\n",
    "\n",
    "# In kích thước của từng DataLoader\n",
    "print_loader_shapes(train_loader, \"Train Loader\")\n",
    "print_loader_shapes(test_loader, \"Test Loader\")\n",
    "print_loader_shapes(val_loader, \"Validation Loader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MI5gJB9YiUL"
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "m7pzp3RNYiUL"
   },
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, model, num_classes=10):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def fit(self, num_epochs, optimizer_type, train_loader, val_loader, base_lr = 0.01, weight_decay=0.0001, scheduler=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Hàm huấn luyện mô hình.\n",
    "        Args:\n",
    "            num_epochs (int): Số epoch huấn luyện.\n",
    "            optimizer (torch.optim.Optimizer): Optimizer được sử dụng.\n",
    "            train_loader (DataLoader): Bộ dữ liệu huấn luyện.\n",
    "            val_loader (DataLoader): Bộ dữ liệu kiểm tra (validation).\n",
    "            scheduler (torch.optim.lr_scheduler._LRScheduler): Lịch điều chỉnh learning rate (nếu có).\n",
    "            verbose (bool): In thông tin chi tiết khi huấn luyện.\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "\n",
    "        if(optimizer_type == \"Adam\"):\n",
    "            optimizer = optim.Adam(self.parameters(), weight_decay=weight_decay)\n",
    "        elif(optimizer_type == \"ADOPT\"):\n",
    "            optimizer = ADOPT(self.parameters(),weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "        history = {\n",
    "            'step_loss': [],\n",
    "            'step_accuracy': [],\n",
    "            'step_val_accuracy': [],\n",
    "            'epoch_loss': [],\n",
    "            'epoch_accuracy': [],\n",
    "            'val_accuracy': []\n",
    "        }\n",
    "\n",
    "        iteration = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            running_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "\n",
    "            for i, (inputs, labels) in enumerate(train_loader):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                iteration += 1\n",
    "\n",
    "                lr = base_lr / (iteration ** 0.5)\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_train += (predicted == labels).sum().item()\n",
    "                total_train += labels.size(0)\n",
    "\n",
    "                step_loss = loss.item()\n",
    "                step_accuracy = correct_train / total_train\n",
    "                history['step_loss'].append(step_loss)\n",
    "                history['step_accuracy'].append(step_accuracy)\n",
    "\n",
    "\n",
    "                if verbose and ((i+1) % 100 == 0):\n",
    "                    print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], \"\n",
    "                          f\"Loss: {step_loss:.6f}, Train Accuracy: {step_accuracy:.6f}\")\n",
    "\n",
    "            # Tổng hợp kết quả epoch\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            epoch_accuracy = correct_train / total_train\n",
    "            history['epoch_loss'].append(epoch_loss)\n",
    "            history['epoch_accuracy'].append(epoch_accuracy)\n",
    "\n",
    "            # Đánh giá trên toàn bộ validation set\n",
    "            val_accuracy = self._evaluate(val_loader, device)\n",
    "            history['val_accuracy'].append(val_accuracy)\n",
    "\n",
    "\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.6f}, \"\n",
    "                      f\"Train Accuracy: {epoch_accuracy:.6f}, Validation Accuracy: {val_accuracy:.6f}\")\n",
    "        return history\n",
    "\n",
    "\n",
    "    def predict(self, test_loader):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "\n",
    "        self.eval()\n",
    "        predictions = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = self(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\"\n",
    "        Tính độ chính xác (accuracy) trên tập test.\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "\n",
    "        accuracy = self._evaluate(test_loader, device)\n",
    "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "        return accuracy\n",
    "\n",
    "    def _evaluate(self, data_loader, device):\n",
    "        \"\"\"\n",
    "        Hàm hỗ trợ tính độ chính xác cho cả validation và test.\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in data_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = self(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        return correct / total\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pna9Z_8YqCV"
   },
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55uvq0liYiUL",
    "outputId": "123e4301-a586-4a96-8611-0afd02afa30d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/1250], Loss: 1.456789, Train Accuracy: 0.305000\n",
      "Epoch [1/100], Step [200/1250], Loss: 1.202838, Train Accuracy: 0.372656\n",
      "Epoch [1/100], Step [300/1250], Loss: 1.085090, Train Accuracy: 0.423021\n",
      "Epoch [1/100], Step [400/1250], Loss: 1.271137, Train Accuracy: 0.456328\n",
      "Epoch [1/100], Step [500/1250], Loss: 1.330687, Train Accuracy: 0.481875\n",
      "Epoch [1/100], Step [600/1250], Loss: 1.127979, Train Accuracy: 0.501719\n",
      "Epoch [1/100], Step [700/1250], Loss: 1.078756, Train Accuracy: 0.515804\n",
      "Epoch [1/100], Step [800/1250], Loss: 0.761440, Train Accuracy: 0.531484\n",
      "Epoch [1/100], Step [900/1250], Loss: 0.836502, Train Accuracy: 0.544444\n",
      "Epoch [1/100], Step [1000/1250], Loss: 0.768878, Train Accuracy: 0.556375\n",
      "Epoch [1/100], Step [1100/1250], Loss: 1.061478, Train Accuracy: 0.567102\n",
      "Epoch [1/100], Step [1200/1250], Loss: 0.866157, Train Accuracy: 0.577656\n",
      "Epoch 1/100, Loss: 1.211368, Train Accuracy: 0.582225, Validation Accuracy: 0.721800\n",
      "Epoch [2/100], Step [100/1250], Loss: 0.817618, Train Accuracy: 0.747188\n",
      "Epoch [2/100], Step [200/1250], Loss: 0.745502, Train Accuracy: 0.740781\n",
      "Epoch [2/100], Step [300/1250], Loss: 0.912876, Train Accuracy: 0.739583\n",
      "Epoch [2/100], Step [400/1250], Loss: 0.755229, Train Accuracy: 0.738594\n",
      "Epoch [2/100], Step [500/1250], Loss: 0.509115, Train Accuracy: 0.741563\n",
      "Epoch [2/100], Step [600/1250], Loss: 0.519741, Train Accuracy: 0.744219\n",
      "Epoch [2/100], Step [700/1250], Loss: 0.490675, Train Accuracy: 0.745982\n",
      "Epoch [2/100], Step [800/1250], Loss: 1.106272, Train Accuracy: 0.747383\n",
      "Epoch [2/100], Step [900/1250], Loss: 0.885533, Train Accuracy: 0.748889\n",
      "Epoch [2/100], Step [1000/1250], Loss: 0.739127, Train Accuracy: 0.750469\n",
      "Epoch [2/100], Step [1100/1250], Loss: 1.018083, Train Accuracy: 0.752330\n",
      "Epoch [2/100], Step [1200/1250], Loss: 0.730903, Train Accuracy: 0.754349\n",
      "Epoch 2/100, Loss: 0.731750, Train Accuracy: 0.755075, Validation Accuracy: 0.775500\n",
      "Epoch [3/100], Step [100/1250], Loss: 0.565916, Train Accuracy: 0.820000\n",
      "Epoch [3/100], Step [200/1250], Loss: 0.752546, Train Accuracy: 0.820156\n",
      "Epoch [3/100], Step [300/1250], Loss: 0.592030, Train Accuracy: 0.816667\n",
      "Epoch [3/100], Step [400/1250], Loss: 0.693124, Train Accuracy: 0.817891\n",
      "Epoch [3/100], Step [500/1250], Loss: 0.633576, Train Accuracy: 0.817937\n",
      "Epoch [3/100], Step [600/1250], Loss: 0.729184, Train Accuracy: 0.818125\n",
      "Epoch [3/100], Step [700/1250], Loss: 0.510168, Train Accuracy: 0.815223\n",
      "Epoch [3/100], Step [800/1250], Loss: 0.445939, Train Accuracy: 0.814023\n",
      "Epoch [3/100], Step [900/1250], Loss: 0.526032, Train Accuracy: 0.814549\n",
      "Epoch [3/100], Step [1000/1250], Loss: 0.270767, Train Accuracy: 0.815219\n",
      "Epoch [3/100], Step [1100/1250], Loss: 0.506211, Train Accuracy: 0.815881\n",
      "Epoch [3/100], Step [1200/1250], Loss: 0.325886, Train Accuracy: 0.816849\n",
      "Epoch 3/100, Loss: 0.537264, Train Accuracy: 0.817350, Validation Accuracy: 0.802900\n",
      "Epoch [4/100], Step [100/1250], Loss: 0.180030, Train Accuracy: 0.865625\n",
      "Epoch [4/100], Step [200/1250], Loss: 0.649584, Train Accuracy: 0.866406\n",
      "Epoch [4/100], Step [300/1250], Loss: 0.239447, Train Accuracy: 0.865000\n",
      "Epoch [4/100], Step [400/1250], Loss: 0.585604, Train Accuracy: 0.864219\n",
      "Epoch [4/100], Step [500/1250], Loss: 0.224951, Train Accuracy: 0.864125\n",
      "Epoch [4/100], Step [600/1250], Loss: 0.417999, Train Accuracy: 0.860938\n",
      "Epoch [4/100], Step [700/1250], Loss: 0.424345, Train Accuracy: 0.859777\n",
      "Epoch [4/100], Step [800/1250], Loss: 0.384501, Train Accuracy: 0.860469\n",
      "Epoch [4/100], Step [900/1250], Loss: 0.523942, Train Accuracy: 0.861250\n",
      "Epoch [4/100], Step [1000/1250], Loss: 0.564150, Train Accuracy: 0.861125\n",
      "Epoch [4/100], Step [1100/1250], Loss: 0.277114, Train Accuracy: 0.861023\n",
      "Epoch [4/100], Step [1200/1250], Loss: 0.693524, Train Accuracy: 0.860729\n",
      "Epoch 4/100, Loss: 0.409042, Train Accuracy: 0.861025, Validation Accuracy: 0.808400\n",
      "Epoch [5/100], Step [100/1250], Loss: 0.331347, Train Accuracy: 0.904062\n",
      "Epoch [5/100], Step [200/1250], Loss: 0.328164, Train Accuracy: 0.908594\n",
      "Epoch [5/100], Step [300/1250], Loss: 0.403137, Train Accuracy: 0.906875\n",
      "Epoch [5/100], Step [400/1250], Loss: 0.246510, Train Accuracy: 0.906094\n",
      "Epoch [5/100], Step [500/1250], Loss: 0.216847, Train Accuracy: 0.904813\n",
      "Epoch [5/100], Step [600/1250], Loss: 0.100297, Train Accuracy: 0.902604\n",
      "Epoch [5/100], Step [700/1250], Loss: 0.298520, Train Accuracy: 0.901429\n",
      "Epoch [5/100], Step [800/1250], Loss: 0.190751, Train Accuracy: 0.900039\n",
      "Epoch [5/100], Step [900/1250], Loss: 0.257554, Train Accuracy: 0.899687\n",
      "Epoch [5/100], Step [1000/1250], Loss: 0.279395, Train Accuracy: 0.899188\n",
      "Epoch [5/100], Step [1100/1250], Loss: 0.392379, Train Accuracy: 0.899659\n",
      "Epoch [5/100], Step [1200/1250], Loss: 0.191089, Train Accuracy: 0.899297\n",
      "Epoch 5/100, Loss: 0.300764, Train Accuracy: 0.898800, Validation Accuracy: 0.811800\n",
      "Epoch [6/100], Step [100/1250], Loss: 0.081719, Train Accuracy: 0.940625\n",
      "Epoch [6/100], Step [200/1250], Loss: 0.156721, Train Accuracy: 0.936875\n",
      "Epoch [6/100], Step [300/1250], Loss: 0.128902, Train Accuracy: 0.935208\n",
      "Epoch [6/100], Step [400/1250], Loss: 0.131888, Train Accuracy: 0.933359\n",
      "Epoch [6/100], Step [500/1250], Loss: 0.239517, Train Accuracy: 0.931875\n",
      "Epoch [6/100], Step [600/1250], Loss: 0.236339, Train Accuracy: 0.931198\n",
      "Epoch [6/100], Step [700/1250], Loss: 0.083594, Train Accuracy: 0.930402\n",
      "Epoch [6/100], Step [800/1250], Loss: 0.323273, Train Accuracy: 0.929375\n",
      "Epoch [6/100], Step [900/1250], Loss: 0.156067, Train Accuracy: 0.927743\n",
      "Epoch [6/100], Step [1000/1250], Loss: 0.307367, Train Accuracy: 0.926406\n",
      "Epoch [6/100], Step [1100/1250], Loss: 0.148779, Train Accuracy: 0.927045\n",
      "Epoch [6/100], Step [1200/1250], Loss: 0.573340, Train Accuracy: 0.926276\n",
      "Epoch 6/100, Loss: 0.218835, Train Accuracy: 0.926050, Validation Accuracy: 0.806700\n",
      "Epoch [7/100], Step [100/1250], Loss: 0.229147, Train Accuracy: 0.950937\n",
      "Epoch [7/100], Step [200/1250], Loss: 0.182753, Train Accuracy: 0.948906\n",
      "Epoch [7/100], Step [300/1250], Loss: 0.042243, Train Accuracy: 0.950208\n",
      "Epoch [7/100], Step [400/1250], Loss: 0.061120, Train Accuracy: 0.951328\n",
      "Epoch [7/100], Step [500/1250], Loss: 0.041118, Train Accuracy: 0.950063\n",
      "Epoch [7/100], Step [600/1250], Loss: 0.062594, Train Accuracy: 0.950469\n",
      "Epoch [7/100], Step [700/1250], Loss: 0.120136, Train Accuracy: 0.949330\n",
      "Epoch [7/100], Step [800/1250], Loss: 0.130351, Train Accuracy: 0.949141\n",
      "Epoch [7/100], Step [900/1250], Loss: 0.066245, Train Accuracy: 0.948576\n",
      "Epoch [7/100], Step [1000/1250], Loss: 0.055684, Train Accuracy: 0.948594\n",
      "Epoch [7/100], Step [1100/1250], Loss: 0.333407, Train Accuracy: 0.948210\n",
      "Epoch [7/100], Step [1200/1250], Loss: 0.036147, Train Accuracy: 0.947839\n",
      "Epoch 7/100, Loss: 0.156156, Train Accuracy: 0.947350, Validation Accuracy: 0.812700\n",
      "Epoch [8/100], Step [100/1250], Loss: 0.349097, Train Accuracy: 0.969063\n",
      "Epoch [8/100], Step [200/1250], Loss: 0.008338, Train Accuracy: 0.971250\n",
      "Epoch [8/100], Step [300/1250], Loss: 0.127889, Train Accuracy: 0.972500\n",
      "Epoch [8/100], Step [400/1250], Loss: 0.416011, Train Accuracy: 0.971484\n",
      "Epoch [8/100], Step [500/1250], Loss: 0.063085, Train Accuracy: 0.970437\n",
      "Epoch [8/100], Step [600/1250], Loss: 0.090613, Train Accuracy: 0.967760\n",
      "Epoch [8/100], Step [700/1250], Loss: 0.118094, Train Accuracy: 0.967098\n",
      "Epoch [8/100], Step [800/1250], Loss: 0.045598, Train Accuracy: 0.965938\n",
      "Epoch [8/100], Step [900/1250], Loss: 0.121343, Train Accuracy: 0.965104\n",
      "Epoch [8/100], Step [1000/1250], Loss: 0.212430, Train Accuracy: 0.964688\n",
      "Epoch [8/100], Step [1100/1250], Loss: 0.024068, Train Accuracy: 0.964318\n",
      "Epoch [8/100], Step [1200/1250], Loss: 0.238630, Train Accuracy: 0.963932\n",
      "Epoch 8/100, Loss: 0.108857, Train Accuracy: 0.963675, Validation Accuracy: 0.806200\n",
      "Epoch [9/100], Step [100/1250], Loss: 0.052819, Train Accuracy: 0.978125\n",
      "Epoch [9/100], Step [200/1250], Loss: 0.009175, Train Accuracy: 0.979531\n",
      "Epoch [9/100], Step [300/1250], Loss: 0.022745, Train Accuracy: 0.980417\n",
      "Epoch [9/100], Step [400/1250], Loss: 0.009820, Train Accuracy: 0.978203\n",
      "Epoch [9/100], Step [500/1250], Loss: 0.099863, Train Accuracy: 0.978000\n",
      "Epoch [9/100], Step [600/1250], Loss: 0.016284, Train Accuracy: 0.977708\n",
      "Epoch [9/100], Step [700/1250], Loss: 0.050996, Train Accuracy: 0.977277\n",
      "Epoch [9/100], Step [800/1250], Loss: 0.158599, Train Accuracy: 0.976914\n",
      "Epoch [9/100], Step [900/1250], Loss: 0.051446, Train Accuracy: 0.975521\n",
      "Epoch [9/100], Step [1000/1250], Loss: 0.128482, Train Accuracy: 0.974750\n",
      "Epoch [9/100], Step [1100/1250], Loss: 0.219490, Train Accuracy: 0.973580\n",
      "Epoch [9/100], Step [1200/1250], Loss: 0.042642, Train Accuracy: 0.972552\n",
      "Epoch 9/100, Loss: 0.081024, Train Accuracy: 0.972575, Validation Accuracy: 0.813900\n",
      "Epoch [10/100], Step [100/1250], Loss: 0.047412, Train Accuracy: 0.980625\n",
      "Epoch [10/100], Step [200/1250], Loss: 0.032048, Train Accuracy: 0.981094\n",
      "Epoch [10/100], Step [300/1250], Loss: 0.008932, Train Accuracy: 0.981146\n",
      "Epoch [10/100], Step [400/1250], Loss: 0.110688, Train Accuracy: 0.981172\n",
      "Epoch [10/100], Step [500/1250], Loss: 0.185187, Train Accuracy: 0.980563\n",
      "Epoch [10/100], Step [600/1250], Loss: 0.049775, Train Accuracy: 0.981094\n",
      "Epoch [10/100], Step [700/1250], Loss: 0.046750, Train Accuracy: 0.980625\n",
      "Epoch [10/100], Step [800/1250], Loss: 0.071362, Train Accuracy: 0.980352\n",
      "Epoch [10/100], Step [900/1250], Loss: 0.003463, Train Accuracy: 0.980590\n",
      "Epoch [10/100], Step [1000/1250], Loss: 0.033157, Train Accuracy: 0.980594\n",
      "Epoch [10/100], Step [1100/1250], Loss: 0.003974, Train Accuracy: 0.980795\n",
      "Epoch [10/100], Step [1200/1250], Loss: 0.294058, Train Accuracy: 0.980339\n",
      "Epoch 10/100, Loss: 0.058191, Train Accuracy: 0.980400, Validation Accuracy: 0.811600\n",
      "Epoch [11/100], Step [100/1250], Loss: 0.018907, Train Accuracy: 0.989688\n",
      "Epoch [11/100], Step [200/1250], Loss: 0.072409, Train Accuracy: 0.984844\n",
      "Epoch [11/100], Step [300/1250], Loss: 0.006879, Train Accuracy: 0.984375\n",
      "Epoch [11/100], Step [400/1250], Loss: 0.062972, Train Accuracy: 0.983750\n",
      "Epoch [11/100], Step [500/1250], Loss: 0.027779, Train Accuracy: 0.984187\n",
      "Epoch [11/100], Step [600/1250], Loss: 0.014453, Train Accuracy: 0.984427\n",
      "Epoch [11/100], Step [700/1250], Loss: 0.051909, Train Accuracy: 0.984152\n",
      "Epoch [11/100], Step [800/1250], Loss: 0.011074, Train Accuracy: 0.983984\n",
      "Epoch [11/100], Step [900/1250], Loss: 0.041218, Train Accuracy: 0.983715\n",
      "Epoch [11/100], Step [1000/1250], Loss: 0.020279, Train Accuracy: 0.983719\n",
      "Epoch [11/100], Step [1100/1250], Loss: 0.044493, Train Accuracy: 0.983977\n",
      "Epoch [11/100], Step [1200/1250], Loss: 0.019759, Train Accuracy: 0.983750\n",
      "Epoch 11/100, Loss: 0.047743, Train Accuracy: 0.983500, Validation Accuracy: 0.812500\n",
      "Epoch [12/100], Step [100/1250], Loss: 0.003156, Train Accuracy: 0.989375\n",
      "Epoch [12/100], Step [200/1250], Loss: 0.044291, Train Accuracy: 0.987500\n",
      "Epoch [12/100], Step [300/1250], Loss: 0.006601, Train Accuracy: 0.987708\n",
      "Epoch [12/100], Step [400/1250], Loss: 0.023515, Train Accuracy: 0.987969\n",
      "Epoch [12/100], Step [500/1250], Loss: 0.018620, Train Accuracy: 0.987437\n",
      "Epoch [12/100], Step [600/1250], Loss: 0.072220, Train Accuracy: 0.987135\n",
      "Epoch [12/100], Step [700/1250], Loss: 0.016275, Train Accuracy: 0.987366\n",
      "Epoch [12/100], Step [800/1250], Loss: 0.020847, Train Accuracy: 0.987305\n",
      "Epoch [12/100], Step [900/1250], Loss: 0.003644, Train Accuracy: 0.987326\n",
      "Epoch [12/100], Step [1000/1250], Loss: 0.004071, Train Accuracy: 0.987437\n",
      "Epoch [12/100], Step [1100/1250], Loss: 0.020707, Train Accuracy: 0.987727\n",
      "Epoch [12/100], Step [1200/1250], Loss: 0.029820, Train Accuracy: 0.987422\n",
      "Epoch 12/100, Loss: 0.038206, Train Accuracy: 0.987350, Validation Accuracy: 0.809200\n",
      "Epoch [13/100], Step [100/1250], Loss: 0.008392, Train Accuracy: 0.989688\n",
      "Epoch [13/100], Step [200/1250], Loss: 0.003190, Train Accuracy: 0.990469\n",
      "Epoch [13/100], Step [300/1250], Loss: 0.022347, Train Accuracy: 0.990729\n",
      "Epoch [13/100], Step [400/1250], Loss: 0.035360, Train Accuracy: 0.990156\n",
      "Epoch [13/100], Step [500/1250], Loss: 0.001648, Train Accuracy: 0.990000\n",
      "Epoch [13/100], Step [600/1250], Loss: 0.051460, Train Accuracy: 0.989635\n",
      "Epoch [13/100], Step [700/1250], Loss: 0.055575, Train Accuracy: 0.989018\n",
      "Epoch [13/100], Step [800/1250], Loss: 0.003362, Train Accuracy: 0.989102\n",
      "Epoch [13/100], Step [900/1250], Loss: 0.014968, Train Accuracy: 0.989375\n",
      "Epoch [13/100], Step [1000/1250], Loss: 0.002778, Train Accuracy: 0.989625\n",
      "Epoch [13/100], Step [1100/1250], Loss: 0.001969, Train Accuracy: 0.989574\n",
      "Epoch [13/100], Step [1200/1250], Loss: 0.117327, Train Accuracy: 0.989401\n",
      "Epoch 13/100, Loss: 0.032362, Train Accuracy: 0.989600, Validation Accuracy: 0.816000\n",
      "Epoch [14/100], Step [100/1250], Loss: 0.036695, Train Accuracy: 0.992500\n",
      "Epoch [14/100], Step [200/1250], Loss: 0.025419, Train Accuracy: 0.992188\n",
      "Epoch [14/100], Step [300/1250], Loss: 0.000341, Train Accuracy: 0.992500\n",
      "Epoch [14/100], Step [400/1250], Loss: 0.041935, Train Accuracy: 0.992734\n",
      "Epoch [14/100], Step [500/1250], Loss: 0.000934, Train Accuracy: 0.992687\n",
      "Epoch [14/100], Step [600/1250], Loss: 0.079441, Train Accuracy: 0.992188\n",
      "Epoch [14/100], Step [700/1250], Loss: 0.003195, Train Accuracy: 0.992366\n",
      "Epoch [14/100], Step [800/1250], Loss: 0.016408, Train Accuracy: 0.992461\n",
      "Epoch [14/100], Step [900/1250], Loss: 0.000883, Train Accuracy: 0.992465\n",
      "Epoch [14/100], Step [1000/1250], Loss: 0.003198, Train Accuracy: 0.992531\n",
      "Epoch [14/100], Step [1100/1250], Loss: 0.117838, Train Accuracy: 0.992330\n",
      "Epoch [14/100], Step [1200/1250], Loss: 0.005464, Train Accuracy: 0.992240\n",
      "Epoch 14/100, Loss: 0.023489, Train Accuracy: 0.992075, Validation Accuracy: 0.819700\n",
      "Epoch [15/100], Step [100/1250], Loss: 0.002409, Train Accuracy: 0.993437\n",
      "Epoch [15/100], Step [200/1250], Loss: 0.001353, Train Accuracy: 0.994062\n",
      "Epoch [15/100], Step [300/1250], Loss: 0.216383, Train Accuracy: 0.993021\n",
      "Epoch [15/100], Step [400/1250], Loss: 0.021808, Train Accuracy: 0.993047\n",
      "Epoch [15/100], Step [500/1250], Loss: 0.002060, Train Accuracy: 0.993250\n",
      "Epoch [15/100], Step [600/1250], Loss: 0.004699, Train Accuracy: 0.993698\n",
      "Epoch [15/100], Step [700/1250], Loss: 0.046727, Train Accuracy: 0.993571\n",
      "Epoch [15/100], Step [800/1250], Loss: 0.004702, Train Accuracy: 0.993477\n",
      "Epoch [15/100], Step [900/1250], Loss: 0.019325, Train Accuracy: 0.993611\n",
      "Epoch [15/100], Step [1000/1250], Loss: 0.004838, Train Accuracy: 0.993313\n",
      "Epoch [15/100], Step [1100/1250], Loss: 0.037712, Train Accuracy: 0.992983\n",
      "Epoch [15/100], Step [1200/1250], Loss: 0.028036, Train Accuracy: 0.992839\n",
      "Epoch 15/100, Loss: 0.022160, Train Accuracy: 0.992875, Validation Accuracy: 0.814500\n",
      "Epoch [16/100], Step [100/1250], Loss: 0.001185, Train Accuracy: 0.994062\n",
      "Epoch [16/100], Step [200/1250], Loss: 0.045407, Train Accuracy: 0.993750\n",
      "Epoch [16/100], Step [300/1250], Loss: 0.022742, Train Accuracy: 0.993333\n",
      "Epoch [16/100], Step [400/1250], Loss: 0.001748, Train Accuracy: 0.993750\n",
      "Epoch [16/100], Step [500/1250], Loss: 0.000802, Train Accuracy: 0.993938\n",
      "Epoch [16/100], Step [600/1250], Loss: 0.002236, Train Accuracy: 0.993646\n",
      "Epoch [16/100], Step [700/1250], Loss: 0.011026, Train Accuracy: 0.993839\n",
      "Epoch [16/100], Step [800/1250], Loss: 0.119519, Train Accuracy: 0.993633\n",
      "Epoch [16/100], Step [900/1250], Loss: 0.003150, Train Accuracy: 0.993264\n",
      "Epoch [16/100], Step [1000/1250], Loss: 0.030749, Train Accuracy: 0.993000\n",
      "Epoch [16/100], Step [1100/1250], Loss: 0.045384, Train Accuracy: 0.993153\n",
      "Epoch [16/100], Step [1200/1250], Loss: 0.032898, Train Accuracy: 0.992839\n",
      "Epoch 16/100, Loss: 0.023068, Train Accuracy: 0.992475, Validation Accuracy: 0.815800\n",
      "Epoch [17/100], Step [100/1250], Loss: 0.001067, Train Accuracy: 0.993125\n",
      "Epoch [17/100], Step [200/1250], Loss: 0.003488, Train Accuracy: 0.994844\n",
      "Epoch [17/100], Step [300/1250], Loss: 0.003394, Train Accuracy: 0.994896\n",
      "Epoch [17/100], Step [400/1250], Loss: 0.020300, Train Accuracy: 0.994687\n",
      "Epoch [17/100], Step [500/1250], Loss: 0.002748, Train Accuracy: 0.994812\n",
      "Epoch [17/100], Step [600/1250], Loss: 0.001974, Train Accuracy: 0.994844\n",
      "Epoch [17/100], Step [700/1250], Loss: 0.017923, Train Accuracy: 0.994687\n",
      "Epoch [17/100], Step [800/1250], Loss: 0.005965, Train Accuracy: 0.994570\n",
      "Epoch [17/100], Step [900/1250], Loss: 0.000983, Train Accuracy: 0.994271\n",
      "Epoch [17/100], Step [1000/1250], Loss: 0.001419, Train Accuracy: 0.994188\n",
      "Epoch [17/100], Step [1100/1250], Loss: 0.046108, Train Accuracy: 0.994034\n",
      "Epoch [17/100], Step [1200/1250], Loss: 0.033127, Train Accuracy: 0.993932\n",
      "Epoch 17/100, Loss: 0.018468, Train Accuracy: 0.993900, Validation Accuracy: 0.812100\n",
      "Epoch [18/100], Step [100/1250], Loss: 0.005544, Train Accuracy: 0.997188\n",
      "Epoch [18/100], Step [200/1250], Loss: 0.006991, Train Accuracy: 0.996250\n",
      "Epoch [18/100], Step [300/1250], Loss: 0.009761, Train Accuracy: 0.995625\n",
      "Epoch [18/100], Step [400/1250], Loss: 0.003327, Train Accuracy: 0.995859\n",
      "Epoch [18/100], Step [500/1250], Loss: 0.002355, Train Accuracy: 0.996188\n",
      "Epoch [18/100], Step [600/1250], Loss: 0.003435, Train Accuracy: 0.995990\n",
      "Epoch [18/100], Step [700/1250], Loss: 0.016394, Train Accuracy: 0.995759\n",
      "Epoch [18/100], Step [800/1250], Loss: 0.064773, Train Accuracy: 0.995742\n",
      "Epoch [18/100], Step [900/1250], Loss: 0.000278, Train Accuracy: 0.995868\n",
      "Epoch [18/100], Step [1000/1250], Loss: 0.036248, Train Accuracy: 0.995938\n",
      "Epoch [18/100], Step [1100/1250], Loss: 0.022347, Train Accuracy: 0.995767\n",
      "Epoch [18/100], Step [1200/1250], Loss: 0.002754, Train Accuracy: 0.995729\n",
      "Epoch 18/100, Loss: 0.013621, Train Accuracy: 0.995775, Validation Accuracy: 0.814900\n",
      "Epoch [19/100], Step [100/1250], Loss: 0.000535, Train Accuracy: 0.998750\n",
      "Epoch [19/100], Step [200/1250], Loss: 0.065315, Train Accuracy: 0.998437\n",
      "Epoch [19/100], Step [300/1250], Loss: 0.003894, Train Accuracy: 0.998437\n",
      "Epoch [19/100], Step [400/1250], Loss: 0.007222, Train Accuracy: 0.998047\n",
      "Epoch [19/100], Step [500/1250], Loss: 0.000832, Train Accuracy: 0.997437\n",
      "Epoch [19/100], Step [600/1250], Loss: 0.001464, Train Accuracy: 0.997031\n",
      "Epoch [19/100], Step [700/1250], Loss: 0.000700, Train Accuracy: 0.996741\n",
      "Epoch [19/100], Step [800/1250], Loss: 0.000482, Train Accuracy: 0.996523\n",
      "Epoch [19/100], Step [900/1250], Loss: 0.002195, Train Accuracy: 0.996424\n",
      "Epoch [19/100], Step [1000/1250], Loss: 0.006623, Train Accuracy: 0.996094\n",
      "Epoch [19/100], Step [1100/1250], Loss: 0.008737, Train Accuracy: 0.996193\n",
      "Epoch [19/100], Step [1200/1250], Loss: 0.009019, Train Accuracy: 0.996198\n",
      "Epoch 19/100, Loss: 0.012640, Train Accuracy: 0.996300, Validation Accuracy: 0.820500\n",
      "Epoch [20/100], Step [100/1250], Loss: 0.000075, Train Accuracy: 0.997812\n",
      "Epoch [20/100], Step [200/1250], Loss: 0.001618, Train Accuracy: 0.997500\n",
      "Epoch [20/100], Step [300/1250], Loss: 0.001091, Train Accuracy: 0.997604\n",
      "Epoch [20/100], Step [400/1250], Loss: 0.004167, Train Accuracy: 0.997422\n",
      "Epoch [20/100], Step [500/1250], Loss: 0.002716, Train Accuracy: 0.997000\n",
      "Epoch [20/100], Step [600/1250], Loss: 0.000096, Train Accuracy: 0.997031\n",
      "Epoch [20/100], Step [700/1250], Loss: 0.000640, Train Accuracy: 0.996830\n",
      "Epoch [20/100], Step [800/1250], Loss: 0.007459, Train Accuracy: 0.996914\n",
      "Epoch [20/100], Step [900/1250], Loss: 0.000909, Train Accuracy: 0.996910\n",
      "Epoch [20/100], Step [1000/1250], Loss: 0.017944, Train Accuracy: 0.996750\n",
      "Epoch [20/100], Step [1100/1250], Loss: 0.059244, Train Accuracy: 0.996676\n",
      "Epoch [20/100], Step [1200/1250], Loss: 0.002659, Train Accuracy: 0.996693\n",
      "Epoch 20/100, Loss: 0.011242, Train Accuracy: 0.996575, Validation Accuracy: 0.818100\n",
      "Epoch [21/100], Step [100/1250], Loss: 0.000140, Train Accuracy: 0.999687\n",
      "Epoch [21/100], Step [200/1250], Loss: 0.000615, Train Accuracy: 0.998906\n",
      "Epoch [21/100], Step [300/1250], Loss: 0.003543, Train Accuracy: 0.998229\n",
      "Epoch [21/100], Step [400/1250], Loss: 0.000195, Train Accuracy: 0.998047\n",
      "Epoch [21/100], Step [500/1250], Loss: 0.002283, Train Accuracy: 0.997687\n",
      "Epoch [21/100], Step [600/1250], Loss: 0.010073, Train Accuracy: 0.997500\n",
      "Epoch [21/100], Step [700/1250], Loss: 0.073246, Train Accuracy: 0.997321\n",
      "Epoch [21/100], Step [800/1250], Loss: 0.001274, Train Accuracy: 0.997227\n",
      "Epoch [21/100], Step [900/1250], Loss: 0.000789, Train Accuracy: 0.997396\n",
      "Epoch [21/100], Step [1000/1250], Loss: 0.037245, Train Accuracy: 0.997094\n",
      "Epoch [21/100], Step [1100/1250], Loss: 0.002056, Train Accuracy: 0.997216\n",
      "Epoch [21/100], Step [1200/1250], Loss: 0.000642, Train Accuracy: 0.997031\n",
      "Epoch 21/100, Loss: 0.009118, Train Accuracy: 0.997100, Validation Accuracy: 0.817200\n",
      "Epoch [22/100], Step [100/1250], Loss: 0.001817, Train Accuracy: 0.997500\n",
      "Epoch [22/100], Step [200/1250], Loss: 0.000146, Train Accuracy: 0.997969\n",
      "Epoch [22/100], Step [300/1250], Loss: 0.000394, Train Accuracy: 0.997708\n",
      "Epoch [22/100], Step [400/1250], Loss: 0.000114, Train Accuracy: 0.998047\n",
      "Epoch [22/100], Step [500/1250], Loss: 0.000603, Train Accuracy: 0.997687\n",
      "Epoch [22/100], Step [600/1250], Loss: 0.000756, Train Accuracy: 0.997396\n",
      "Epoch [22/100], Step [700/1250], Loss: 0.000497, Train Accuracy: 0.997366\n",
      "Epoch [22/100], Step [800/1250], Loss: 0.000310, Train Accuracy: 0.997227\n",
      "Epoch [22/100], Step [900/1250], Loss: 0.003969, Train Accuracy: 0.997326\n",
      "Epoch [22/100], Step [1000/1250], Loss: 0.067959, Train Accuracy: 0.997125\n",
      "Epoch [22/100], Step [1100/1250], Loss: 0.001483, Train Accuracy: 0.997244\n",
      "Epoch [22/100], Step [1200/1250], Loss: 0.003633, Train Accuracy: 0.997109\n",
      "Epoch 22/100, Loss: 0.009938, Train Accuracy: 0.997025, Validation Accuracy: 0.812200\n",
      "Epoch [23/100], Step [100/1250], Loss: 0.000417, Train Accuracy: 0.997812\n",
      "Epoch [23/100], Step [200/1250], Loss: 0.001579, Train Accuracy: 0.997188\n",
      "Epoch [23/100], Step [300/1250], Loss: 0.000589, Train Accuracy: 0.997500\n",
      "Epoch [23/100], Step [400/1250], Loss: 0.003530, Train Accuracy: 0.997188\n",
      "Epoch [23/100], Step [500/1250], Loss: 0.000681, Train Accuracy: 0.996875\n",
      "Epoch [23/100], Step [600/1250], Loss: 0.000662, Train Accuracy: 0.996823\n",
      "Epoch [23/100], Step [700/1250], Loss: 0.009268, Train Accuracy: 0.996786\n",
      "Epoch [23/100], Step [800/1250], Loss: 0.000473, Train Accuracy: 0.996836\n",
      "Epoch [23/100], Step [900/1250], Loss: 0.016790, Train Accuracy: 0.996701\n",
      "Epoch [23/100], Step [1000/1250], Loss: 0.000257, Train Accuracy: 0.996531\n",
      "Epoch [23/100], Step [1100/1250], Loss: 0.011798, Train Accuracy: 0.996534\n",
      "Epoch [23/100], Step [1200/1250], Loss: 0.000669, Train Accuracy: 0.996458\n",
      "Epoch 23/100, Loss: 0.010552, Train Accuracy: 0.996475, Validation Accuracy: 0.818600\n",
      "Epoch [24/100], Step [100/1250], Loss: 0.005580, Train Accuracy: 0.998437\n",
      "Epoch [24/100], Step [200/1250], Loss: 0.000738, Train Accuracy: 0.998437\n",
      "Epoch [24/100], Step [300/1250], Loss: 0.011879, Train Accuracy: 0.998125\n",
      "Epoch [24/100], Step [400/1250], Loss: 0.003298, Train Accuracy: 0.997422\n",
      "Epoch [24/100], Step [500/1250], Loss: 0.000620, Train Accuracy: 0.997062\n",
      "Epoch [24/100], Step [600/1250], Loss: 0.001157, Train Accuracy: 0.996875\n",
      "Epoch [24/100], Step [700/1250], Loss: 0.033263, Train Accuracy: 0.996652\n",
      "Epoch [24/100], Step [800/1250], Loss: 0.002375, Train Accuracy: 0.996797\n",
      "Epoch [24/100], Step [900/1250], Loss: 0.005306, Train Accuracy: 0.996979\n",
      "Epoch [24/100], Step [1000/1250], Loss: 0.000596, Train Accuracy: 0.997062\n",
      "Epoch [24/100], Step [1100/1250], Loss: 0.000185, Train Accuracy: 0.996960\n",
      "Epoch [24/100], Step [1200/1250], Loss: 0.002655, Train Accuracy: 0.996901\n",
      "Epoch 24/100, Loss: 0.009774, Train Accuracy: 0.996800, Validation Accuracy: 0.812900\n",
      "Epoch [25/100], Step [100/1250], Loss: 0.011512, Train Accuracy: 0.993750\n",
      "Epoch [25/100], Step [200/1250], Loss: 0.000319, Train Accuracy: 0.995000\n",
      "Epoch [25/100], Step [300/1250], Loss: 0.001069, Train Accuracy: 0.995417\n",
      "Epoch [25/100], Step [400/1250], Loss: 0.002304, Train Accuracy: 0.995391\n",
      "Epoch [25/100], Step [500/1250], Loss: 0.000137, Train Accuracy: 0.995812\n",
      "Epoch [25/100], Step [600/1250], Loss: 0.022276, Train Accuracy: 0.995677\n",
      "Epoch [25/100], Step [700/1250], Loss: 0.000767, Train Accuracy: 0.995714\n",
      "Epoch [25/100], Step [800/1250], Loss: 0.000810, Train Accuracy: 0.995859\n",
      "Epoch [25/100], Step [900/1250], Loss: 0.038740, Train Accuracy: 0.995868\n",
      "Epoch [25/100], Step [1000/1250], Loss: 0.001606, Train Accuracy: 0.995781\n",
      "Epoch [25/100], Step [1100/1250], Loss: 0.000125, Train Accuracy: 0.995625\n",
      "Epoch [25/100], Step [1200/1250], Loss: 0.002405, Train Accuracy: 0.995781\n",
      "Epoch 25/100, Loss: 0.013191, Train Accuracy: 0.995775, Validation Accuracy: 0.816600\n",
      "Epoch [26/100], Step [100/1250], Loss: 0.000885, Train Accuracy: 0.998125\n",
      "Epoch [26/100], Step [200/1250], Loss: 0.000363, Train Accuracy: 0.998594\n",
      "Epoch [26/100], Step [300/1250], Loss: 0.007003, Train Accuracy: 0.998646\n",
      "Epoch [26/100], Step [400/1250], Loss: 0.000105, Train Accuracy: 0.998672\n",
      "Epoch [26/100], Step [500/1250], Loss: 0.000134, Train Accuracy: 0.998625\n",
      "Epoch [26/100], Step [600/1250], Loss: 0.002208, Train Accuracy: 0.998594\n",
      "Epoch [26/100], Step [700/1250], Loss: 0.005626, Train Accuracy: 0.998571\n",
      "Epoch [26/100], Step [800/1250], Loss: 0.001236, Train Accuracy: 0.998477\n",
      "Epoch [26/100], Step [900/1250], Loss: 0.000068, Train Accuracy: 0.998437\n",
      "Epoch [26/100], Step [1000/1250], Loss: 0.000960, Train Accuracy: 0.998406\n",
      "Epoch [26/100], Step [1100/1250], Loss: 0.013557, Train Accuracy: 0.998295\n",
      "Epoch [26/100], Step [1200/1250], Loss: 0.000787, Train Accuracy: 0.998229\n",
      "Epoch 26/100, Loss: 0.006966, Train Accuracy: 0.998075, Validation Accuracy: 0.815700\n",
      "Epoch [27/100], Step [100/1250], Loss: 0.001531, Train Accuracy: 0.997500\n",
      "Epoch [27/100], Step [200/1250], Loss: 0.106917, Train Accuracy: 0.996406\n",
      "Epoch [27/100], Step [300/1250], Loss: 0.003175, Train Accuracy: 0.996042\n",
      "Epoch [27/100], Step [400/1250], Loss: 0.014520, Train Accuracy: 0.996406\n",
      "Epoch [27/100], Step [500/1250], Loss: 0.013544, Train Accuracy: 0.996500\n",
      "Epoch [27/100], Step [600/1250], Loss: 0.012120, Train Accuracy: 0.996719\n",
      "Epoch [27/100], Step [700/1250], Loss: 0.000670, Train Accuracy: 0.997009\n",
      "Epoch [27/100], Step [800/1250], Loss: 0.002604, Train Accuracy: 0.996836\n",
      "Epoch [27/100], Step [900/1250], Loss: 0.001148, Train Accuracy: 0.996701\n",
      "Epoch [27/100], Step [1000/1250], Loss: 0.002156, Train Accuracy: 0.996750\n",
      "Epoch [27/100], Step [1100/1250], Loss: 0.000300, Train Accuracy: 0.996875\n",
      "Epoch [27/100], Step [1200/1250], Loss: 0.001704, Train Accuracy: 0.996771\n",
      "Epoch 27/100, Loss: 0.009903, Train Accuracy: 0.996725, Validation Accuracy: 0.816400\n",
      "Epoch [28/100], Step [100/1250], Loss: 0.049186, Train Accuracy: 0.995938\n",
      "Epoch [28/100], Step [200/1250], Loss: 0.016116, Train Accuracy: 0.995469\n",
      "Epoch [28/100], Step [300/1250], Loss: 0.007119, Train Accuracy: 0.995625\n",
      "Epoch [28/100], Step [400/1250], Loss: 0.003172, Train Accuracy: 0.996016\n",
      "Epoch [28/100], Step [500/1250], Loss: 0.000668, Train Accuracy: 0.995938\n",
      "Epoch [28/100], Step [600/1250], Loss: 0.000476, Train Accuracy: 0.996146\n",
      "Epoch [28/100], Step [700/1250], Loss: 0.000954, Train Accuracy: 0.996384\n",
      "Epoch [28/100], Step [800/1250], Loss: 0.009637, Train Accuracy: 0.996484\n",
      "Epoch [28/100], Step [900/1250], Loss: 0.001210, Train Accuracy: 0.996354\n",
      "Epoch [28/100], Step [1000/1250], Loss: 0.017154, Train Accuracy: 0.996344\n",
      "Epoch [28/100], Step [1100/1250], Loss: 0.000773, Train Accuracy: 0.996420\n",
      "Epoch [28/100], Step [1200/1250], Loss: 0.000437, Train Accuracy: 0.996406\n",
      "Epoch 28/100, Loss: 0.010775, Train Accuracy: 0.996375, Validation Accuracy: 0.817900\n",
      "Epoch [29/100], Step [100/1250], Loss: 0.001739, Train Accuracy: 0.997500\n",
      "Epoch [29/100], Step [200/1250], Loss: 0.001758, Train Accuracy: 0.996875\n",
      "Epoch [29/100], Step [300/1250], Loss: 0.009292, Train Accuracy: 0.995729\n",
      "Epoch [29/100], Step [400/1250], Loss: 0.000642, Train Accuracy: 0.996016\n",
      "Epoch [29/100], Step [500/1250], Loss: 0.000483, Train Accuracy: 0.996062\n",
      "Epoch [29/100], Step [600/1250], Loss: 0.000211, Train Accuracy: 0.996302\n",
      "Epoch [29/100], Step [700/1250], Loss: 0.000543, Train Accuracy: 0.996429\n",
      "Epoch [29/100], Step [800/1250], Loss: 0.006969, Train Accuracy: 0.996406\n",
      "Epoch [29/100], Step [900/1250], Loss: 0.000137, Train Accuracy: 0.996319\n",
      "Epoch [29/100], Step [1000/1250], Loss: 0.001421, Train Accuracy: 0.996250\n",
      "Epoch [29/100], Step [1100/1250], Loss: 0.077033, Train Accuracy: 0.996165\n",
      "Epoch [29/100], Step [1200/1250], Loss: 0.000324, Train Accuracy: 0.996172\n",
      "Epoch 29/100, Loss: 0.011277, Train Accuracy: 0.996175, Validation Accuracy: 0.818200\n",
      "Epoch [30/100], Step [100/1250], Loss: 0.000938, Train Accuracy: 0.997500\n",
      "Epoch [30/100], Step [200/1250], Loss: 0.001321, Train Accuracy: 0.997656\n",
      "Epoch [30/100], Step [300/1250], Loss: 0.010665, Train Accuracy: 0.998229\n",
      "Epoch [30/100], Step [400/1250], Loss: 0.030102, Train Accuracy: 0.997812\n",
      "Epoch [30/100], Step [500/1250], Loss: 0.000385, Train Accuracy: 0.997375\n",
      "Epoch [30/100], Step [600/1250], Loss: 0.000071, Train Accuracy: 0.997344\n",
      "Epoch [30/100], Step [700/1250], Loss: 0.000189, Train Accuracy: 0.997500\n",
      "Epoch [30/100], Step [800/1250], Loss: 0.004288, Train Accuracy: 0.997266\n",
      "Epoch [30/100], Step [900/1250], Loss: 0.000431, Train Accuracy: 0.997361\n",
      "Epoch [30/100], Step [1000/1250], Loss: 0.000583, Train Accuracy: 0.997500\n",
      "Epoch [30/100], Step [1100/1250], Loss: 0.000704, Train Accuracy: 0.997415\n",
      "Epoch [30/100], Step [1200/1250], Loss: 0.001440, Train Accuracy: 0.997370\n",
      "Epoch 30/100, Loss: 0.008542, Train Accuracy: 0.997200, Validation Accuracy: 0.819000\n",
      "Epoch [31/100], Step [100/1250], Loss: 0.020301, Train Accuracy: 0.998437\n",
      "Epoch [31/100], Step [200/1250], Loss: 0.000977, Train Accuracy: 0.998906\n",
      "Epoch [31/100], Step [300/1250], Loss: 0.026441, Train Accuracy: 0.998750\n",
      "Epoch [31/100], Step [400/1250], Loss: 0.002857, Train Accuracy: 0.998516\n",
      "Epoch [31/100], Step [500/1250], Loss: 0.000270, Train Accuracy: 0.998437\n",
      "Epoch [31/100], Step [600/1250], Loss: 0.001961, Train Accuracy: 0.998385\n",
      "Epoch [31/100], Step [700/1250], Loss: 0.000133, Train Accuracy: 0.998482\n",
      "Epoch [31/100], Step [800/1250], Loss: 0.002104, Train Accuracy: 0.998398\n",
      "Epoch [31/100], Step [900/1250], Loss: 0.015184, Train Accuracy: 0.998333\n",
      "Epoch [31/100], Step [1000/1250], Loss: 0.081812, Train Accuracy: 0.998250\n",
      "Epoch [31/100], Step [1100/1250], Loss: 0.000225, Train Accuracy: 0.998153\n",
      "Epoch [31/100], Step [1200/1250], Loss: 0.000796, Train Accuracy: 0.997943\n",
      "Epoch 31/100, Loss: 0.006423, Train Accuracy: 0.997950, Validation Accuracy: 0.817700\n",
      "Epoch [32/100], Step [100/1250], Loss: 0.001343, Train Accuracy: 0.997188\n",
      "Epoch [32/100], Step [200/1250], Loss: 0.003239, Train Accuracy: 0.997656\n",
      "Epoch [32/100], Step [300/1250], Loss: 0.000521, Train Accuracy: 0.997708\n",
      "Epoch [32/100], Step [400/1250], Loss: 0.000468, Train Accuracy: 0.997344\n",
      "Epoch [32/100], Step [500/1250], Loss: 0.012073, Train Accuracy: 0.997188\n",
      "Epoch [32/100], Step [600/1250], Loss: 0.002797, Train Accuracy: 0.997188\n",
      "Epoch [32/100], Step [700/1250], Loss: 0.000564, Train Accuracy: 0.997232\n",
      "Epoch [32/100], Step [800/1250], Loss: 0.006676, Train Accuracy: 0.997578\n",
      "Epoch [32/100], Step [900/1250], Loss: 0.000927, Train Accuracy: 0.997604\n",
      "Epoch [32/100], Step [1000/1250], Loss: 0.001399, Train Accuracy: 0.997625\n",
      "Epoch [32/100], Step [1100/1250], Loss: 0.000862, Train Accuracy: 0.997614\n",
      "Epoch [32/100], Step [1200/1250], Loss: 0.000661, Train Accuracy: 0.997578\n",
      "Epoch 32/100, Loss: 0.007522, Train Accuracy: 0.997600, Validation Accuracy: 0.819700\n",
      "Epoch [33/100], Step [100/1250], Loss: 0.020326, Train Accuracy: 0.998437\n",
      "Epoch [33/100], Step [200/1250], Loss: 0.000186, Train Accuracy: 0.998281\n",
      "Epoch [33/100], Step [300/1250], Loss: 0.000223, Train Accuracy: 0.998542\n",
      "Epoch [33/100], Step [400/1250], Loss: 0.024484, Train Accuracy: 0.998594\n",
      "Epoch [33/100], Step [500/1250], Loss: 0.005605, Train Accuracy: 0.998313\n",
      "Epoch [33/100], Step [600/1250], Loss: 0.001077, Train Accuracy: 0.998021\n",
      "Epoch [33/100], Step [700/1250], Loss: 0.000052, Train Accuracy: 0.998080\n",
      "Epoch [33/100], Step [800/1250], Loss: 0.046629, Train Accuracy: 0.998008\n",
      "Epoch [33/100], Step [900/1250], Loss: 0.000137, Train Accuracy: 0.998160\n",
      "Epoch [33/100], Step [1000/1250], Loss: 0.000459, Train Accuracy: 0.998156\n",
      "Epoch [33/100], Step [1100/1250], Loss: 0.000309, Train Accuracy: 0.998040\n",
      "Epoch [33/100], Step [1200/1250], Loss: 0.063150, Train Accuracy: 0.997891\n",
      "Epoch 33/100, Loss: 0.006427, Train Accuracy: 0.997800, Validation Accuracy: 0.812800\n",
      "Epoch [34/100], Step [100/1250], Loss: 0.000368, Train Accuracy: 0.998750\n",
      "Epoch [34/100], Step [200/1250], Loss: 0.000108, Train Accuracy: 0.998125\n",
      "Epoch [34/100], Step [300/1250], Loss: 0.000553, Train Accuracy: 0.998229\n",
      "Epoch [34/100], Step [400/1250], Loss: 0.057137, Train Accuracy: 0.998125\n",
      "Epoch [34/100], Step [500/1250], Loss: 0.002328, Train Accuracy: 0.998437\n",
      "Epoch [34/100], Step [600/1250], Loss: 0.001036, Train Accuracy: 0.998437\n",
      "Epoch [34/100], Step [700/1250], Loss: 0.000681, Train Accuracy: 0.998437\n",
      "Epoch [34/100], Step [800/1250], Loss: 0.019791, Train Accuracy: 0.998477\n",
      "Epoch [34/100], Step [900/1250], Loss: 0.003701, Train Accuracy: 0.998403\n",
      "Epoch [34/100], Step [1000/1250], Loss: 0.000482, Train Accuracy: 0.998281\n",
      "Epoch [34/100], Step [1100/1250], Loss: 0.000642, Train Accuracy: 0.998210\n",
      "Epoch [34/100], Step [1200/1250], Loss: 0.000076, Train Accuracy: 0.998229\n",
      "Epoch 34/100, Loss: 0.006092, Train Accuracy: 0.998200, Validation Accuracy: 0.816100\n",
      "Epoch [35/100], Step [100/1250], Loss: 0.000934, Train Accuracy: 0.997812\n",
      "Epoch [35/100], Step [200/1250], Loss: 0.002591, Train Accuracy: 0.998281\n",
      "Epoch [35/100], Step [300/1250], Loss: 0.029973, Train Accuracy: 0.997188\n",
      "Epoch [35/100], Step [400/1250], Loss: 0.006018, Train Accuracy: 0.996719\n",
      "Epoch [35/100], Step [500/1250], Loss: 0.000563, Train Accuracy: 0.997062\n",
      "Epoch [35/100], Step [600/1250], Loss: 0.000174, Train Accuracy: 0.997083\n",
      "Epoch [35/100], Step [700/1250], Loss: 0.008937, Train Accuracy: 0.997321\n",
      "Epoch [35/100], Step [800/1250], Loss: 0.000692, Train Accuracy: 0.997383\n",
      "Epoch [35/100], Step [900/1250], Loss: 0.000062, Train Accuracy: 0.997465\n",
      "Epoch [35/100], Step [1000/1250], Loss: 0.005584, Train Accuracy: 0.997313\n",
      "Epoch [35/100], Step [1100/1250], Loss: 0.000078, Train Accuracy: 0.997358\n",
      "Epoch [35/100], Step [1200/1250], Loss: 0.000380, Train Accuracy: 0.997396\n",
      "Epoch 35/100, Loss: 0.008062, Train Accuracy: 0.997300, Validation Accuracy: 0.816700\n",
      "Epoch [36/100], Step [100/1250], Loss: 0.000142, Train Accuracy: 0.997500\n",
      "Epoch [36/100], Step [200/1250], Loss: 0.000619, Train Accuracy: 0.997031\n",
      "Epoch [36/100], Step [300/1250], Loss: 0.003323, Train Accuracy: 0.997396\n",
      "Epoch [36/100], Step [400/1250], Loss: 0.004301, Train Accuracy: 0.997344\n",
      "Epoch [36/100], Step [500/1250], Loss: 0.003246, Train Accuracy: 0.997188\n",
      "Epoch [36/100], Step [600/1250], Loss: 0.000273, Train Accuracy: 0.997083\n",
      "Epoch [36/100], Step [700/1250], Loss: 0.005026, Train Accuracy: 0.997098\n",
      "Epoch [36/100], Step [800/1250], Loss: 0.012984, Train Accuracy: 0.997266\n",
      "Epoch [36/100], Step [900/1250], Loss: 0.000859, Train Accuracy: 0.997396\n",
      "Epoch [36/100], Step [1000/1250], Loss: 0.008710, Train Accuracy: 0.997500\n",
      "Epoch [36/100], Step [1100/1250], Loss: 0.000425, Train Accuracy: 0.997528\n",
      "Epoch [36/100], Step [1200/1250], Loss: 0.005108, Train Accuracy: 0.997526\n",
      "Epoch 36/100, Loss: 0.008318, Train Accuracy: 0.997500, Validation Accuracy: 0.820900\n",
      "Epoch [37/100], Step [100/1250], Loss: 0.000822, Train Accuracy: 0.999062\n",
      "Epoch [37/100], Step [200/1250], Loss: 0.000155, Train Accuracy: 0.998281\n",
      "Epoch [37/100], Step [300/1250], Loss: 0.000090, Train Accuracy: 0.998021\n",
      "Epoch [37/100], Step [400/1250], Loss: 0.000956, Train Accuracy: 0.998203\n",
      "Epoch [37/100], Step [500/1250], Loss: 0.000302, Train Accuracy: 0.998375\n",
      "Epoch [37/100], Step [600/1250], Loss: 0.000070, Train Accuracy: 0.998177\n",
      "Epoch [37/100], Step [700/1250], Loss: 0.000678, Train Accuracy: 0.998304\n",
      "Epoch [37/100], Step [800/1250], Loss: 0.000844, Train Accuracy: 0.998281\n",
      "Epoch [37/100], Step [900/1250], Loss: 0.000280, Train Accuracy: 0.998299\n",
      "Epoch [37/100], Step [1000/1250], Loss: 0.001491, Train Accuracy: 0.998281\n",
      "Epoch [37/100], Step [1100/1250], Loss: 0.001055, Train Accuracy: 0.998267\n",
      "Epoch [37/100], Step [1200/1250], Loss: 0.008581, Train Accuracy: 0.998307\n",
      "Epoch 37/100, Loss: 0.005544, Train Accuracy: 0.998325, Validation Accuracy: 0.815500\n",
      "Epoch [38/100], Step [100/1250], Loss: 0.002719, Train Accuracy: 0.998750\n",
      "Epoch [38/100], Step [200/1250], Loss: 0.000120, Train Accuracy: 0.999062\n",
      "Epoch [38/100], Step [300/1250], Loss: 0.000081, Train Accuracy: 0.998750\n",
      "Epoch [38/100], Step [400/1250], Loss: 0.000117, Train Accuracy: 0.998281\n",
      "Epoch [38/100], Step [500/1250], Loss: 0.003387, Train Accuracy: 0.998563\n",
      "Epoch [38/100], Step [600/1250], Loss: 0.010643, Train Accuracy: 0.998594\n",
      "Epoch [38/100], Step [700/1250], Loss: 0.000468, Train Accuracy: 0.998304\n",
      "Epoch [38/100], Step [800/1250], Loss: 0.006860, Train Accuracy: 0.998242\n",
      "Epoch [38/100], Step [900/1250], Loss: 0.001379, Train Accuracy: 0.998299\n",
      "Epoch [38/100], Step [1000/1250], Loss: 0.004752, Train Accuracy: 0.998313\n",
      "Epoch [38/100], Step [1100/1250], Loss: 0.001235, Train Accuracy: 0.998153\n",
      "Epoch [38/100], Step [1200/1250], Loss: 0.000050, Train Accuracy: 0.998177\n",
      "Epoch 38/100, Loss: 0.006607, Train Accuracy: 0.998050, Validation Accuracy: 0.819200\n",
      "Epoch [39/100], Step [100/1250], Loss: 0.000943, Train Accuracy: 0.998437\n",
      "Epoch [39/100], Step [200/1250], Loss: 0.000302, Train Accuracy: 0.998125\n",
      "Epoch [39/100], Step [300/1250], Loss: 0.000352, Train Accuracy: 0.998125\n",
      "Epoch [39/100], Step [400/1250], Loss: 0.037648, Train Accuracy: 0.998281\n",
      "Epoch [39/100], Step [500/1250], Loss: 0.000660, Train Accuracy: 0.998437\n",
      "Epoch [39/100], Step [600/1250], Loss: 0.001186, Train Accuracy: 0.998229\n",
      "Epoch [39/100], Step [700/1250], Loss: 0.000538, Train Accuracy: 0.998348\n",
      "Epoch [39/100], Step [800/1250], Loss: 0.000750, Train Accuracy: 0.998203\n",
      "Epoch [39/100], Step [900/1250], Loss: 0.000380, Train Accuracy: 0.998056\n",
      "Epoch [39/100], Step [1000/1250], Loss: 0.006483, Train Accuracy: 0.997844\n",
      "Epoch [39/100], Step [1100/1250], Loss: 0.001013, Train Accuracy: 0.997869\n",
      "Epoch [39/100], Step [1200/1250], Loss: 0.003711, Train Accuracy: 0.997969\n",
      "Epoch 39/100, Loss: 0.005999, Train Accuracy: 0.997950, Validation Accuracy: 0.821600\n",
      "Epoch [40/100], Step [100/1250], Loss: 0.000566, Train Accuracy: 0.999062\n",
      "Epoch [40/100], Step [200/1250], Loss: 0.001129, Train Accuracy: 0.998750\n",
      "Epoch [40/100], Step [300/1250], Loss: 0.006211, Train Accuracy: 0.998958\n",
      "Epoch [40/100], Step [400/1250], Loss: 0.000913, Train Accuracy: 0.998906\n",
      "Epoch [40/100], Step [500/1250], Loss: 0.000146, Train Accuracy: 0.998750\n",
      "Epoch [40/100], Step [600/1250], Loss: 0.001399, Train Accuracy: 0.998385\n",
      "Epoch [40/100], Step [700/1250], Loss: 0.000173, Train Accuracy: 0.998527\n",
      "Epoch [40/100], Step [800/1250], Loss: 0.008104, Train Accuracy: 0.998516\n",
      "Epoch [40/100], Step [900/1250], Loss: 0.000091, Train Accuracy: 0.998472\n",
      "Epoch [40/100], Step [1000/1250], Loss: 0.002009, Train Accuracy: 0.998344\n",
      "Epoch [40/100], Step [1100/1250], Loss: 0.001257, Train Accuracy: 0.998267\n",
      "Epoch [40/100], Step [1200/1250], Loss: 0.000150, Train Accuracy: 0.998255\n",
      "Epoch 40/100, Loss: 0.005447, Train Accuracy: 0.998275, Validation Accuracy: 0.819000\n",
      "Epoch [41/100], Step [100/1250], Loss: 0.000194, Train Accuracy: 0.999062\n",
      "Epoch [41/100], Step [200/1250], Loss: 0.000288, Train Accuracy: 0.998750\n",
      "Epoch [41/100], Step [300/1250], Loss: 0.000265, Train Accuracy: 0.998333\n",
      "Epoch [41/100], Step [400/1250], Loss: 0.000365, Train Accuracy: 0.998359\n",
      "Epoch [41/100], Step [500/1250], Loss: 0.000741, Train Accuracy: 0.998437\n",
      "Epoch [41/100], Step [600/1250], Loss: 0.000491, Train Accuracy: 0.998542\n",
      "Epoch [41/100], Step [700/1250], Loss: 0.021990, Train Accuracy: 0.998348\n",
      "Epoch [41/100], Step [800/1250], Loss: 0.028082, Train Accuracy: 0.998359\n",
      "Epoch [41/100], Step [900/1250], Loss: 0.045880, Train Accuracy: 0.998403\n",
      "Epoch [41/100], Step [1000/1250], Loss: 0.007995, Train Accuracy: 0.998500\n",
      "Epoch [41/100], Step [1100/1250], Loss: 0.000825, Train Accuracy: 0.998409\n",
      "Epoch [41/100], Step [1200/1250], Loss: 0.000184, Train Accuracy: 0.998385\n",
      "Epoch 41/100, Loss: 0.004971, Train Accuracy: 0.998325, Validation Accuracy: 0.817500\n",
      "Epoch [42/100], Step [100/1250], Loss: 0.004998, Train Accuracy: 0.998437\n",
      "Epoch [42/100], Step [200/1250], Loss: 0.000711, Train Accuracy: 0.998281\n",
      "Epoch [42/100], Step [300/1250], Loss: 0.000469, Train Accuracy: 0.998333\n",
      "Epoch [42/100], Step [400/1250], Loss: 0.002582, Train Accuracy: 0.998281\n",
      "Epoch [42/100], Step [500/1250], Loss: 0.000179, Train Accuracy: 0.997938\n",
      "Epoch [42/100], Step [600/1250], Loss: 0.002716, Train Accuracy: 0.998073\n",
      "Epoch [42/100], Step [700/1250], Loss: 0.000148, Train Accuracy: 0.998125\n",
      "Epoch [42/100], Step [800/1250], Loss: 0.000676, Train Accuracy: 0.998086\n",
      "Epoch [42/100], Step [900/1250], Loss: 0.000747, Train Accuracy: 0.998090\n",
      "Epoch [42/100], Step [1000/1250], Loss: 0.000204, Train Accuracy: 0.998094\n",
      "Epoch [42/100], Step [1100/1250], Loss: 0.000098, Train Accuracy: 0.998097\n",
      "Epoch [42/100], Step [1200/1250], Loss: 0.000079, Train Accuracy: 0.997969\n",
      "Epoch 42/100, Loss: 0.006921, Train Accuracy: 0.997900, Validation Accuracy: 0.818000\n",
      "Epoch [43/100], Step [100/1250], Loss: 0.002089, Train Accuracy: 0.998437\n",
      "Epoch [43/100], Step [200/1250], Loss: 0.000035, Train Accuracy: 0.997812\n",
      "Epoch [43/100], Step [300/1250], Loss: 0.000330, Train Accuracy: 0.997500\n",
      "Epoch [43/100], Step [400/1250], Loss: 0.004311, Train Accuracy: 0.997734\n",
      "Epoch [43/100], Step [500/1250], Loss: 0.009506, Train Accuracy: 0.997812\n",
      "Epoch [43/100], Step [600/1250], Loss: 0.000734, Train Accuracy: 0.997865\n",
      "Epoch [43/100], Step [700/1250], Loss: 0.012330, Train Accuracy: 0.997768\n",
      "Epoch [43/100], Step [800/1250], Loss: 0.000294, Train Accuracy: 0.997891\n",
      "Epoch [43/100], Step [900/1250], Loss: 0.000403, Train Accuracy: 0.997882\n",
      "Epoch [43/100], Step [1000/1250], Loss: 0.009664, Train Accuracy: 0.997969\n",
      "Epoch [43/100], Step [1100/1250], Loss: 0.000565, Train Accuracy: 0.997983\n",
      "Epoch [43/100], Step [1200/1250], Loss: 0.011302, Train Accuracy: 0.997943\n",
      "Epoch 43/100, Loss: 0.006447, Train Accuracy: 0.997950, Validation Accuracy: 0.817100\n",
      "Epoch [44/100], Step [100/1250], Loss: 0.000177, Train Accuracy: 0.999062\n",
      "Epoch [44/100], Step [200/1250], Loss: 0.000523, Train Accuracy: 0.998750\n",
      "Epoch [44/100], Step [300/1250], Loss: 0.002627, Train Accuracy: 0.998333\n",
      "Epoch [44/100], Step [400/1250], Loss: 0.003554, Train Accuracy: 0.998359\n",
      "Epoch [44/100], Step [500/1250], Loss: 0.000293, Train Accuracy: 0.998313\n",
      "Epoch [44/100], Step [600/1250], Loss: 0.001186, Train Accuracy: 0.998385\n",
      "Epoch [44/100], Step [700/1250], Loss: 0.006578, Train Accuracy: 0.998393\n",
      "Epoch [44/100], Step [800/1250], Loss: 0.000050, Train Accuracy: 0.998516\n",
      "Epoch [44/100], Step [900/1250], Loss: 0.002922, Train Accuracy: 0.998472\n",
      "Epoch [44/100], Step [1000/1250], Loss: 0.002820, Train Accuracy: 0.998500\n",
      "Epoch [44/100], Step [1100/1250], Loss: 0.000900, Train Accuracy: 0.998494\n",
      "Epoch [44/100], Step [1200/1250], Loss: 0.000617, Train Accuracy: 0.998542\n",
      "Epoch 44/100, Loss: 0.004678, Train Accuracy: 0.998550, Validation Accuracy: 0.818300\n",
      "Epoch [45/100], Step [100/1250], Loss: 0.000288, Train Accuracy: 0.997812\n",
      "Epoch [45/100], Step [200/1250], Loss: 0.001158, Train Accuracy: 0.997969\n",
      "Epoch [45/100], Step [300/1250], Loss: 0.000095, Train Accuracy: 0.997708\n",
      "Epoch [45/100], Step [400/1250], Loss: 0.000401, Train Accuracy: 0.998047\n",
      "Epoch [45/100], Step [500/1250], Loss: 0.001723, Train Accuracy: 0.998188\n",
      "Epoch [45/100], Step [600/1250], Loss: 0.000085, Train Accuracy: 0.997969\n",
      "Epoch [45/100], Step [700/1250], Loss: 0.000653, Train Accuracy: 0.997946\n",
      "Epoch [45/100], Step [800/1250], Loss: 0.000105, Train Accuracy: 0.998164\n",
      "Epoch [45/100], Step [900/1250], Loss: 0.000810, Train Accuracy: 0.998229\n",
      "Epoch [45/100], Step [1000/1250], Loss: 0.000205, Train Accuracy: 0.998219\n",
      "Epoch [45/100], Step [1100/1250], Loss: 0.000754, Train Accuracy: 0.998210\n",
      "Epoch [45/100], Step [1200/1250], Loss: 0.002739, Train Accuracy: 0.998177\n",
      "Epoch 45/100, Loss: 0.006206, Train Accuracy: 0.998150, Validation Accuracy: 0.817400\n",
      "Epoch [46/100], Step [100/1250], Loss: 0.000370, Train Accuracy: 0.999062\n",
      "Epoch [46/100], Step [200/1250], Loss: 0.000482, Train Accuracy: 0.998125\n",
      "Epoch [46/100], Step [300/1250], Loss: 0.000387, Train Accuracy: 0.998333\n",
      "Epoch [46/100], Step [400/1250], Loss: 0.000761, Train Accuracy: 0.998437\n",
      "Epoch [46/100], Step [500/1250], Loss: 0.000308, Train Accuracy: 0.998625\n",
      "Epoch [46/100], Step [600/1250], Loss: 0.000431, Train Accuracy: 0.998698\n",
      "Epoch [46/100], Step [700/1250], Loss: 0.000114, Train Accuracy: 0.998795\n",
      "Epoch [46/100], Step [800/1250], Loss: 0.000598, Train Accuracy: 0.998711\n",
      "Epoch [46/100], Step [900/1250], Loss: 0.000141, Train Accuracy: 0.998750\n",
      "Epoch [46/100], Step [1000/1250], Loss: 0.000324, Train Accuracy: 0.998625\n",
      "Epoch [46/100], Step [1100/1250], Loss: 0.000078, Train Accuracy: 0.998494\n",
      "Epoch [46/100], Step [1200/1250], Loss: 0.008871, Train Accuracy: 0.998516\n",
      "Epoch 46/100, Loss: 0.005053, Train Accuracy: 0.998475, Validation Accuracy: 0.817600\n",
      "Epoch [47/100], Step [100/1250], Loss: 0.011606, Train Accuracy: 0.998750\n",
      "Epoch [47/100], Step [200/1250], Loss: 0.001121, Train Accuracy: 0.999062\n",
      "Epoch [47/100], Step [300/1250], Loss: 0.042227, Train Accuracy: 0.998750\n",
      "Epoch [47/100], Step [400/1250], Loss: 0.000077, Train Accuracy: 0.998672\n",
      "Epoch [47/100], Step [500/1250], Loss: 0.003256, Train Accuracy: 0.998750\n",
      "Epoch [47/100], Step [600/1250], Loss: 0.123731, Train Accuracy: 0.998594\n",
      "Epoch [47/100], Step [700/1250], Loss: 0.000211, Train Accuracy: 0.998616\n",
      "Epoch [47/100], Step [800/1250], Loss: 0.028606, Train Accuracy: 0.998477\n",
      "Epoch [47/100], Step [900/1250], Loss: 0.000111, Train Accuracy: 0.998368\n",
      "Epoch [47/100], Step [1000/1250], Loss: 0.010276, Train Accuracy: 0.998219\n",
      "Epoch [47/100], Step [1100/1250], Loss: 0.002724, Train Accuracy: 0.998210\n",
      "Epoch [47/100], Step [1200/1250], Loss: 0.000570, Train Accuracy: 0.998229\n",
      "Epoch 47/100, Loss: 0.006221, Train Accuracy: 0.998225, Validation Accuracy: 0.814300\n",
      "Epoch [48/100], Step [100/1250], Loss: 0.000358, Train Accuracy: 0.998750\n",
      "Epoch [48/100], Step [200/1250], Loss: 0.002998, Train Accuracy: 0.997969\n",
      "Epoch [48/100], Step [300/1250], Loss: 0.000307, Train Accuracy: 0.998646\n",
      "Epoch [48/100], Step [400/1250], Loss: 0.000295, Train Accuracy: 0.998828\n",
      "Epoch [48/100], Step [500/1250], Loss: 0.000949, Train Accuracy: 0.998563\n",
      "Epoch [48/100], Step [600/1250], Loss: 0.001682, Train Accuracy: 0.998490\n",
      "Epoch [48/100], Step [700/1250], Loss: 0.000663, Train Accuracy: 0.998437\n",
      "Epoch [48/100], Step [800/1250], Loss: 0.000123, Train Accuracy: 0.998555\n",
      "Epoch [48/100], Step [900/1250], Loss: 0.000357, Train Accuracy: 0.998437\n",
      "Epoch [48/100], Step [1000/1250], Loss: 0.000921, Train Accuracy: 0.998281\n",
      "Epoch [48/100], Step [1100/1250], Loss: 0.000100, Train Accuracy: 0.998267\n",
      "Epoch [48/100], Step [1200/1250], Loss: 0.000100, Train Accuracy: 0.998203\n",
      "Epoch 48/100, Loss: 0.006020, Train Accuracy: 0.998225, Validation Accuracy: 0.818100\n",
      "Epoch [49/100], Step [100/1250], Loss: 0.000244, Train Accuracy: 0.998437\n",
      "Epoch [49/100], Step [200/1250], Loss: 0.002837, Train Accuracy: 0.998437\n",
      "Epoch [49/100], Step [300/1250], Loss: 0.000169, Train Accuracy: 0.998646\n",
      "Epoch [49/100], Step [400/1250], Loss: 0.003611, Train Accuracy: 0.998437\n",
      "Epoch [49/100], Step [500/1250], Loss: 0.008453, Train Accuracy: 0.998313\n",
      "Epoch [49/100], Step [600/1250], Loss: 0.003054, Train Accuracy: 0.998125\n",
      "Epoch [49/100], Step [700/1250], Loss: 0.000447, Train Accuracy: 0.998304\n",
      "Epoch [49/100], Step [800/1250], Loss: 0.000088, Train Accuracy: 0.998320\n",
      "Epoch [49/100], Step [900/1250], Loss: 0.008106, Train Accuracy: 0.998299\n",
      "Epoch [49/100], Step [1000/1250], Loss: 0.000269, Train Accuracy: 0.998281\n",
      "Epoch [49/100], Step [1100/1250], Loss: 0.000236, Train Accuracy: 0.998352\n",
      "Epoch [49/100], Step [1200/1250], Loss: 0.001309, Train Accuracy: 0.998281\n",
      "Epoch 49/100, Loss: 0.005802, Train Accuracy: 0.998250, Validation Accuracy: 0.814700\n",
      "Epoch [50/100], Step [100/1250], Loss: 0.000290, Train Accuracy: 0.997812\n",
      "Epoch [50/100], Step [200/1250], Loss: 0.002289, Train Accuracy: 0.998906\n",
      "Epoch [50/100], Step [300/1250], Loss: 0.000150, Train Accuracy: 0.998854\n",
      "Epoch [50/100], Step [400/1250], Loss: 0.001698, Train Accuracy: 0.998359\n",
      "Epoch [50/100], Step [500/1250], Loss: 0.004919, Train Accuracy: 0.998062\n",
      "Epoch [50/100], Step [600/1250], Loss: 0.000519, Train Accuracy: 0.998125\n",
      "Epoch [50/100], Step [700/1250], Loss: 0.000142, Train Accuracy: 0.998304\n",
      "Epoch [50/100], Step [800/1250], Loss: 0.000054, Train Accuracy: 0.998477\n",
      "Epoch [50/100], Step [900/1250], Loss: 0.000702, Train Accuracy: 0.998576\n",
      "Epoch [50/100], Step [1000/1250], Loss: 0.000142, Train Accuracy: 0.998500\n",
      "Epoch [50/100], Step [1100/1250], Loss: 0.000343, Train Accuracy: 0.998466\n",
      "Epoch [50/100], Step [1200/1250], Loss: 0.000073, Train Accuracy: 0.998516\n",
      "Epoch 50/100, Loss: 0.005312, Train Accuracy: 0.998575, Validation Accuracy: 0.818300\n",
      "Epoch [51/100], Step [100/1250], Loss: 0.001355, Train Accuracy: 0.999375\n",
      "Epoch [51/100], Step [200/1250], Loss: 0.000735, Train Accuracy: 0.998594\n",
      "Epoch [51/100], Step [300/1250], Loss: 0.001674, Train Accuracy: 0.998437\n",
      "Epoch [51/100], Step [400/1250], Loss: 0.001476, Train Accuracy: 0.998516\n",
      "Epoch [51/100], Step [500/1250], Loss: 0.000443, Train Accuracy: 0.998563\n",
      "Epoch [51/100], Step [600/1250], Loss: 0.011751, Train Accuracy: 0.998646\n",
      "Epoch [51/100], Step [700/1250], Loss: 0.000206, Train Accuracy: 0.998571\n",
      "Epoch [51/100], Step [800/1250], Loss: 0.001462, Train Accuracy: 0.998672\n",
      "Epoch [51/100], Step [900/1250], Loss: 0.000033, Train Accuracy: 0.998576\n",
      "Epoch [51/100], Step [1000/1250], Loss: 0.000731, Train Accuracy: 0.998625\n",
      "Epoch [51/100], Step [1100/1250], Loss: 0.003183, Train Accuracy: 0.998722\n",
      "Epoch [51/100], Step [1200/1250], Loss: 0.000439, Train Accuracy: 0.998802\n",
      "Epoch 51/100, Loss: 0.004079, Train Accuracy: 0.998775, Validation Accuracy: 0.820000\n",
      "Epoch [52/100], Step [100/1250], Loss: 0.000171, Train Accuracy: 0.998125\n",
      "Epoch [52/100], Step [200/1250], Loss: 0.000129, Train Accuracy: 0.998594\n",
      "Epoch [52/100], Step [300/1250], Loss: 0.000167, Train Accuracy: 0.998333\n",
      "Epoch [52/100], Step [400/1250], Loss: 0.001511, Train Accuracy: 0.998281\n",
      "Epoch [52/100], Step [500/1250], Loss: 0.000119, Train Accuracy: 0.998437\n",
      "Epoch [52/100], Step [600/1250], Loss: 0.000442, Train Accuracy: 0.998646\n",
      "Epoch [52/100], Step [700/1250], Loss: 0.001311, Train Accuracy: 0.998661\n",
      "Epoch [52/100], Step [800/1250], Loss: 0.000438, Train Accuracy: 0.998633\n",
      "Epoch [52/100], Step [900/1250], Loss: 0.000518, Train Accuracy: 0.998785\n",
      "Epoch [52/100], Step [1000/1250], Loss: 0.000335, Train Accuracy: 0.998812\n",
      "Epoch [52/100], Step [1100/1250], Loss: 0.001202, Train Accuracy: 0.998750\n",
      "Epoch [52/100], Step [1200/1250], Loss: 0.000235, Train Accuracy: 0.998776\n",
      "Epoch 52/100, Loss: 0.004231, Train Accuracy: 0.998700, Validation Accuracy: 0.817000\n",
      "Epoch [53/100], Step [100/1250], Loss: 0.000040, Train Accuracy: 0.999687\n",
      "Epoch [53/100], Step [200/1250], Loss: 0.000502, Train Accuracy: 0.998281\n",
      "Epoch [53/100], Step [300/1250], Loss: 0.000325, Train Accuracy: 0.998021\n",
      "Epoch [53/100], Step [400/1250], Loss: 0.003661, Train Accuracy: 0.998047\n",
      "Epoch [53/100], Step [500/1250], Loss: 0.000074, Train Accuracy: 0.998125\n",
      "Epoch [53/100], Step [600/1250], Loss: 0.001084, Train Accuracy: 0.998281\n",
      "Epoch [53/100], Step [700/1250], Loss: 0.000288, Train Accuracy: 0.998437\n",
      "Epoch [53/100], Step [800/1250], Loss: 0.014039, Train Accuracy: 0.998398\n",
      "Epoch [53/100], Step [900/1250], Loss: 0.000155, Train Accuracy: 0.998472\n",
      "Epoch [53/100], Step [1000/1250], Loss: 0.000123, Train Accuracy: 0.998406\n",
      "Epoch [53/100], Step [1100/1250], Loss: 0.015649, Train Accuracy: 0.998494\n",
      "Epoch [53/100], Step [1200/1250], Loss: 0.001222, Train Accuracy: 0.998542\n",
      "Epoch 53/100, Loss: 0.004927, Train Accuracy: 0.998600, Validation Accuracy: 0.815600\n",
      "Epoch [54/100], Step [100/1250], Loss: 0.000112, Train Accuracy: 0.999375\n",
      "Epoch [54/100], Step [200/1250], Loss: 0.001416, Train Accuracy: 0.999531\n",
      "Epoch [54/100], Step [300/1250], Loss: 0.000298, Train Accuracy: 0.999271\n",
      "Epoch [54/100], Step [400/1250], Loss: 0.000056, Train Accuracy: 0.999375\n",
      "Epoch [54/100], Step [500/1250], Loss: 0.001454, Train Accuracy: 0.999375\n",
      "Epoch [54/100], Step [600/1250], Loss: 0.000753, Train Accuracy: 0.999427\n",
      "Epoch [54/100], Step [700/1250], Loss: 0.002858, Train Accuracy: 0.999330\n",
      "Epoch [54/100], Step [800/1250], Loss: 0.128347, Train Accuracy: 0.999141\n",
      "Epoch [54/100], Step [900/1250], Loss: 0.000334, Train Accuracy: 0.999028\n",
      "Epoch [54/100], Step [1000/1250], Loss: 0.000217, Train Accuracy: 0.998812\n",
      "Epoch [54/100], Step [1100/1250], Loss: 0.000717, Train Accuracy: 0.998864\n",
      "Epoch [54/100], Step [1200/1250], Loss: 0.001215, Train Accuracy: 0.998828\n",
      "Epoch 54/100, Loss: 0.003676, Train Accuracy: 0.998800, Validation Accuracy: 0.817100\n",
      "Epoch [55/100], Step [100/1250], Loss: 0.000184, Train Accuracy: 0.999375\n",
      "Epoch [55/100], Step [200/1250], Loss: 0.000441, Train Accuracy: 0.999531\n",
      "Epoch [55/100], Step [300/1250], Loss: 0.000127, Train Accuracy: 0.999062\n",
      "Epoch [55/100], Step [400/1250], Loss: 0.000150, Train Accuracy: 0.998984\n",
      "Epoch [55/100], Step [500/1250], Loss: 0.000852, Train Accuracy: 0.998875\n",
      "Epoch [55/100], Step [600/1250], Loss: 0.004723, Train Accuracy: 0.998490\n",
      "Epoch [55/100], Step [700/1250], Loss: 0.000274, Train Accuracy: 0.998661\n",
      "Epoch [55/100], Step [800/1250], Loss: 0.000482, Train Accuracy: 0.998594\n",
      "Epoch [55/100], Step [900/1250], Loss: 0.001829, Train Accuracy: 0.998646\n",
      "Epoch [55/100], Step [1000/1250], Loss: 0.000166, Train Accuracy: 0.998719\n",
      "Epoch [55/100], Step [1100/1250], Loss: 0.000850, Train Accuracy: 0.998665\n",
      "Epoch [55/100], Step [1200/1250], Loss: 0.000666, Train Accuracy: 0.998698\n",
      "Epoch 55/100, Loss: 0.004422, Train Accuracy: 0.998725, Validation Accuracy: 0.816900\n",
      "Epoch [56/100], Step [100/1250], Loss: 0.000398, Train Accuracy: 1.000000\n",
      "Epoch [56/100], Step [200/1250], Loss: 0.000838, Train Accuracy: 0.999844\n",
      "Epoch [56/100], Step [300/1250], Loss: 0.011139, Train Accuracy: 0.999375\n",
      "Epoch [56/100], Step [400/1250], Loss: 0.000132, Train Accuracy: 0.999297\n",
      "Epoch [56/100], Step [500/1250], Loss: 0.000156, Train Accuracy: 0.999188\n",
      "Epoch [56/100], Step [600/1250], Loss: 0.010987, Train Accuracy: 0.999271\n",
      "Epoch [56/100], Step [700/1250], Loss: 0.000066, Train Accuracy: 0.999286\n",
      "Epoch [56/100], Step [800/1250], Loss: 0.000487, Train Accuracy: 0.999375\n",
      "Epoch [56/100], Step [900/1250], Loss: 0.000512, Train Accuracy: 0.999410\n",
      "Epoch [56/100], Step [1000/1250], Loss: 0.000143, Train Accuracy: 0.999437\n",
      "Epoch [56/100], Step [1100/1250], Loss: 0.000187, Train Accuracy: 0.999375\n",
      "Epoch [56/100], Step [1200/1250], Loss: 0.000919, Train Accuracy: 0.999323\n",
      "Epoch 56/100, Loss: 0.002475, Train Accuracy: 0.999350, Validation Accuracy: 0.818900\n",
      "Epoch [57/100], Step [100/1250], Loss: 0.000195, Train Accuracy: 0.999687\n",
      "Epoch [57/100], Step [200/1250], Loss: 0.077007, Train Accuracy: 0.999531\n",
      "Epoch [57/100], Step [300/1250], Loss: 0.000129, Train Accuracy: 0.999583\n",
      "Epoch [57/100], Step [400/1250], Loss: 0.000350, Train Accuracy: 0.999375\n",
      "Epoch [57/100], Step [500/1250], Loss: 0.000122, Train Accuracy: 0.999437\n",
      "Epoch [57/100], Step [600/1250], Loss: 0.000849, Train Accuracy: 0.999375\n",
      "Epoch [57/100], Step [700/1250], Loss: 0.003125, Train Accuracy: 0.999330\n",
      "Epoch [57/100], Step [800/1250], Loss: 0.000098, Train Accuracy: 0.999023\n",
      "Epoch [57/100], Step [900/1250], Loss: 0.033391, Train Accuracy: 0.998611\n",
      "Epoch [57/100], Step [1000/1250], Loss: 0.000389, Train Accuracy: 0.998531\n",
      "Epoch [57/100], Step [1100/1250], Loss: 0.002304, Train Accuracy: 0.998608\n",
      "Epoch [57/100], Step [1200/1250], Loss: 0.000534, Train Accuracy: 0.998646\n",
      "Epoch 57/100, Loss: 0.004221, Train Accuracy: 0.998625, Validation Accuracy: 0.817100\n",
      "Epoch [58/100], Step [100/1250], Loss: 0.016563, Train Accuracy: 0.999062\n",
      "Epoch [58/100], Step [200/1250], Loss: 0.000184, Train Accuracy: 0.999375\n",
      "Epoch [58/100], Step [300/1250], Loss: 0.002717, Train Accuracy: 0.998750\n",
      "Epoch [58/100], Step [400/1250], Loss: 0.000566, Train Accuracy: 0.998672\n",
      "Epoch [58/100], Step [500/1250], Loss: 0.000778, Train Accuracy: 0.998625\n",
      "Epoch [58/100], Step [600/1250], Loss: 0.000123, Train Accuracy: 0.998750\n",
      "Epoch [58/100], Step [700/1250], Loss: 0.000547, Train Accuracy: 0.998750\n",
      "Epoch [58/100], Step [800/1250], Loss: 0.000061, Train Accuracy: 0.998672\n",
      "Epoch [58/100], Step [900/1250], Loss: 0.000160, Train Accuracy: 0.998576\n",
      "Epoch [58/100], Step [1000/1250], Loss: 0.007164, Train Accuracy: 0.998594\n",
      "Epoch [58/100], Step [1100/1250], Loss: 0.000099, Train Accuracy: 0.998665\n",
      "Epoch [58/100], Step [1200/1250], Loss: 0.000310, Train Accuracy: 0.998646\n",
      "Epoch 58/100, Loss: 0.004554, Train Accuracy: 0.998650, Validation Accuracy: 0.816600\n",
      "Epoch [59/100], Step [100/1250], Loss: 0.001991, Train Accuracy: 1.000000\n",
      "Epoch [59/100], Step [200/1250], Loss: 0.000413, Train Accuracy: 1.000000\n",
      "Epoch [59/100], Step [300/1250], Loss: 0.000229, Train Accuracy: 0.999896\n",
      "Epoch [59/100], Step [400/1250], Loss: 0.002216, Train Accuracy: 0.999766\n",
      "Epoch [59/100], Step [500/1250], Loss: 0.000875, Train Accuracy: 0.999625\n",
      "Epoch [59/100], Step [600/1250], Loss: 0.000500, Train Accuracy: 0.999271\n",
      "Epoch [59/100], Step [700/1250], Loss: 0.000123, Train Accuracy: 0.999062\n",
      "Epoch [59/100], Step [800/1250], Loss: 0.000476, Train Accuracy: 0.998906\n",
      "Epoch [59/100], Step [900/1250], Loss: 0.001504, Train Accuracy: 0.998854\n",
      "Epoch [59/100], Step [1000/1250], Loss: 0.057211, Train Accuracy: 0.998719\n",
      "Epoch [59/100], Step [1100/1250], Loss: 0.000280, Train Accuracy: 0.998551\n",
      "Epoch [59/100], Step [1200/1250], Loss: 0.000523, Train Accuracy: 0.998437\n",
      "Epoch 59/100, Loss: 0.005058, Train Accuracy: 0.998450, Validation Accuracy: 0.816200\n",
      "Epoch [60/100], Step [100/1250], Loss: 0.000258, Train Accuracy: 0.999375\n",
      "Epoch [60/100], Step [200/1250], Loss: 0.000437, Train Accuracy: 0.998594\n",
      "Epoch [60/100], Step [300/1250], Loss: 0.000918, Train Accuracy: 0.998542\n",
      "Epoch [60/100], Step [400/1250], Loss: 0.000376, Train Accuracy: 0.998672\n",
      "Epoch [60/100], Step [500/1250], Loss: 0.000540, Train Accuracy: 0.998812\n",
      "Epoch [60/100], Step [600/1250], Loss: 0.000267, Train Accuracy: 0.998854\n",
      "Epoch [60/100], Step [700/1250], Loss: 0.000473, Train Accuracy: 0.998795\n",
      "Epoch [60/100], Step [800/1250], Loss: 0.000297, Train Accuracy: 0.998789\n",
      "Epoch [60/100], Step [900/1250], Loss: 0.000642, Train Accuracy: 0.998819\n",
      "Epoch [60/100], Step [1000/1250], Loss: 0.000248, Train Accuracy: 0.998531\n",
      "Epoch [60/100], Step [1100/1250], Loss: 0.000172, Train Accuracy: 0.998381\n",
      "Epoch [60/100], Step [1200/1250], Loss: 0.000290, Train Accuracy: 0.998333\n",
      "Epoch 60/100, Loss: 0.005440, Train Accuracy: 0.998275, Validation Accuracy: 0.807300\n",
      "Epoch [61/100], Step [100/1250], Loss: 0.000178, Train Accuracy: 0.999375\n",
      "Epoch [61/100], Step [200/1250], Loss: 0.001321, Train Accuracy: 0.999219\n",
      "Epoch [61/100], Step [300/1250], Loss: 0.003296, Train Accuracy: 0.999375\n",
      "Epoch [61/100], Step [400/1250], Loss: 0.000037, Train Accuracy: 0.999531\n",
      "Epoch [61/100], Step [500/1250], Loss: 0.000122, Train Accuracy: 0.999437\n",
      "Epoch [61/100], Step [600/1250], Loss: 0.000585, Train Accuracy: 0.999375\n",
      "Epoch [61/100], Step [700/1250], Loss: 0.000059, Train Accuracy: 0.999286\n",
      "Epoch [61/100], Step [800/1250], Loss: 0.008585, Train Accuracy: 0.999102\n",
      "Epoch [61/100], Step [900/1250], Loss: 0.000228, Train Accuracy: 0.998958\n",
      "Epoch [61/100], Step [1000/1250], Loss: 0.002908, Train Accuracy: 0.998969\n",
      "Epoch [61/100], Step [1100/1250], Loss: 0.000128, Train Accuracy: 0.998835\n",
      "Epoch [61/100], Step [1200/1250], Loss: 0.000227, Train Accuracy: 0.998854\n",
      "Epoch 61/100, Loss: 0.003894, Train Accuracy: 0.998850, Validation Accuracy: 0.814100\n",
      "Epoch [62/100], Step [100/1250], Loss: 0.000269, Train Accuracy: 0.998125\n",
      "Epoch [62/100], Step [200/1250], Loss: 0.000341, Train Accuracy: 0.997969\n",
      "Epoch [62/100], Step [300/1250], Loss: 0.002600, Train Accuracy: 0.998229\n",
      "Epoch [62/100], Step [400/1250], Loss: 0.000637, Train Accuracy: 0.998203\n",
      "Epoch [62/100], Step [500/1250], Loss: 0.000150, Train Accuracy: 0.998125\n",
      "Epoch [62/100], Step [600/1250], Loss: 0.005157, Train Accuracy: 0.998021\n",
      "Epoch [62/100], Step [700/1250], Loss: 0.000676, Train Accuracy: 0.998170\n",
      "Epoch [62/100], Step [800/1250], Loss: 0.000819, Train Accuracy: 0.998125\n",
      "Epoch [62/100], Step [900/1250], Loss: 0.000089, Train Accuracy: 0.998229\n",
      "Epoch [62/100], Step [1000/1250], Loss: 0.001314, Train Accuracy: 0.998219\n",
      "Epoch [62/100], Step [1100/1250], Loss: 0.001973, Train Accuracy: 0.998239\n",
      "Epoch [62/100], Step [1200/1250], Loss: 0.019725, Train Accuracy: 0.998281\n",
      "Epoch 62/100, Loss: 0.006260, Train Accuracy: 0.998225, Validation Accuracy: 0.814400\n",
      "Epoch [63/100], Step [100/1250], Loss: 0.000260, Train Accuracy: 0.999062\n",
      "Epoch [63/100], Step [200/1250], Loss: 0.000140, Train Accuracy: 0.999219\n",
      "Epoch [63/100], Step [300/1250], Loss: 0.000107, Train Accuracy: 0.999062\n",
      "Epoch [63/100], Step [400/1250], Loss: 0.009630, Train Accuracy: 0.999141\n",
      "Epoch [63/100], Step [500/1250], Loss: 0.003324, Train Accuracy: 0.999188\n",
      "Epoch [63/100], Step [600/1250], Loss: 0.003490, Train Accuracy: 0.999115\n",
      "Epoch [63/100], Step [700/1250], Loss: 0.005714, Train Accuracy: 0.998973\n",
      "Epoch [63/100], Step [800/1250], Loss: 0.000944, Train Accuracy: 0.998828\n",
      "Epoch [63/100], Step [900/1250], Loss: 0.002940, Train Accuracy: 0.998854\n",
      "Epoch [63/100], Step [1000/1250], Loss: 0.000406, Train Accuracy: 0.998875\n",
      "Epoch [63/100], Step [1100/1250], Loss: 0.000076, Train Accuracy: 0.998892\n",
      "Epoch [63/100], Step [1200/1250], Loss: 0.000147, Train Accuracy: 0.998880\n",
      "Epoch 63/100, Loss: 0.004868, Train Accuracy: 0.998850, Validation Accuracy: 0.820800\n",
      "Epoch [64/100], Step [100/1250], Loss: 0.000176, Train Accuracy: 1.000000\n",
      "Epoch [64/100], Step [200/1250], Loss: 0.000081, Train Accuracy: 0.999062\n",
      "Epoch [64/100], Step [300/1250], Loss: 0.001435, Train Accuracy: 0.998854\n",
      "Epoch [64/100], Step [400/1250], Loss: 0.000320, Train Accuracy: 0.998672\n",
      "Epoch [64/100], Step [500/1250], Loss: 0.000060, Train Accuracy: 0.998938\n",
      "Epoch [64/100], Step [600/1250], Loss: 0.001008, Train Accuracy: 0.999010\n",
      "Epoch [64/100], Step [700/1250], Loss: 0.000866, Train Accuracy: 0.999018\n",
      "Epoch [64/100], Step [800/1250], Loss: 0.014423, Train Accuracy: 0.999102\n",
      "Epoch [64/100], Step [900/1250], Loss: 0.013597, Train Accuracy: 0.999062\n",
      "Epoch [64/100], Step [1000/1250], Loss: 0.000487, Train Accuracy: 0.999094\n",
      "Epoch [64/100], Step [1100/1250], Loss: 0.000318, Train Accuracy: 0.999148\n",
      "Epoch [64/100], Step [1200/1250], Loss: 0.000160, Train Accuracy: 0.999167\n",
      "Epoch 64/100, Loss: 0.002797, Train Accuracy: 0.999150, Validation Accuracy: 0.818500\n",
      "Epoch [65/100], Step [100/1250], Loss: 0.000151, Train Accuracy: 0.997812\n",
      "Epoch [65/100], Step [200/1250], Loss: 0.000158, Train Accuracy: 0.998281\n",
      "Epoch [65/100], Step [300/1250], Loss: 0.010850, Train Accuracy: 0.998437\n",
      "Epoch [65/100], Step [400/1250], Loss: 0.000632, Train Accuracy: 0.998672\n",
      "Epoch [65/100], Step [500/1250], Loss: 0.000309, Train Accuracy: 0.998563\n",
      "Epoch [65/100], Step [600/1250], Loss: 0.000382, Train Accuracy: 0.998698\n",
      "Epoch [65/100], Step [700/1250], Loss: 0.000049, Train Accuracy: 0.998750\n",
      "Epoch [65/100], Step [800/1250], Loss: 0.000783, Train Accuracy: 0.998828\n",
      "Epoch [65/100], Step [900/1250], Loss: 0.002226, Train Accuracy: 0.998611\n",
      "Epoch [65/100], Step [1000/1250], Loss: 0.008839, Train Accuracy: 0.998469\n",
      "Epoch [65/100], Step [1100/1250], Loss: 0.002748, Train Accuracy: 0.998437\n",
      "Epoch [65/100], Step [1200/1250], Loss: 0.000214, Train Accuracy: 0.998490\n",
      "Epoch 65/100, Loss: 0.004601, Train Accuracy: 0.998550, Validation Accuracy: 0.816200\n",
      "Epoch [66/100], Step [100/1250], Loss: 0.000311, Train Accuracy: 0.999687\n",
      "Epoch [66/100], Step [200/1250], Loss: 0.000077, Train Accuracy: 0.999687\n",
      "Epoch [66/100], Step [300/1250], Loss: 0.000131, Train Accuracy: 0.999583\n",
      "Epoch [66/100], Step [400/1250], Loss: 0.009727, Train Accuracy: 0.999375\n",
      "Epoch [66/100], Step [500/1250], Loss: 0.000121, Train Accuracy: 0.999437\n",
      "Epoch [66/100], Step [600/1250], Loss: 0.007486, Train Accuracy: 0.999427\n",
      "Epoch [66/100], Step [700/1250], Loss: 0.000259, Train Accuracy: 0.999375\n",
      "Epoch [66/100], Step [800/1250], Loss: 0.000238, Train Accuracy: 0.999414\n",
      "Epoch [66/100], Step [900/1250], Loss: 0.000057, Train Accuracy: 0.999375\n",
      "Epoch [66/100], Step [1000/1250], Loss: 0.004045, Train Accuracy: 0.999313\n",
      "Epoch [66/100], Step [1100/1250], Loss: 0.000077, Train Accuracy: 0.999318\n",
      "Epoch [66/100], Step [1200/1250], Loss: 0.000116, Train Accuracy: 0.999245\n",
      "Epoch 66/100, Loss: 0.002707, Train Accuracy: 0.999200, Validation Accuracy: 0.818600\n",
      "Epoch [67/100], Step [100/1250], Loss: 0.000106, Train Accuracy: 0.999687\n",
      "Epoch [67/100], Step [200/1250], Loss: 0.000057, Train Accuracy: 0.999687\n",
      "Epoch [67/100], Step [300/1250], Loss: 0.000090, Train Accuracy: 0.999583\n",
      "Epoch [67/100], Step [400/1250], Loss: 0.001935, Train Accuracy: 0.999687\n",
      "Epoch [67/100], Step [500/1250], Loss: 0.000074, Train Accuracy: 0.999625\n",
      "Epoch [67/100], Step [600/1250], Loss: 0.000111, Train Accuracy: 0.999635\n",
      "Epoch [67/100], Step [700/1250], Loss: 0.000284, Train Accuracy: 0.999330\n",
      "Epoch [67/100], Step [800/1250], Loss: 0.000075, Train Accuracy: 0.999102\n",
      "Epoch [67/100], Step [900/1250], Loss: 0.000813, Train Accuracy: 0.998958\n",
      "Epoch [67/100], Step [1000/1250], Loss: 0.003122, Train Accuracy: 0.998875\n",
      "Epoch [67/100], Step [1100/1250], Loss: 0.000248, Train Accuracy: 0.998864\n",
      "Epoch [67/100], Step [1200/1250], Loss: 0.000258, Train Accuracy: 0.998854\n",
      "Epoch 67/100, Loss: 0.003497, Train Accuracy: 0.998900, Validation Accuracy: 0.818000\n",
      "Epoch [68/100], Step [100/1250], Loss: 0.000732, Train Accuracy: 0.999375\n",
      "Epoch [68/100], Step [200/1250], Loss: 0.000206, Train Accuracy: 0.999219\n",
      "Epoch [68/100], Step [300/1250], Loss: 0.000180, Train Accuracy: 0.999167\n",
      "Epoch [68/100], Step [400/1250], Loss: 0.000151, Train Accuracy: 0.998828\n",
      "Epoch [68/100], Step [500/1250], Loss: 0.000167, Train Accuracy: 0.998875\n",
      "Epoch [68/100], Step [600/1250], Loss: 0.000609, Train Accuracy: 0.998802\n",
      "Epoch [68/100], Step [700/1250], Loss: 0.000139, Train Accuracy: 0.998705\n",
      "Epoch [68/100], Step [800/1250], Loss: 0.000165, Train Accuracy: 0.998750\n",
      "Epoch [68/100], Step [900/1250], Loss: 0.000280, Train Accuracy: 0.998750\n",
      "Epoch [68/100], Step [1000/1250], Loss: 0.000343, Train Accuracy: 0.998750\n",
      "Epoch [68/100], Step [1100/1250], Loss: 0.000165, Train Accuracy: 0.998835\n",
      "Epoch [68/100], Step [1200/1250], Loss: 0.011596, Train Accuracy: 0.998828\n",
      "Epoch 68/100, Loss: 0.003679, Train Accuracy: 0.998875, Validation Accuracy: 0.819600\n",
      "Epoch [69/100], Step [100/1250], Loss: 0.000065, Train Accuracy: 1.000000\n",
      "Epoch [69/100], Step [200/1250], Loss: 0.000399, Train Accuracy: 1.000000\n",
      "Epoch [69/100], Step [300/1250], Loss: 0.000077, Train Accuracy: 0.999792\n",
      "Epoch [69/100], Step [400/1250], Loss: 0.003519, Train Accuracy: 0.999453\n",
      "Epoch [69/100], Step [500/1250], Loss: 0.000346, Train Accuracy: 0.999375\n",
      "Epoch [69/100], Step [600/1250], Loss: 0.000477, Train Accuracy: 0.999271\n",
      "Epoch [69/100], Step [700/1250], Loss: 0.000324, Train Accuracy: 0.999018\n",
      "Epoch [69/100], Step [800/1250], Loss: 0.002606, Train Accuracy: 0.998984\n",
      "Epoch [69/100], Step [900/1250], Loss: 0.000069, Train Accuracy: 0.998819\n",
      "Epoch [69/100], Step [1000/1250], Loss: 0.000556, Train Accuracy: 0.998875\n",
      "Epoch [69/100], Step [1100/1250], Loss: 0.023524, Train Accuracy: 0.998864\n",
      "Epoch [69/100], Step [1200/1250], Loss: 0.000645, Train Accuracy: 0.998776\n",
      "Epoch 69/100, Loss: 0.004273, Train Accuracy: 0.998800, Validation Accuracy: 0.817400\n",
      "Epoch [70/100], Step [100/1250], Loss: 0.001477, Train Accuracy: 0.999687\n",
      "Epoch [70/100], Step [200/1250], Loss: 0.000087, Train Accuracy: 0.999219\n",
      "Epoch [70/100], Step [300/1250], Loss: 0.000649, Train Accuracy: 0.999167\n",
      "Epoch [70/100], Step [400/1250], Loss: 0.000394, Train Accuracy: 0.999219\n",
      "Epoch [70/100], Step [500/1250], Loss: 0.000508, Train Accuracy: 0.999188\n",
      "Epoch [70/100], Step [600/1250], Loss: 0.005064, Train Accuracy: 0.999271\n",
      "Epoch [70/100], Step [700/1250], Loss: 0.000092, Train Accuracy: 0.999152\n",
      "Epoch [70/100], Step [800/1250], Loss: 0.005441, Train Accuracy: 0.998750\n",
      "Epoch [70/100], Step [900/1250], Loss: 0.000153, Train Accuracy: 0.998819\n",
      "Epoch [70/100], Step [1000/1250], Loss: 0.000132, Train Accuracy: 0.998719\n",
      "Epoch [70/100], Step [1100/1250], Loss: 0.000117, Train Accuracy: 0.998693\n",
      "Epoch [70/100], Step [1200/1250], Loss: 0.000657, Train Accuracy: 0.998750\n",
      "Epoch 70/100, Loss: 0.004409, Train Accuracy: 0.998700, Validation Accuracy: 0.811900\n",
      "Epoch [71/100], Step [100/1250], Loss: 0.000326, Train Accuracy: 0.998750\n",
      "Epoch [71/100], Step [200/1250], Loss: 0.000587, Train Accuracy: 0.998594\n",
      "Epoch [71/100], Step [300/1250], Loss: 0.002253, Train Accuracy: 0.998750\n",
      "Epoch [71/100], Step [400/1250], Loss: 0.000026, Train Accuracy: 0.998984\n",
      "Epoch [71/100], Step [500/1250], Loss: 0.034117, Train Accuracy: 0.998563\n",
      "Epoch [71/100], Step [600/1250], Loss: 0.000462, Train Accuracy: 0.998437\n",
      "Epoch [71/100], Step [700/1250], Loss: 0.003224, Train Accuracy: 0.998304\n",
      "Epoch [71/100], Step [800/1250], Loss: 0.000369, Train Accuracy: 0.998281\n",
      "Epoch [71/100], Step [900/1250], Loss: 0.001613, Train Accuracy: 0.998264\n",
      "Epoch [71/100], Step [1000/1250], Loss: 0.000109, Train Accuracy: 0.998250\n",
      "Epoch [71/100], Step [1100/1250], Loss: 0.004219, Train Accuracy: 0.998324\n",
      "Epoch [71/100], Step [1200/1250], Loss: 0.000658, Train Accuracy: 0.998333\n",
      "Epoch 71/100, Loss: 0.005123, Train Accuracy: 0.998350, Validation Accuracy: 0.819600\n",
      "Epoch [72/100], Step [100/1250], Loss: 0.000271, Train Accuracy: 0.998750\n",
      "Epoch [72/100], Step [200/1250], Loss: 0.000290, Train Accuracy: 0.998125\n",
      "Epoch [72/100], Step [300/1250], Loss: 0.000968, Train Accuracy: 0.998021\n",
      "Epoch [72/100], Step [400/1250], Loss: 0.001765, Train Accuracy: 0.998125\n",
      "Epoch [72/100], Step [500/1250], Loss: 0.000406, Train Accuracy: 0.998313\n",
      "Epoch [72/100], Step [600/1250], Loss: 0.000482, Train Accuracy: 0.998229\n",
      "Epoch [72/100], Step [700/1250], Loss: 0.000075, Train Accuracy: 0.998482\n",
      "Epoch [72/100], Step [800/1250], Loss: 0.000075, Train Accuracy: 0.998477\n",
      "Epoch [72/100], Step [900/1250], Loss: 0.000098, Train Accuracy: 0.998611\n",
      "Epoch [72/100], Step [1000/1250], Loss: 0.000548, Train Accuracy: 0.998594\n",
      "Epoch [72/100], Step [1100/1250], Loss: 0.000405, Train Accuracy: 0.998636\n",
      "Epoch [72/100], Step [1200/1250], Loss: 0.000075, Train Accuracy: 0.998672\n",
      "Epoch 72/100, Loss: 0.004094, Train Accuracy: 0.998700, Validation Accuracy: 0.819100\n",
      "Epoch [73/100], Step [100/1250], Loss: 0.033370, Train Accuracy: 0.998750\n",
      "Epoch [73/100], Step [200/1250], Loss: 0.000047, Train Accuracy: 0.998437\n",
      "Epoch [73/100], Step [300/1250], Loss: 0.000559, Train Accuracy: 0.998542\n",
      "Epoch [73/100], Step [400/1250], Loss: 0.029249, Train Accuracy: 0.998594\n",
      "Epoch [73/100], Step [500/1250], Loss: 0.001281, Train Accuracy: 0.998375\n",
      "Epoch [73/100], Step [600/1250], Loss: 0.001027, Train Accuracy: 0.998333\n",
      "Epoch [73/100], Step [700/1250], Loss: 0.000268, Train Accuracy: 0.998304\n",
      "Epoch [73/100], Step [800/1250], Loss: 0.000166, Train Accuracy: 0.998437\n",
      "Epoch [73/100], Step [900/1250], Loss: 0.010110, Train Accuracy: 0.998472\n",
      "Epoch [73/100], Step [1000/1250], Loss: 0.004437, Train Accuracy: 0.998469\n",
      "Epoch [73/100], Step [1100/1250], Loss: 0.000212, Train Accuracy: 0.998381\n",
      "Epoch [73/100], Step [1200/1250], Loss: 0.000073, Train Accuracy: 0.998516\n",
      "Epoch 73/100, Loss: 0.004764, Train Accuracy: 0.998525, Validation Accuracy: 0.817400\n",
      "Epoch [74/100], Step [100/1250], Loss: 0.003295, Train Accuracy: 0.999375\n",
      "Epoch [74/100], Step [200/1250], Loss: 0.000168, Train Accuracy: 0.999531\n",
      "Epoch [74/100], Step [300/1250], Loss: 0.000347, Train Accuracy: 0.999167\n",
      "Epoch [74/100], Step [400/1250], Loss: 0.000086, Train Accuracy: 0.998984\n",
      "Epoch [74/100], Step [500/1250], Loss: 0.000119, Train Accuracy: 0.998687\n",
      "Epoch [74/100], Step [600/1250], Loss: 0.000142, Train Accuracy: 0.998542\n",
      "Epoch [74/100], Step [700/1250], Loss: 0.046497, Train Accuracy: 0.998482\n",
      "Epoch [74/100], Step [800/1250], Loss: 0.001700, Train Accuracy: 0.998516\n",
      "Epoch [74/100], Step [900/1250], Loss: 0.086592, Train Accuracy: 0.998437\n",
      "Epoch [74/100], Step [1000/1250], Loss: 0.108920, Train Accuracy: 0.998406\n",
      "Epoch [74/100], Step [1100/1250], Loss: 0.000077, Train Accuracy: 0.998409\n",
      "Epoch [74/100], Step [1200/1250], Loss: 0.000420, Train Accuracy: 0.998333\n",
      "Epoch 74/100, Loss: 0.004765, Train Accuracy: 0.998325, Validation Accuracy: 0.812000\n",
      "Epoch [75/100], Step [100/1250], Loss: 0.000153, Train Accuracy: 0.998437\n",
      "Epoch [75/100], Step [200/1250], Loss: 0.013256, Train Accuracy: 0.998437\n",
      "Epoch [75/100], Step [300/1250], Loss: 0.000950, Train Accuracy: 0.998021\n",
      "Epoch [75/100], Step [400/1250], Loss: 0.003061, Train Accuracy: 0.997891\n",
      "Epoch [75/100], Step [500/1250], Loss: 0.000266, Train Accuracy: 0.998250\n",
      "Epoch [75/100], Step [600/1250], Loss: 0.000230, Train Accuracy: 0.998437\n",
      "Epoch [75/100], Step [700/1250], Loss: 0.000441, Train Accuracy: 0.998437\n",
      "Epoch [75/100], Step [800/1250], Loss: 0.000090, Train Accuracy: 0.998398\n",
      "Epoch [75/100], Step [900/1250], Loss: 0.000457, Train Accuracy: 0.998542\n",
      "Epoch [75/100], Step [1000/1250], Loss: 0.000786, Train Accuracy: 0.998594\n",
      "Epoch [75/100], Step [1100/1250], Loss: 0.000746, Train Accuracy: 0.998608\n",
      "Epoch [75/100], Step [1200/1250], Loss: 0.000343, Train Accuracy: 0.998568\n",
      "Epoch 75/100, Loss: 0.004458, Train Accuracy: 0.998600, Validation Accuracy: 0.816200\n",
      "Epoch [76/100], Step [100/1250], Loss: 0.000380, Train Accuracy: 0.999062\n",
      "Epoch [76/100], Step [200/1250], Loss: 0.000195, Train Accuracy: 0.999375\n",
      "Epoch [76/100], Step [300/1250], Loss: 0.020617, Train Accuracy: 0.999583\n",
      "Epoch [76/100], Step [400/1250], Loss: 0.000090, Train Accuracy: 0.999531\n",
      "Epoch [76/100], Step [500/1250], Loss: 0.000205, Train Accuracy: 0.999375\n",
      "Epoch [76/100], Step [600/1250], Loss: 0.000622, Train Accuracy: 0.999323\n",
      "Epoch [76/100], Step [700/1250], Loss: 0.000480, Train Accuracy: 0.998929\n",
      "Epoch [76/100], Step [800/1250], Loss: 0.000509, Train Accuracy: 0.998789\n",
      "Epoch [76/100], Step [900/1250], Loss: 0.000095, Train Accuracy: 0.998785\n",
      "Epoch [76/100], Step [1000/1250], Loss: 0.007970, Train Accuracy: 0.998844\n",
      "Epoch [76/100], Step [1100/1250], Loss: 0.023029, Train Accuracy: 0.998920\n",
      "Epoch [76/100], Step [1200/1250], Loss: 0.011525, Train Accuracy: 0.998984\n",
      "Epoch 76/100, Loss: 0.003426, Train Accuracy: 0.998975, Validation Accuracy: 0.817700\n",
      "Epoch [77/100], Step [100/1250], Loss: 0.000149, Train Accuracy: 1.000000\n",
      "Epoch [77/100], Step [200/1250], Loss: 0.000841, Train Accuracy: 0.999844\n",
      "Epoch [77/100], Step [300/1250], Loss: 0.000169, Train Accuracy: 0.999271\n",
      "Epoch [77/100], Step [400/1250], Loss: 0.000734, Train Accuracy: 0.999375\n",
      "Epoch [77/100], Step [500/1250], Loss: 0.000190, Train Accuracy: 0.999250\n",
      "Epoch [77/100], Step [600/1250], Loss: 0.032731, Train Accuracy: 0.999219\n",
      "Epoch [77/100], Step [700/1250], Loss: 0.000289, Train Accuracy: 0.999330\n",
      "Epoch [77/100], Step [800/1250], Loss: 0.000291, Train Accuracy: 0.999219\n",
      "Epoch [77/100], Step [900/1250], Loss: 0.000082, Train Accuracy: 0.999236\n",
      "Epoch [77/100], Step [1000/1250], Loss: 0.000329, Train Accuracy: 0.999094\n",
      "Epoch [77/100], Step [1100/1250], Loss: 0.072018, Train Accuracy: 0.999091\n",
      "Epoch [77/100], Step [1200/1250], Loss: 0.000071, Train Accuracy: 0.999089\n",
      "Epoch 77/100, Loss: 0.003040, Train Accuracy: 0.999075, Validation Accuracy: 0.812100\n",
      "Epoch [78/100], Step [100/1250], Loss: 0.000149, Train Accuracy: 0.999375\n",
      "Epoch [78/100], Step [200/1250], Loss: 0.000208, Train Accuracy: 0.999062\n",
      "Epoch [78/100], Step [300/1250], Loss: 0.002102, Train Accuracy: 0.999375\n",
      "Epoch [78/100], Step [400/1250], Loss: 0.000803, Train Accuracy: 0.999531\n",
      "Epoch [78/100], Step [500/1250], Loss: 0.000909, Train Accuracy: 0.999500\n",
      "Epoch [78/100], Step [600/1250], Loss: 0.000207, Train Accuracy: 0.999427\n",
      "Epoch [78/100], Step [700/1250], Loss: 0.005945, Train Accuracy: 0.999420\n",
      "Epoch [78/100], Step [800/1250], Loss: 0.000196, Train Accuracy: 0.999492\n",
      "Epoch [78/100], Step [900/1250], Loss: 0.077287, Train Accuracy: 0.999444\n",
      "Epoch [78/100], Step [1000/1250], Loss: 0.000054, Train Accuracy: 0.999469\n",
      "Epoch [78/100], Step [1100/1250], Loss: 0.000181, Train Accuracy: 0.999432\n",
      "Epoch [78/100], Step [1200/1250], Loss: 0.000076, Train Accuracy: 0.999401\n",
      "Epoch 78/100, Loss: 0.002144, Train Accuracy: 0.999350, Validation Accuracy: 0.814100\n",
      "Epoch [79/100], Step [100/1250], Loss: 0.000989, Train Accuracy: 0.998750\n",
      "Epoch [79/100], Step [200/1250], Loss: 0.000233, Train Accuracy: 0.998594\n",
      "Epoch [79/100], Step [300/1250], Loss: 0.000549, Train Accuracy: 0.998750\n",
      "Epoch [79/100], Step [400/1250], Loss: 0.000148, Train Accuracy: 0.998984\n",
      "Epoch [79/100], Step [500/1250], Loss: 0.000048, Train Accuracy: 0.999125\n",
      "Epoch [79/100], Step [600/1250], Loss: 0.000293, Train Accuracy: 0.999062\n",
      "Epoch [79/100], Step [700/1250], Loss: 0.000070, Train Accuracy: 0.999152\n",
      "Epoch [79/100], Step [800/1250], Loss: 0.000555, Train Accuracy: 0.999219\n",
      "Epoch [79/100], Step [900/1250], Loss: 0.095680, Train Accuracy: 0.999236\n",
      "Epoch [79/100], Step [1000/1250], Loss: 0.000399, Train Accuracy: 0.999250\n",
      "Epoch [79/100], Step [1100/1250], Loss: 0.000336, Train Accuracy: 0.999318\n",
      "Epoch [79/100], Step [1200/1250], Loss: 0.000073, Train Accuracy: 0.999349\n",
      "Epoch 79/100, Loss: 0.002409, Train Accuracy: 0.999350, Validation Accuracy: 0.819800\n",
      "Epoch [80/100], Step [100/1250], Loss: 0.000200, Train Accuracy: 0.999062\n",
      "Epoch [80/100], Step [200/1250], Loss: 0.000283, Train Accuracy: 0.999375\n",
      "Epoch [80/100], Step [300/1250], Loss: 0.000197, Train Accuracy: 0.999271\n",
      "Epoch [80/100], Step [400/1250], Loss: 0.000080, Train Accuracy: 0.999375\n",
      "Epoch [80/100], Step [500/1250], Loss: 0.000193, Train Accuracy: 0.999437\n",
      "Epoch [80/100], Step [600/1250], Loss: 0.001851, Train Accuracy: 0.999375\n",
      "Epoch [80/100], Step [700/1250], Loss: 0.000025, Train Accuracy: 0.999330\n",
      "Epoch [80/100], Step [800/1250], Loss: 0.003845, Train Accuracy: 0.999258\n",
      "Epoch [80/100], Step [900/1250], Loss: 0.000213, Train Accuracy: 0.999201\n",
      "Epoch [80/100], Step [1000/1250], Loss: 0.001808, Train Accuracy: 0.999125\n",
      "Epoch [80/100], Step [1100/1250], Loss: 0.000331, Train Accuracy: 0.999148\n",
      "Epoch [80/100], Step [1200/1250], Loss: 0.000116, Train Accuracy: 0.999089\n",
      "Epoch 80/100, Loss: 0.002758, Train Accuracy: 0.999125, Validation Accuracy: 0.816900\n",
      "Epoch [81/100], Step [100/1250], Loss: 0.000190, Train Accuracy: 0.999687\n",
      "Epoch [81/100], Step [200/1250], Loss: 0.000162, Train Accuracy: 0.999687\n",
      "Epoch [81/100], Step [300/1250], Loss: 0.000089, Train Accuracy: 0.999687\n",
      "Epoch [81/100], Step [400/1250], Loss: 0.086306, Train Accuracy: 0.999531\n",
      "Epoch [81/100], Step [500/1250], Loss: 0.000110, Train Accuracy: 0.999437\n",
      "Epoch [81/100], Step [600/1250], Loss: 0.000319, Train Accuracy: 0.999531\n",
      "Epoch [81/100], Step [700/1250], Loss: 0.000066, Train Accuracy: 0.999598\n",
      "Epoch [81/100], Step [800/1250], Loss: 0.000770, Train Accuracy: 0.999609\n",
      "Epoch [81/100], Step [900/1250], Loss: 0.000296, Train Accuracy: 0.999549\n",
      "Epoch [81/100], Step [1000/1250], Loss: 0.008282, Train Accuracy: 0.999531\n",
      "Epoch [81/100], Step [1100/1250], Loss: 0.000321, Train Accuracy: 0.999403\n",
      "Epoch [81/100], Step [1200/1250], Loss: 0.016231, Train Accuracy: 0.999297\n",
      "Epoch 81/100, Loss: 0.002824, Train Accuracy: 0.999250, Validation Accuracy: 0.812800\n",
      "Epoch [82/100], Step [100/1250], Loss: 0.000284, Train Accuracy: 1.000000\n",
      "Epoch [82/100], Step [200/1250], Loss: 0.000247, Train Accuracy: 0.999844\n",
      "Epoch [82/100], Step [300/1250], Loss: 0.000079, Train Accuracy: 0.999583\n",
      "Epoch [82/100], Step [400/1250], Loss: 0.000134, Train Accuracy: 0.999531\n",
      "Epoch [82/100], Step [500/1250], Loss: 0.000219, Train Accuracy: 0.999437\n",
      "Epoch [82/100], Step [600/1250], Loss: 0.000787, Train Accuracy: 0.999062\n",
      "Epoch [82/100], Step [700/1250], Loss: 0.000184, Train Accuracy: 0.999107\n",
      "Epoch [82/100], Step [800/1250], Loss: 0.000208, Train Accuracy: 0.999180\n",
      "Epoch [82/100], Step [900/1250], Loss: 0.001598, Train Accuracy: 0.999201\n",
      "Epoch [82/100], Step [1000/1250], Loss: 0.000045, Train Accuracy: 0.999281\n",
      "Epoch [82/100], Step [1100/1250], Loss: 0.017663, Train Accuracy: 0.999261\n",
      "Epoch [82/100], Step [1200/1250], Loss: 0.000116, Train Accuracy: 0.999219\n",
      "Epoch 82/100, Loss: 0.002904, Train Accuracy: 0.999200, Validation Accuracy: 0.818700\n",
      "Epoch [83/100], Step [100/1250], Loss: 0.000266, Train Accuracy: 1.000000\n",
      "Epoch [83/100], Step [200/1250], Loss: 0.000568, Train Accuracy: 0.999844\n",
      "Epoch [83/100], Step [300/1250], Loss: 0.000030, Train Accuracy: 0.999687\n",
      "Epoch [83/100], Step [400/1250], Loss: 0.000623, Train Accuracy: 0.999609\n",
      "Epoch [83/100], Step [500/1250], Loss: 0.000333, Train Accuracy: 0.999563\n",
      "Epoch [83/100], Step [600/1250], Loss: 0.010182, Train Accuracy: 0.999479\n",
      "Epoch [83/100], Step [700/1250], Loss: 0.000153, Train Accuracy: 0.999420\n",
      "Epoch [83/100], Step [800/1250], Loss: 0.000397, Train Accuracy: 0.999336\n",
      "Epoch [83/100], Step [900/1250], Loss: 0.000053, Train Accuracy: 0.999340\n",
      "Epoch [83/100], Step [1000/1250], Loss: 0.003419, Train Accuracy: 0.999375\n",
      "Epoch [83/100], Step [1100/1250], Loss: 0.001755, Train Accuracy: 0.999347\n",
      "Epoch [83/100], Step [1200/1250], Loss: 0.002943, Train Accuracy: 0.999245\n",
      "Epoch 83/100, Loss: 0.002844, Train Accuracy: 0.999250, Validation Accuracy: 0.817800\n",
      "Epoch [84/100], Step [100/1250], Loss: 0.000104, Train Accuracy: 0.999687\n",
      "Epoch [84/100], Step [200/1250], Loss: 0.002144, Train Accuracy: 0.999687\n",
      "Epoch [84/100], Step [300/1250], Loss: 0.000180, Train Accuracy: 0.999479\n",
      "Epoch [84/100], Step [400/1250], Loss: 0.001135, Train Accuracy: 0.999297\n",
      "Epoch [84/100], Step [500/1250], Loss: 0.001134, Train Accuracy: 0.999250\n",
      "Epoch [84/100], Step [600/1250], Loss: 0.006892, Train Accuracy: 0.999167\n",
      "Epoch [84/100], Step [700/1250], Loss: 0.000323, Train Accuracy: 0.999196\n",
      "Epoch [84/100], Step [800/1250], Loss: 0.000838, Train Accuracy: 0.999258\n",
      "Epoch [84/100], Step [900/1250], Loss: 0.000114, Train Accuracy: 0.999340\n",
      "Epoch [84/100], Step [1000/1250], Loss: 0.001056, Train Accuracy: 0.999344\n",
      "Epoch [84/100], Step [1100/1250], Loss: 0.000230, Train Accuracy: 0.999347\n",
      "Epoch [84/100], Step [1200/1250], Loss: 0.000135, Train Accuracy: 0.999271\n",
      "Epoch 84/100, Loss: 0.002929, Train Accuracy: 0.999225, Validation Accuracy: 0.820600\n",
      "Epoch [85/100], Step [100/1250], Loss: 0.000432, Train Accuracy: 0.999375\n",
      "Epoch [85/100], Step [200/1250], Loss: 0.000694, Train Accuracy: 0.999219\n",
      "Epoch [85/100], Step [300/1250], Loss: 0.003556, Train Accuracy: 0.999479\n",
      "Epoch [85/100], Step [400/1250], Loss: 0.001265, Train Accuracy: 0.999297\n",
      "Epoch [85/100], Step [500/1250], Loss: 0.000176, Train Accuracy: 0.999313\n",
      "Epoch [85/100], Step [600/1250], Loss: 0.000146, Train Accuracy: 0.999375\n",
      "Epoch [85/100], Step [700/1250], Loss: 0.000056, Train Accuracy: 0.999330\n",
      "Epoch [85/100], Step [800/1250], Loss: 0.000127, Train Accuracy: 0.999258\n",
      "Epoch [85/100], Step [900/1250], Loss: 0.000227, Train Accuracy: 0.999201\n",
      "Epoch [85/100], Step [1000/1250], Loss: 0.000039, Train Accuracy: 0.999156\n",
      "Epoch [85/100], Step [1100/1250], Loss: 0.007363, Train Accuracy: 0.999205\n",
      "Epoch [85/100], Step [1200/1250], Loss: 0.002805, Train Accuracy: 0.999167\n",
      "Epoch 85/100, Loss: 0.002625, Train Accuracy: 0.999200, Validation Accuracy: 0.816500\n",
      "Epoch [86/100], Step [100/1250], Loss: 0.111732, Train Accuracy: 0.998750\n",
      "Epoch [86/100], Step [200/1250], Loss: 0.039374, Train Accuracy: 0.998594\n",
      "Epoch [86/100], Step [300/1250], Loss: 0.004785, Train Accuracy: 0.998542\n",
      "Epoch [86/100], Step [400/1250], Loss: 0.000142, Train Accuracy: 0.998906\n",
      "Epoch [86/100], Step [500/1250], Loss: 0.000871, Train Accuracy: 0.999000\n",
      "Epoch [86/100], Step [600/1250], Loss: 0.000166, Train Accuracy: 0.999010\n",
      "Epoch [86/100], Step [700/1250], Loss: 0.000215, Train Accuracy: 0.998973\n",
      "Epoch [86/100], Step [800/1250], Loss: 0.000386, Train Accuracy: 0.998945\n",
      "Epoch [86/100], Step [900/1250], Loss: 0.000068, Train Accuracy: 0.998819\n",
      "Epoch [86/100], Step [1000/1250], Loss: 0.006560, Train Accuracy: 0.998875\n",
      "Epoch [86/100], Step [1100/1250], Loss: 0.000394, Train Accuracy: 0.998807\n",
      "Epoch [86/100], Step [1200/1250], Loss: 0.001027, Train Accuracy: 0.998750\n",
      "Epoch 86/100, Loss: 0.003999, Train Accuracy: 0.998775, Validation Accuracy: 0.815100\n",
      "Epoch [87/100], Step [100/1250], Loss: 0.000047, Train Accuracy: 0.999375\n",
      "Epoch [87/100], Step [200/1250], Loss: 0.000648, Train Accuracy: 0.999531\n",
      "Epoch [87/100], Step [300/1250], Loss: 0.000158, Train Accuracy: 0.999583\n",
      "Epoch [87/100], Step [400/1250], Loss: 0.000321, Train Accuracy: 0.999297\n",
      "Epoch [87/100], Step [500/1250], Loss: 0.000314, Train Accuracy: 0.999313\n",
      "Epoch [87/100], Step [600/1250], Loss: 0.000300, Train Accuracy: 0.999427\n",
      "Epoch [87/100], Step [700/1250], Loss: 0.024592, Train Accuracy: 0.999420\n",
      "Epoch [87/100], Step [800/1250], Loss: 0.000064, Train Accuracy: 0.999414\n",
      "Epoch [87/100], Step [900/1250], Loss: 0.000662, Train Accuracy: 0.999410\n",
      "Epoch [87/100], Step [1000/1250], Loss: 0.000189, Train Accuracy: 0.999344\n",
      "Epoch [87/100], Step [1100/1250], Loss: 0.000151, Train Accuracy: 0.999318\n",
      "Epoch [87/100], Step [1200/1250], Loss: 0.006003, Train Accuracy: 0.999323\n",
      "Epoch 87/100, Loss: 0.002251, Train Accuracy: 0.999325, Validation Accuracy: 0.818700\n",
      "Epoch [88/100], Step [100/1250], Loss: 0.000499, Train Accuracy: 0.999375\n",
      "Epoch [88/100], Step [200/1250], Loss: 0.000118, Train Accuracy: 0.999531\n",
      "Epoch [88/100], Step [300/1250], Loss: 0.001029, Train Accuracy: 0.999271\n",
      "Epoch [88/100], Step [400/1250], Loss: 0.000140, Train Accuracy: 0.999375\n",
      "Epoch [88/100], Step [500/1250], Loss: 0.007250, Train Accuracy: 0.999500\n",
      "Epoch [88/100], Step [600/1250], Loss: 0.000150, Train Accuracy: 0.999531\n",
      "Epoch [88/100], Step [700/1250], Loss: 0.000113, Train Accuracy: 0.999598\n",
      "Epoch [88/100], Step [800/1250], Loss: 0.000102, Train Accuracy: 0.999531\n",
      "Epoch [88/100], Step [900/1250], Loss: 0.015135, Train Accuracy: 0.999410\n",
      "Epoch [88/100], Step [1000/1250], Loss: 0.004168, Train Accuracy: 0.999375\n",
      "Epoch [88/100], Step [1100/1250], Loss: 0.000412, Train Accuracy: 0.999347\n",
      "Epoch [88/100], Step [1200/1250], Loss: 0.000735, Train Accuracy: 0.999323\n",
      "Epoch 88/100, Loss: 0.002633, Train Accuracy: 0.999300, Validation Accuracy: 0.819100\n",
      "Epoch [89/100], Step [100/1250], Loss: 0.000174, Train Accuracy: 1.000000\n",
      "Epoch [89/100], Step [200/1250], Loss: 0.022562, Train Accuracy: 1.000000\n",
      "Epoch [89/100], Step [300/1250], Loss: 0.004224, Train Accuracy: 0.999896\n",
      "Epoch [89/100], Step [400/1250], Loss: 0.000351, Train Accuracy: 0.999609\n",
      "Epoch [89/100], Step [500/1250], Loss: 0.000076, Train Accuracy: 0.999563\n",
      "Epoch [89/100], Step [600/1250], Loss: 0.000087, Train Accuracy: 0.999583\n",
      "Epoch [89/100], Step [700/1250], Loss: 0.085106, Train Accuracy: 0.999420\n",
      "Epoch [89/100], Step [800/1250], Loss: 0.000434, Train Accuracy: 0.999258\n",
      "Epoch [89/100], Step [900/1250], Loss: 0.000114, Train Accuracy: 0.999167\n",
      "Epoch [89/100], Step [1000/1250], Loss: 0.000501, Train Accuracy: 0.999031\n",
      "Epoch [89/100], Step [1100/1250], Loss: 0.000343, Train Accuracy: 0.999006\n",
      "Epoch [89/100], Step [1200/1250], Loss: 0.000152, Train Accuracy: 0.998932\n",
      "Epoch 89/100, Loss: 0.003438, Train Accuracy: 0.998950, Validation Accuracy: 0.816800\n",
      "Epoch [90/100], Step [100/1250], Loss: 0.001588, Train Accuracy: 0.999062\n",
      "Epoch [90/100], Step [200/1250], Loss: 0.006512, Train Accuracy: 0.999219\n",
      "Epoch [90/100], Step [300/1250], Loss: 0.042567, Train Accuracy: 0.998750\n",
      "Epoch [90/100], Step [400/1250], Loss: 0.007324, Train Accuracy: 0.998984\n",
      "Epoch [90/100], Step [500/1250], Loss: 0.000350, Train Accuracy: 0.998875\n",
      "Epoch [90/100], Step [600/1250], Loss: 0.000206, Train Accuracy: 0.998698\n",
      "Epoch [90/100], Step [700/1250], Loss: 0.000201, Train Accuracy: 0.998884\n",
      "Epoch [90/100], Step [800/1250], Loss: 0.000108, Train Accuracy: 0.998906\n",
      "Epoch [90/100], Step [900/1250], Loss: 0.001305, Train Accuracy: 0.998993\n",
      "Epoch [90/100], Step [1000/1250], Loss: 0.000898, Train Accuracy: 0.999000\n",
      "Epoch [90/100], Step [1100/1250], Loss: 0.000113, Train Accuracy: 0.999062\n",
      "Epoch [90/100], Step [1200/1250], Loss: 0.000228, Train Accuracy: 0.999062\n",
      "Epoch 90/100, Loss: 0.003512, Train Accuracy: 0.999100, Validation Accuracy: 0.818500\n",
      "Epoch [91/100], Step [100/1250], Loss: 0.000068, Train Accuracy: 1.000000\n",
      "Epoch [91/100], Step [200/1250], Loss: 0.000047, Train Accuracy: 1.000000\n",
      "Epoch [91/100], Step [300/1250], Loss: 0.000063, Train Accuracy: 0.999792\n",
      "Epoch [91/100], Step [400/1250], Loss: 0.001507, Train Accuracy: 0.999766\n",
      "Epoch [91/100], Step [500/1250], Loss: 0.000231, Train Accuracy: 0.999812\n",
      "Epoch [91/100], Step [600/1250], Loss: 0.000272, Train Accuracy: 0.999844\n",
      "Epoch [91/100], Step [700/1250], Loss: 0.000254, Train Accuracy: 0.999866\n",
      "Epoch [91/100], Step [800/1250], Loss: 0.000219, Train Accuracy: 0.999883\n",
      "Epoch [91/100], Step [900/1250], Loss: 0.006910, Train Accuracy: 0.999861\n",
      "Epoch [91/100], Step [1000/1250], Loss: 0.000368, Train Accuracy: 0.999875\n",
      "Epoch [91/100], Step [1100/1250], Loss: 0.000207, Train Accuracy: 0.999858\n",
      "Epoch [91/100], Step [1200/1250], Loss: 0.000645, Train Accuracy: 0.999870\n",
      "Epoch 91/100, Loss: 0.001082, Train Accuracy: 0.999875, Validation Accuracy: 0.822400\n",
      "Epoch [92/100], Step [100/1250], Loss: 0.000042, Train Accuracy: 0.999687\n",
      "Epoch [92/100], Step [200/1250], Loss: 0.000125, Train Accuracy: 0.999844\n",
      "Epoch [92/100], Step [300/1250], Loss: 0.000102, Train Accuracy: 0.999792\n",
      "Epoch [92/100], Step [400/1250], Loss: 0.000225, Train Accuracy: 0.999766\n",
      "Epoch [92/100], Step [500/1250], Loss: 0.000239, Train Accuracy: 0.999687\n",
      "Epoch [92/100], Step [600/1250], Loss: 0.000110, Train Accuracy: 0.999635\n",
      "Epoch [92/100], Step [700/1250], Loss: 0.000766, Train Accuracy: 0.999598\n",
      "Epoch [92/100], Step [800/1250], Loss: 0.001052, Train Accuracy: 0.999570\n",
      "Epoch [92/100], Step [900/1250], Loss: 0.000103, Train Accuracy: 0.999583\n",
      "Epoch [92/100], Step [1000/1250], Loss: 0.000079, Train Accuracy: 0.999531\n",
      "Epoch [92/100], Step [1100/1250], Loss: 0.000357, Train Accuracy: 0.999545\n",
      "Epoch [92/100], Step [1200/1250], Loss: 0.000077, Train Accuracy: 0.999505\n",
      "Epoch 92/100, Loss: 0.001416, Train Accuracy: 0.999525, Validation Accuracy: 0.818600\n",
      "Epoch [93/100], Step [100/1250], Loss: 0.000284, Train Accuracy: 0.999375\n",
      "Epoch [93/100], Step [200/1250], Loss: 0.000110, Train Accuracy: 0.999531\n",
      "Epoch [93/100], Step [300/1250], Loss: 0.000571, Train Accuracy: 0.999583\n",
      "Epoch [93/100], Step [400/1250], Loss: 0.002081, Train Accuracy: 0.999375\n",
      "Epoch [93/100], Step [500/1250], Loss: 0.000752, Train Accuracy: 0.999062\n",
      "Epoch [93/100], Step [600/1250], Loss: 0.000323, Train Accuracy: 0.999219\n",
      "Epoch [93/100], Step [700/1250], Loss: 0.000298, Train Accuracy: 0.999196\n",
      "Epoch [93/100], Step [800/1250], Loss: 0.000074, Train Accuracy: 0.999219\n",
      "Epoch [93/100], Step [900/1250], Loss: 0.000051, Train Accuracy: 0.999306\n",
      "Epoch [93/100], Step [1000/1250], Loss: 0.000242, Train Accuracy: 0.999375\n",
      "Epoch [93/100], Step [1100/1250], Loss: 0.000217, Train Accuracy: 0.999375\n",
      "Epoch [93/100], Step [1200/1250], Loss: 0.000185, Train Accuracy: 0.999323\n",
      "Epoch 93/100, Loss: 0.002142, Train Accuracy: 0.999350, Validation Accuracy: 0.818700\n",
      "Epoch [94/100], Step [100/1250], Loss: 0.000101, Train Accuracy: 0.999375\n",
      "Epoch [94/100], Step [200/1250], Loss: 0.000238, Train Accuracy: 0.999687\n",
      "Epoch [94/100], Step [300/1250], Loss: 0.000297, Train Accuracy: 0.999687\n",
      "Epoch [94/100], Step [400/1250], Loss: 0.000034, Train Accuracy: 0.999687\n",
      "Epoch [94/100], Step [500/1250], Loss: 0.000192, Train Accuracy: 0.999500\n",
      "Epoch [94/100], Step [600/1250], Loss: 0.000396, Train Accuracy: 0.999375\n",
      "Epoch [94/100], Step [700/1250], Loss: 0.000152, Train Accuracy: 0.999286\n",
      "Epoch [94/100], Step [800/1250], Loss: 0.060437, Train Accuracy: 0.999219\n",
      "Epoch [94/100], Step [900/1250], Loss: 0.001993, Train Accuracy: 0.999201\n",
      "Epoch [94/100], Step [1000/1250], Loss: 0.000164, Train Accuracy: 0.999281\n",
      "Epoch [94/100], Step [1100/1250], Loss: 0.000539, Train Accuracy: 0.999290\n",
      "Epoch [94/100], Step [1200/1250], Loss: 0.000646, Train Accuracy: 0.999271\n",
      "Epoch 94/100, Loss: 0.002479, Train Accuracy: 0.999275, Validation Accuracy: 0.817200\n",
      "Epoch [95/100], Step [100/1250], Loss: 0.000076, Train Accuracy: 0.999687\n",
      "Epoch [95/100], Step [200/1250], Loss: 0.000073, Train Accuracy: 0.999219\n",
      "Epoch [95/100], Step [300/1250], Loss: 0.000312, Train Accuracy: 0.999167\n",
      "Epoch [95/100], Step [400/1250], Loss: 0.000476, Train Accuracy: 0.998984\n",
      "Epoch [95/100], Step [500/1250], Loss: 0.000206, Train Accuracy: 0.999125\n",
      "Epoch [95/100], Step [600/1250], Loss: 0.000160, Train Accuracy: 0.999062\n",
      "Epoch [95/100], Step [700/1250], Loss: 0.000092, Train Accuracy: 0.999062\n",
      "Epoch [95/100], Step [800/1250], Loss: 0.000748, Train Accuracy: 0.999102\n",
      "Epoch [95/100], Step [900/1250], Loss: 0.000252, Train Accuracy: 0.999097\n",
      "Epoch [95/100], Step [1000/1250], Loss: 0.000227, Train Accuracy: 0.999031\n",
      "Epoch [95/100], Step [1100/1250], Loss: 0.000961, Train Accuracy: 0.998949\n",
      "Epoch [95/100], Step [1200/1250], Loss: 0.000366, Train Accuracy: 0.998984\n",
      "Epoch 95/100, Loss: 0.003106, Train Accuracy: 0.999000, Validation Accuracy: 0.818700\n",
      "Epoch [96/100], Step [100/1250], Loss: 0.000074, Train Accuracy: 0.999375\n",
      "Epoch [96/100], Step [200/1250], Loss: 0.000331, Train Accuracy: 0.999219\n",
      "Epoch [96/100], Step [300/1250], Loss: 0.000790, Train Accuracy: 0.999375\n",
      "Epoch [96/100], Step [400/1250], Loss: 0.000870, Train Accuracy: 0.999297\n",
      "Epoch [96/100], Step [500/1250], Loss: 0.000434, Train Accuracy: 0.999313\n",
      "Epoch [96/100], Step [600/1250], Loss: 0.000194, Train Accuracy: 0.999219\n",
      "Epoch [96/100], Step [700/1250], Loss: 0.000312, Train Accuracy: 0.999241\n",
      "Epoch [96/100], Step [800/1250], Loss: 0.000434, Train Accuracy: 0.999297\n",
      "Epoch [96/100], Step [900/1250], Loss: 0.000060, Train Accuracy: 0.999340\n",
      "Epoch [96/100], Step [1000/1250], Loss: 0.000156, Train Accuracy: 0.999406\n",
      "Epoch [96/100], Step [1100/1250], Loss: 0.002660, Train Accuracy: 0.999460\n",
      "Epoch [96/100], Step [1200/1250], Loss: 0.000104, Train Accuracy: 0.999453\n",
      "Epoch 96/100, Loss: 0.002248, Train Accuracy: 0.999475, Validation Accuracy: 0.820200\n",
      "Epoch [97/100], Step [100/1250], Loss: 0.000135, Train Accuracy: 0.999375\n",
      "Epoch [97/100], Step [200/1250], Loss: 0.000090, Train Accuracy: 0.999375\n",
      "Epoch [97/100], Step [300/1250], Loss: 0.001549, Train Accuracy: 0.999583\n",
      "Epoch [97/100], Step [400/1250], Loss: 0.000072, Train Accuracy: 0.999687\n",
      "Epoch [97/100], Step [500/1250], Loss: 0.000137, Train Accuracy: 0.999750\n",
      "Epoch [97/100], Step [600/1250], Loss: 0.000242, Train Accuracy: 0.999792\n",
      "Epoch [97/100], Step [700/1250], Loss: 0.001749, Train Accuracy: 0.999732\n",
      "Epoch [97/100], Step [800/1250], Loss: 0.000139, Train Accuracy: 0.999727\n",
      "Epoch [97/100], Step [900/1250], Loss: 0.000124, Train Accuracy: 0.999722\n",
      "Epoch [97/100], Step [1000/1250], Loss: 0.000126, Train Accuracy: 0.999750\n",
      "Epoch [97/100], Step [1100/1250], Loss: 0.000137, Train Accuracy: 0.999744\n",
      "Epoch [97/100], Step [1200/1250], Loss: 0.000174, Train Accuracy: 0.999714\n",
      "Epoch 97/100, Loss: 0.001669, Train Accuracy: 0.999725, Validation Accuracy: 0.815900\n",
      "Epoch [98/100], Step [100/1250], Loss: 0.000057, Train Accuracy: 1.000000\n",
      "Epoch [98/100], Step [200/1250], Loss: 0.140412, Train Accuracy: 0.999531\n",
      "Epoch [98/100], Step [300/1250], Loss: 0.003532, Train Accuracy: 0.999271\n",
      "Epoch [98/100], Step [400/1250], Loss: 0.000237, Train Accuracy: 0.999375\n",
      "Epoch [98/100], Step [500/1250], Loss: 0.000204, Train Accuracy: 0.999313\n",
      "Epoch [98/100], Step [600/1250], Loss: 0.001252, Train Accuracy: 0.999167\n",
      "Epoch [98/100], Step [700/1250], Loss: 0.000469, Train Accuracy: 0.999107\n",
      "Epoch [98/100], Step [800/1250], Loss: 0.000076, Train Accuracy: 0.998984\n",
      "Epoch [98/100], Step [900/1250], Loss: 0.005087, Train Accuracy: 0.998993\n",
      "Epoch [98/100], Step [1000/1250], Loss: 0.000173, Train Accuracy: 0.999062\n",
      "Epoch [98/100], Step [1100/1250], Loss: 0.000730, Train Accuracy: 0.999119\n",
      "Epoch [98/100], Step [1200/1250], Loss: 0.011930, Train Accuracy: 0.999193\n",
      "Epoch 98/100, Loss: 0.002732, Train Accuracy: 0.999225, Validation Accuracy: 0.818600\n",
      "Epoch [99/100], Step [100/1250], Loss: 0.000122, Train Accuracy: 0.999375\n",
      "Epoch [99/100], Step [200/1250], Loss: 0.000147, Train Accuracy: 0.999687\n",
      "Epoch [99/100], Step [300/1250], Loss: 0.010933, Train Accuracy: 0.999375\n",
      "Epoch [99/100], Step [400/1250], Loss: 0.000276, Train Accuracy: 0.999219\n",
      "Epoch [99/100], Step [500/1250], Loss: 0.000100, Train Accuracy: 0.999125\n",
      "Epoch [99/100], Step [600/1250], Loss: 0.000653, Train Accuracy: 0.999115\n",
      "Epoch [99/100], Step [700/1250], Loss: 0.000336, Train Accuracy: 0.998973\n",
      "Epoch [99/100], Step [800/1250], Loss: 0.005858, Train Accuracy: 0.999023\n",
      "Epoch [99/100], Step [900/1250], Loss: 0.001063, Train Accuracy: 0.999062\n",
      "Epoch [99/100], Step [1000/1250], Loss: 0.000483, Train Accuracy: 0.999062\n",
      "Epoch [99/100], Step [1100/1250], Loss: 0.000648, Train Accuracy: 0.999119\n",
      "Epoch [99/100], Step [1200/1250], Loss: 0.000316, Train Accuracy: 0.999167\n",
      "Epoch 99/100, Loss: 0.003250, Train Accuracy: 0.999200, Validation Accuracy: 0.818700\n",
      "Epoch [100/100], Step [100/1250], Loss: 0.000242, Train Accuracy: 0.999687\n",
      "Epoch [100/100], Step [200/1250], Loss: 0.000586, Train Accuracy: 0.999219\n",
      "Epoch [100/100], Step [300/1250], Loss: 0.000768, Train Accuracy: 0.999271\n",
      "Epoch [100/100], Step [400/1250], Loss: 0.000472, Train Accuracy: 0.998984\n",
      "Epoch [100/100], Step [500/1250], Loss: 0.000149, Train Accuracy: 0.998938\n",
      "Epoch [100/100], Step [600/1250], Loss: 0.000186, Train Accuracy: 0.998958\n",
      "Epoch [100/100], Step [700/1250], Loss: 0.000217, Train Accuracy: 0.999018\n",
      "Epoch [100/100], Step [800/1250], Loss: 0.001509, Train Accuracy: 0.999141\n",
      "Epoch [100/100], Step [900/1250], Loss: 0.000664, Train Accuracy: 0.999236\n",
      "Epoch [100/100], Step [1000/1250], Loss: 0.001380, Train Accuracy: 0.999281\n",
      "Epoch [100/100], Step [1100/1250], Loss: 0.000032, Train Accuracy: 0.999318\n",
      "Epoch [100/100], Step [1200/1250], Loss: 0.008780, Train Accuracy: 0.999323\n",
      "Epoch 100/100, Loss: 0.003149, Train Accuracy: 0.999300, Validation Accuracy: 0.814600\n",
      "Epoch [1/100], Step [100/1250], Loss: 2.309907, Train Accuracy: 0.105000\n",
      "Epoch [1/100], Step [200/1250], Loss: 2.288958, Train Accuracy: 0.104531\n",
      "Epoch [1/100], Step [300/1250], Loss: 2.305933, Train Accuracy: 0.104063\n",
      "Epoch [1/100], Step [400/1250], Loss: 2.285159, Train Accuracy: 0.107734\n",
      "Epoch [1/100], Step [500/1250], Loss: 2.272274, Train Accuracy: 0.107250\n",
      "Epoch [1/100], Step [600/1250], Loss: 2.293800, Train Accuracy: 0.109219\n",
      "Epoch [1/100], Step [700/1250], Loss: 2.265627, Train Accuracy: 0.111429\n",
      "Epoch [1/100], Step [800/1250], Loss: 2.255257, Train Accuracy: 0.113711\n",
      "Epoch [1/100], Step [900/1250], Loss: 2.301123, Train Accuracy: 0.118507\n",
      "Epoch [1/100], Step [1000/1250], Loss: 2.063430, Train Accuracy: 0.123656\n",
      "Epoch [1/100], Step [1100/1250], Loss: 2.058550, Train Accuracy: 0.128636\n",
      "Epoch [1/100], Step [1200/1250], Loss: 1.990307, Train Accuracy: 0.136484\n",
      "Epoch 1/100, Loss: 2.284709, Train Accuracy: 0.140275, Validation Accuracy: 0.264000\n",
      "Epoch [2/100], Step [100/1250], Loss: 1.666140, Train Accuracy: 0.276875\n",
      "Epoch [2/100], Step [200/1250], Loss: 1.546164, Train Accuracy: 0.303125\n",
      "Epoch [2/100], Step [300/1250], Loss: 1.686119, Train Accuracy: 0.316250\n",
      "Epoch [2/100], Step [400/1250], Loss: 1.487406, Train Accuracy: 0.326797\n",
      "Epoch [2/100], Step [500/1250], Loss: 1.575734, Train Accuracy: 0.335813\n",
      "Epoch [2/100], Step [600/1250], Loss: 1.539090, Train Accuracy: 0.346823\n",
      "Epoch [2/100], Step [700/1250], Loss: 1.479671, Train Accuracy: 0.357455\n",
      "Epoch [2/100], Step [800/1250], Loss: 1.575876, Train Accuracy: 0.369648\n",
      "Epoch [2/100], Step [900/1250], Loss: 1.519106, Train Accuracy: 0.377153\n",
      "Epoch [2/100], Step [1000/1250], Loss: 1.397437, Train Accuracy: 0.388156\n",
      "Epoch [2/100], Step [1100/1250], Loss: 1.356192, Train Accuracy: 0.395739\n",
      "Epoch [2/100], Step [1200/1250], Loss: 1.219541, Train Accuracy: 0.404193\n",
      "Epoch 2/100, Loss: 1.535989, Train Accuracy: 0.408450, Validation Accuracy: 0.528200\n",
      "Epoch [3/100], Step [100/1250], Loss: 1.139303, Train Accuracy: 0.542813\n",
      "Epoch [3/100], Step [200/1250], Loss: 1.249137, Train Accuracy: 0.550469\n",
      "Epoch [3/100], Step [300/1250], Loss: 0.940270, Train Accuracy: 0.548542\n",
      "Epoch [3/100], Step [400/1250], Loss: 1.233163, Train Accuracy: 0.548359\n",
      "Epoch [3/100], Step [500/1250], Loss: 1.154646, Train Accuracy: 0.555375\n",
      "Epoch [3/100], Step [600/1250], Loss: 1.213736, Train Accuracy: 0.563229\n",
      "Epoch [3/100], Step [700/1250], Loss: 0.985337, Train Accuracy: 0.567679\n",
      "Epoch [3/100], Step [800/1250], Loss: 1.071865, Train Accuracy: 0.574492\n",
      "Epoch [3/100], Step [900/1250], Loss: 1.117924, Train Accuracy: 0.577604\n",
      "Epoch [3/100], Step [1000/1250], Loss: 1.285256, Train Accuracy: 0.581844\n",
      "Epoch [3/100], Step [1100/1250], Loss: 1.073826, Train Accuracy: 0.586932\n",
      "Epoch [3/100], Step [1200/1250], Loss: 0.627383, Train Accuracy: 0.591667\n",
      "Epoch 3/100, Loss: 1.131310, Train Accuracy: 0.593975, Validation Accuracy: 0.669900\n",
      "Epoch [4/100], Step [100/1250], Loss: 1.037754, Train Accuracy: 0.673125\n",
      "Epoch [4/100], Step [200/1250], Loss: 1.165468, Train Accuracy: 0.675156\n",
      "Epoch [4/100], Step [300/1250], Loss: 1.028061, Train Accuracy: 0.672188\n",
      "Epoch [4/100], Step [400/1250], Loss: 0.692151, Train Accuracy: 0.677109\n",
      "Epoch [4/100], Step [500/1250], Loss: 1.050742, Train Accuracy: 0.679562\n",
      "Epoch [4/100], Step [600/1250], Loss: 0.889481, Train Accuracy: 0.681667\n",
      "Epoch [4/100], Step [700/1250], Loss: 0.748563, Train Accuracy: 0.682187\n",
      "Epoch [4/100], Step [800/1250], Loss: 0.801289, Train Accuracy: 0.682422\n",
      "Epoch [4/100], Step [900/1250], Loss: 0.949609, Train Accuracy: 0.684306\n",
      "Epoch [4/100], Step [1000/1250], Loss: 0.906262, Train Accuracy: 0.685781\n",
      "Epoch [4/100], Step [1100/1250], Loss: 0.803194, Train Accuracy: 0.686108\n",
      "Epoch [4/100], Step [1200/1250], Loss: 0.815154, Train Accuracy: 0.688099\n",
      "Epoch 4/100, Loss: 0.896848, Train Accuracy: 0.688450, Validation Accuracy: 0.708900\n",
      "Epoch [5/100], Step [100/1250], Loss: 0.765587, Train Accuracy: 0.730313\n",
      "Epoch [5/100], Step [200/1250], Loss: 0.718306, Train Accuracy: 0.731406\n",
      "Epoch [5/100], Step [300/1250], Loss: 0.763982, Train Accuracy: 0.732187\n",
      "Epoch [5/100], Step [400/1250], Loss: 0.533220, Train Accuracy: 0.732500\n",
      "Epoch [5/100], Step [500/1250], Loss: 0.773049, Train Accuracy: 0.732062\n",
      "Epoch [5/100], Step [600/1250], Loss: 0.754207, Train Accuracy: 0.735208\n",
      "Epoch [5/100], Step [700/1250], Loss: 0.715935, Train Accuracy: 0.737143\n",
      "Epoch [5/100], Step [800/1250], Loss: 0.625700, Train Accuracy: 0.737305\n",
      "Epoch [5/100], Step [900/1250], Loss: 0.732243, Train Accuracy: 0.738715\n",
      "Epoch [5/100], Step [1000/1250], Loss: 0.741121, Train Accuracy: 0.737969\n",
      "Epoch [5/100], Step [1100/1250], Loss: 1.037668, Train Accuracy: 0.738409\n",
      "Epoch [5/100], Step [1200/1250], Loss: 0.826638, Train Accuracy: 0.738958\n",
      "Epoch 5/100, Loss: 0.749701, Train Accuracy: 0.738800, Validation Accuracy: 0.737600\n",
      "Epoch [6/100], Step [100/1250], Loss: 0.633038, Train Accuracy: 0.776875\n",
      "Epoch [6/100], Step [200/1250], Loss: 0.504720, Train Accuracy: 0.781563\n",
      "Epoch [6/100], Step [300/1250], Loss: 0.805175, Train Accuracy: 0.782083\n",
      "Epoch [6/100], Step [400/1250], Loss: 0.924082, Train Accuracy: 0.783672\n",
      "Epoch [6/100], Step [500/1250], Loss: 0.456891, Train Accuracy: 0.783438\n",
      "Epoch [6/100], Step [600/1250], Loss: 0.866870, Train Accuracy: 0.781354\n",
      "Epoch [6/100], Step [700/1250], Loss: 0.472394, Train Accuracy: 0.781250\n",
      "Epoch [6/100], Step [800/1250], Loss: 0.351466, Train Accuracy: 0.780664\n",
      "Epoch [6/100], Step [900/1250], Loss: 0.389570, Train Accuracy: 0.781042\n",
      "Epoch [6/100], Step [1000/1250], Loss: 0.372128, Train Accuracy: 0.781062\n",
      "Epoch [6/100], Step [1100/1250], Loss: 1.189831, Train Accuracy: 0.781023\n",
      "Epoch [6/100], Step [1200/1250], Loss: 0.625073, Train Accuracy: 0.780964\n",
      "Epoch 6/100, Loss: 0.638170, Train Accuracy: 0.780975, Validation Accuracy: 0.743700\n",
      "Epoch [7/100], Step [100/1250], Loss: 0.638134, Train Accuracy: 0.799687\n",
      "Epoch [7/100], Step [200/1250], Loss: 0.653784, Train Accuracy: 0.804688\n",
      "Epoch [7/100], Step [300/1250], Loss: 0.445064, Train Accuracy: 0.812396\n",
      "Epoch [7/100], Step [400/1250], Loss: 0.749793, Train Accuracy: 0.814609\n",
      "Epoch [7/100], Step [500/1250], Loss: 0.390496, Train Accuracy: 0.810937\n",
      "Epoch [7/100], Step [600/1250], Loss: 0.652613, Train Accuracy: 0.810625\n",
      "Epoch [7/100], Step [700/1250], Loss: 0.656874, Train Accuracy: 0.811250\n",
      "Epoch [7/100], Step [800/1250], Loss: 0.657442, Train Accuracy: 0.811367\n",
      "Epoch [7/100], Step [900/1250], Loss: 0.406536, Train Accuracy: 0.811389\n",
      "Epoch [7/100], Step [1000/1250], Loss: 0.602295, Train Accuracy: 0.810813\n",
      "Epoch [7/100], Step [1100/1250], Loss: 0.741677, Train Accuracy: 0.811193\n",
      "Epoch [7/100], Step [1200/1250], Loss: 0.278021, Train Accuracy: 0.811562\n",
      "Epoch 7/100, Loss: 0.547218, Train Accuracy: 0.812175, Validation Accuracy: 0.760300\n",
      "Epoch [8/100], Step [100/1250], Loss: 0.239853, Train Accuracy: 0.843437\n",
      "Epoch [8/100], Step [200/1250], Loss: 0.525185, Train Accuracy: 0.850938\n",
      "Epoch [8/100], Step [300/1250], Loss: 0.299479, Train Accuracy: 0.848333\n",
      "Epoch [8/100], Step [400/1250], Loss: 0.381782, Train Accuracy: 0.848047\n",
      "Epoch [8/100], Step [500/1250], Loss: 0.658956, Train Accuracy: 0.846500\n",
      "Epoch [8/100], Step [600/1250], Loss: 0.272156, Train Accuracy: 0.844479\n",
      "Epoch [8/100], Step [700/1250], Loss: 0.382428, Train Accuracy: 0.842812\n",
      "Epoch [8/100], Step [800/1250], Loss: 0.408178, Train Accuracy: 0.843125\n",
      "Epoch [8/100], Step [900/1250], Loss: 0.456207, Train Accuracy: 0.844028\n",
      "Epoch [8/100], Step [1000/1250], Loss: 0.667030, Train Accuracy: 0.843375\n",
      "Epoch [8/100], Step [1100/1250], Loss: 0.562215, Train Accuracy: 0.842358\n",
      "Epoch [8/100], Step [1200/1250], Loss: 0.486625, Train Accuracy: 0.841953\n",
      "Epoch 8/100, Loss: 0.459052, Train Accuracy: 0.842225, Validation Accuracy: 0.770900\n",
      "Epoch [9/100], Step [100/1250], Loss: 0.528956, Train Accuracy: 0.882188\n",
      "Epoch [9/100], Step [200/1250], Loss: 0.163226, Train Accuracy: 0.880781\n",
      "Epoch [9/100], Step [300/1250], Loss: 0.377786, Train Accuracy: 0.880729\n",
      "Epoch [9/100], Step [400/1250], Loss: 0.383613, Train Accuracy: 0.876484\n",
      "Epoch [9/100], Step [500/1250], Loss: 0.653682, Train Accuracy: 0.876500\n",
      "Epoch [9/100], Step [600/1250], Loss: 0.322510, Train Accuracy: 0.876823\n",
      "Epoch [9/100], Step [700/1250], Loss: 0.438165, Train Accuracy: 0.875179\n",
      "Epoch [9/100], Step [800/1250], Loss: 0.482900, Train Accuracy: 0.872969\n",
      "Epoch [9/100], Step [900/1250], Loss: 0.148303, Train Accuracy: 0.871736\n",
      "Epoch [9/100], Step [1000/1250], Loss: 0.552572, Train Accuracy: 0.871437\n",
      "Epoch [9/100], Step [1100/1250], Loss: 0.321710, Train Accuracy: 0.871335\n",
      "Epoch [9/100], Step [1200/1250], Loss: 0.254388, Train Accuracy: 0.869974\n",
      "Epoch 9/100, Loss: 0.377966, Train Accuracy: 0.869950, Validation Accuracy: 0.777500\n",
      "Epoch [10/100], Step [100/1250], Loss: 0.209211, Train Accuracy: 0.893125\n",
      "Epoch [10/100], Step [200/1250], Loss: 0.470633, Train Accuracy: 0.894219\n",
      "Epoch [10/100], Step [300/1250], Loss: 0.304941, Train Accuracy: 0.899062\n",
      "Epoch [10/100], Step [400/1250], Loss: 0.304863, Train Accuracy: 0.897578\n",
      "Epoch [10/100], Step [500/1250], Loss: 0.252754, Train Accuracy: 0.896437\n",
      "Epoch [10/100], Step [600/1250], Loss: 0.257380, Train Accuracy: 0.896563\n",
      "Epoch [10/100], Step [700/1250], Loss: 0.442196, Train Accuracy: 0.896384\n",
      "Epoch [10/100], Step [800/1250], Loss: 0.543877, Train Accuracy: 0.896094\n",
      "Epoch [10/100], Step [900/1250], Loss: 0.135498, Train Accuracy: 0.896424\n",
      "Epoch [10/100], Step [1000/1250], Loss: 0.207387, Train Accuracy: 0.896188\n",
      "Epoch [10/100], Step [1100/1250], Loss: 0.204339, Train Accuracy: 0.895341\n",
      "Epoch [10/100], Step [1200/1250], Loss: 0.180505, Train Accuracy: 0.894870\n",
      "Epoch 10/100, Loss: 0.312752, Train Accuracy: 0.894650, Validation Accuracy: 0.767900\n",
      "Epoch [11/100], Step [100/1250], Loss: 0.059440, Train Accuracy: 0.921250\n",
      "Epoch [11/100], Step [200/1250], Loss: 0.134430, Train Accuracy: 0.922031\n",
      "Epoch [11/100], Step [300/1250], Loss: 0.328012, Train Accuracy: 0.919896\n",
      "Epoch [11/100], Step [400/1250], Loss: 0.188798, Train Accuracy: 0.918906\n",
      "Epoch [11/100], Step [500/1250], Loss: 0.333685, Train Accuracy: 0.917125\n",
      "Epoch [11/100], Step [600/1250], Loss: 0.306560, Train Accuracy: 0.915000\n",
      "Epoch [11/100], Step [700/1250], Loss: 0.166784, Train Accuracy: 0.914821\n",
      "Epoch [11/100], Step [800/1250], Loss: 0.213622, Train Accuracy: 0.915703\n",
      "Epoch [11/100], Step [900/1250], Loss: 0.083100, Train Accuracy: 0.915556\n",
      "Epoch [11/100], Step [1000/1250], Loss: 0.066954, Train Accuracy: 0.915188\n",
      "Epoch [11/100], Step [1100/1250], Loss: 0.245568, Train Accuracy: 0.915341\n",
      "Epoch [11/100], Step [1200/1250], Loss: 0.294202, Train Accuracy: 0.915052\n",
      "Epoch 11/100, Loss: 0.252437, Train Accuracy: 0.915050, Validation Accuracy: 0.780300\n",
      "Epoch [12/100], Step [100/1250], Loss: 0.108596, Train Accuracy: 0.941250\n",
      "Epoch [12/100], Step [200/1250], Loss: 0.089892, Train Accuracy: 0.937813\n",
      "Epoch [12/100], Step [300/1250], Loss: 0.116515, Train Accuracy: 0.936667\n",
      "Epoch [12/100], Step [400/1250], Loss: 0.169736, Train Accuracy: 0.936328\n",
      "Epoch [12/100], Step [500/1250], Loss: 0.046733, Train Accuracy: 0.935375\n",
      "Epoch [12/100], Step [600/1250], Loss: 0.121453, Train Accuracy: 0.933281\n",
      "Epoch [12/100], Step [700/1250], Loss: 0.386684, Train Accuracy: 0.932277\n",
      "Epoch [12/100], Step [800/1250], Loss: 0.191721, Train Accuracy: 0.931094\n",
      "Epoch [12/100], Step [900/1250], Loss: 0.084365, Train Accuracy: 0.930347\n",
      "Epoch [12/100], Step [1000/1250], Loss: 0.029906, Train Accuracy: 0.929844\n",
      "Epoch [12/100], Step [1100/1250], Loss: 0.214977, Train Accuracy: 0.929460\n",
      "Epoch [12/100], Step [1200/1250], Loss: 0.126906, Train Accuracy: 0.930078\n",
      "Epoch 12/100, Loss: 0.207571, Train Accuracy: 0.929975, Validation Accuracy: 0.777900\n",
      "Epoch [13/100], Step [100/1250], Loss: 0.198394, Train Accuracy: 0.952500\n",
      "Epoch [13/100], Step [200/1250], Loss: 0.194746, Train Accuracy: 0.949844\n",
      "Epoch [13/100], Step [300/1250], Loss: 0.258395, Train Accuracy: 0.950625\n",
      "Epoch [13/100], Step [400/1250], Loss: 0.159118, Train Accuracy: 0.947109\n",
      "Epoch [13/100], Step [500/1250], Loss: 0.300551, Train Accuracy: 0.945375\n",
      "Epoch [13/100], Step [600/1250], Loss: 0.292150, Train Accuracy: 0.945833\n",
      "Epoch [13/100], Step [700/1250], Loss: 0.276361, Train Accuracy: 0.945223\n",
      "Epoch [13/100], Step [800/1250], Loss: 0.144197, Train Accuracy: 0.945312\n",
      "Epoch [13/100], Step [900/1250], Loss: 0.268627, Train Accuracy: 0.944722\n",
      "Epoch [13/100], Step [1000/1250], Loss: 0.091953, Train Accuracy: 0.944063\n",
      "Epoch [13/100], Step [1100/1250], Loss: 0.228604, Train Accuracy: 0.943949\n",
      "Epoch [13/100], Step [1200/1250], Loss: 0.195763, Train Accuracy: 0.943802\n",
      "Epoch 13/100, Loss: 0.167805, Train Accuracy: 0.943350, Validation Accuracy: 0.779100\n",
      "Epoch [14/100], Step [100/1250], Loss: 0.041340, Train Accuracy: 0.959375\n",
      "Epoch [14/100], Step [200/1250], Loss: 0.112133, Train Accuracy: 0.958281\n",
      "Epoch [14/100], Step [300/1250], Loss: 0.188083, Train Accuracy: 0.957812\n",
      "Epoch [14/100], Step [400/1250], Loss: 0.123748, Train Accuracy: 0.957734\n",
      "Epoch [14/100], Step [500/1250], Loss: 0.139272, Train Accuracy: 0.957000\n",
      "Epoch [14/100], Step [600/1250], Loss: 0.138773, Train Accuracy: 0.957448\n",
      "Epoch [14/100], Step [700/1250], Loss: 0.281401, Train Accuracy: 0.956696\n",
      "Epoch [14/100], Step [800/1250], Loss: 0.134311, Train Accuracy: 0.956133\n",
      "Epoch [14/100], Step [900/1250], Loss: 0.108493, Train Accuracy: 0.955799\n",
      "Epoch [14/100], Step [1000/1250], Loss: 0.162617, Train Accuracy: 0.955031\n",
      "Epoch [14/100], Step [1100/1250], Loss: 0.029626, Train Accuracy: 0.954148\n",
      "Epoch [14/100], Step [1200/1250], Loss: 0.148477, Train Accuracy: 0.953750\n",
      "Epoch 14/100, Loss: 0.139441, Train Accuracy: 0.953625, Validation Accuracy: 0.775000\n",
      "Epoch [15/100], Step [100/1250], Loss: 0.057166, Train Accuracy: 0.967812\n",
      "Epoch [15/100], Step [200/1250], Loss: 0.019786, Train Accuracy: 0.964844\n",
      "Epoch [15/100], Step [300/1250], Loss: 0.090099, Train Accuracy: 0.965417\n",
      "Epoch [15/100], Step [400/1250], Loss: 0.041195, Train Accuracy: 0.965625\n",
      "Epoch [15/100], Step [500/1250], Loss: 0.026288, Train Accuracy: 0.965437\n",
      "Epoch [15/100], Step [600/1250], Loss: 0.077740, Train Accuracy: 0.964844\n",
      "Epoch [15/100], Step [700/1250], Loss: 0.151098, Train Accuracy: 0.963705\n",
      "Epoch [15/100], Step [800/1250], Loss: 0.091676, Train Accuracy: 0.963750\n",
      "Epoch [15/100], Step [900/1250], Loss: 0.213458, Train Accuracy: 0.963681\n",
      "Epoch [15/100], Step [1000/1250], Loss: 0.125400, Train Accuracy: 0.963063\n",
      "Epoch [15/100], Step [1100/1250], Loss: 0.086905, Train Accuracy: 0.962784\n",
      "Epoch [15/100], Step [1200/1250], Loss: 0.050609, Train Accuracy: 0.962760\n",
      "Epoch 15/100, Loss: 0.113998, Train Accuracy: 0.963050, Validation Accuracy: 0.773900\n",
      "Epoch [16/100], Step [100/1250], Loss: 0.149504, Train Accuracy: 0.964688\n",
      "Epoch [16/100], Step [200/1250], Loss: 0.131575, Train Accuracy: 0.967031\n",
      "Epoch [16/100], Step [300/1250], Loss: 0.054202, Train Accuracy: 0.968021\n",
      "Epoch [16/100], Step [400/1250], Loss: 0.215429, Train Accuracy: 0.967109\n",
      "Epoch [16/100], Step [500/1250], Loss: 0.071170, Train Accuracy: 0.967750\n",
      "Epoch [16/100], Step [600/1250], Loss: 0.088590, Train Accuracy: 0.967240\n",
      "Epoch [16/100], Step [700/1250], Loss: 0.020379, Train Accuracy: 0.966518\n",
      "Epoch [16/100], Step [800/1250], Loss: 0.007247, Train Accuracy: 0.966484\n",
      "Epoch [16/100], Step [900/1250], Loss: 0.024009, Train Accuracy: 0.966979\n",
      "Epoch [16/100], Step [1000/1250], Loss: 0.129421, Train Accuracy: 0.966969\n",
      "Epoch [16/100], Step [1100/1250], Loss: 0.033104, Train Accuracy: 0.967557\n",
      "Epoch [16/100], Step [1200/1250], Loss: 0.224053, Train Accuracy: 0.967214\n",
      "Epoch 16/100, Loss: 0.098168, Train Accuracy: 0.967150, Validation Accuracy: 0.774200\n",
      "Epoch [17/100], Step [100/1250], Loss: 0.049496, Train Accuracy: 0.979062\n",
      "Epoch [17/100], Step [200/1250], Loss: 0.039140, Train Accuracy: 0.977969\n",
      "Epoch [17/100], Step [300/1250], Loss: 0.058973, Train Accuracy: 0.975938\n",
      "Epoch [17/100], Step [400/1250], Loss: 0.032554, Train Accuracy: 0.976172\n",
      "Epoch [17/100], Step [500/1250], Loss: 0.159166, Train Accuracy: 0.976750\n",
      "Epoch [17/100], Step [600/1250], Loss: 0.062980, Train Accuracy: 0.976719\n",
      "Epoch [17/100], Step [700/1250], Loss: 0.011375, Train Accuracy: 0.975759\n",
      "Epoch [17/100], Step [800/1250], Loss: 0.100324, Train Accuracy: 0.975039\n",
      "Epoch [17/100], Step [900/1250], Loss: 0.020418, Train Accuracy: 0.974722\n",
      "Epoch [17/100], Step [1000/1250], Loss: 0.066325, Train Accuracy: 0.974812\n",
      "Epoch [17/100], Step [1100/1250], Loss: 0.265172, Train Accuracy: 0.974602\n",
      "Epoch [17/100], Step [1200/1250], Loss: 0.030353, Train Accuracy: 0.973568\n",
      "Epoch 17/100, Loss: 0.079094, Train Accuracy: 0.973300, Validation Accuracy: 0.771300\n",
      "Epoch [18/100], Step [100/1250], Loss: 0.045753, Train Accuracy: 0.975313\n",
      "Epoch [18/100], Step [200/1250], Loss: 0.129403, Train Accuracy: 0.975625\n",
      "Epoch [18/100], Step [300/1250], Loss: 0.095234, Train Accuracy: 0.977292\n",
      "Epoch [18/100], Step [400/1250], Loss: 0.016319, Train Accuracy: 0.977734\n",
      "Epoch [18/100], Step [500/1250], Loss: 0.018571, Train Accuracy: 0.977500\n",
      "Epoch [18/100], Step [600/1250], Loss: 0.222518, Train Accuracy: 0.977708\n",
      "Epoch [18/100], Step [700/1250], Loss: 0.183762, Train Accuracy: 0.977232\n",
      "Epoch [18/100], Step [800/1250], Loss: 0.043637, Train Accuracy: 0.976953\n",
      "Epoch [18/100], Step [900/1250], Loss: 0.069534, Train Accuracy: 0.976250\n",
      "Epoch [18/100], Step [1000/1250], Loss: 0.004786, Train Accuracy: 0.975969\n",
      "Epoch [18/100], Step [1100/1250], Loss: 0.268483, Train Accuracy: 0.976477\n",
      "Epoch [18/100], Step [1200/1250], Loss: 0.136979, Train Accuracy: 0.976536\n",
      "Epoch 18/100, Loss: 0.071658, Train Accuracy: 0.976550, Validation Accuracy: 0.770800\n",
      "Epoch [19/100], Step [100/1250], Loss: 0.069225, Train Accuracy: 0.984375\n",
      "Epoch [19/100], Step [200/1250], Loss: 0.018199, Train Accuracy: 0.985469\n",
      "Epoch [19/100], Step [300/1250], Loss: 0.010970, Train Accuracy: 0.984479\n",
      "Epoch [19/100], Step [400/1250], Loss: 0.021469, Train Accuracy: 0.983203\n",
      "Epoch [19/100], Step [500/1250], Loss: 0.127022, Train Accuracy: 0.982000\n",
      "Epoch [19/100], Step [600/1250], Loss: 0.055300, Train Accuracy: 0.981667\n",
      "Epoch [19/100], Step [700/1250], Loss: 0.038533, Train Accuracy: 0.980759\n",
      "Epoch [19/100], Step [800/1250], Loss: 0.007836, Train Accuracy: 0.980742\n",
      "Epoch [19/100], Step [900/1250], Loss: 0.097563, Train Accuracy: 0.979826\n",
      "Epoch [19/100], Step [1000/1250], Loss: 0.011195, Train Accuracy: 0.979594\n",
      "Epoch [19/100], Step [1100/1250], Loss: 0.110075, Train Accuracy: 0.979290\n",
      "Epoch [19/100], Step [1200/1250], Loss: 0.035419, Train Accuracy: 0.979401\n",
      "Epoch 19/100, Loss: 0.063081, Train Accuracy: 0.979075, Validation Accuracy: 0.774700\n",
      "Epoch [20/100], Step [100/1250], Loss: 0.052911, Train Accuracy: 0.984688\n",
      "Epoch [20/100], Step [200/1250], Loss: 0.001908, Train Accuracy: 0.985625\n",
      "Epoch [20/100], Step [300/1250], Loss: 0.045716, Train Accuracy: 0.985208\n",
      "Epoch [20/100], Step [400/1250], Loss: 0.066236, Train Accuracy: 0.984453\n",
      "Epoch [20/100], Step [500/1250], Loss: 0.050064, Train Accuracy: 0.983750\n",
      "Epoch [20/100], Step [600/1250], Loss: 0.181285, Train Accuracy: 0.982500\n",
      "Epoch [20/100], Step [700/1250], Loss: 0.056040, Train Accuracy: 0.982500\n",
      "Epoch [20/100], Step [800/1250], Loss: 0.189784, Train Accuracy: 0.982578\n",
      "Epoch [20/100], Step [900/1250], Loss: 0.055959, Train Accuracy: 0.982083\n",
      "Epoch [20/100], Step [1000/1250], Loss: 0.040864, Train Accuracy: 0.982125\n",
      "Epoch [20/100], Step [1100/1250], Loss: 0.008130, Train Accuracy: 0.982216\n",
      "Epoch [20/100], Step [1200/1250], Loss: 0.020376, Train Accuracy: 0.982187\n",
      "Epoch 20/100, Loss: 0.053193, Train Accuracy: 0.982125, Validation Accuracy: 0.774100\n",
      "Epoch [21/100], Step [100/1250], Loss: 0.151063, Train Accuracy: 0.985313\n",
      "Epoch [21/100], Step [200/1250], Loss: 0.071737, Train Accuracy: 0.984844\n",
      "Epoch [21/100], Step [300/1250], Loss: 0.014421, Train Accuracy: 0.985208\n",
      "Epoch [21/100], Step [400/1250], Loss: 0.086453, Train Accuracy: 0.985313\n",
      "Epoch [21/100], Step [500/1250], Loss: 0.059264, Train Accuracy: 0.985625\n",
      "Epoch [21/100], Step [600/1250], Loss: 0.013686, Train Accuracy: 0.984688\n",
      "Epoch [21/100], Step [700/1250], Loss: 0.008898, Train Accuracy: 0.984643\n",
      "Epoch [21/100], Step [800/1250], Loss: 0.040831, Train Accuracy: 0.984805\n",
      "Epoch [21/100], Step [900/1250], Loss: 0.031734, Train Accuracy: 0.984410\n",
      "Epoch [21/100], Step [1000/1250], Loss: 0.016798, Train Accuracy: 0.983906\n",
      "Epoch [21/100], Step [1100/1250], Loss: 0.059274, Train Accuracy: 0.982699\n",
      "Epoch [21/100], Step [1200/1250], Loss: 0.003355, Train Accuracy: 0.982396\n",
      "Epoch 21/100, Loss: 0.051762, Train Accuracy: 0.982250, Validation Accuracy: 0.774100\n",
      "Epoch [22/100], Step [100/1250], Loss: 0.029135, Train Accuracy: 0.986563\n",
      "Epoch [22/100], Step [200/1250], Loss: 0.000700, Train Accuracy: 0.986406\n",
      "Epoch [22/100], Step [300/1250], Loss: 0.003814, Train Accuracy: 0.987187\n",
      "Epoch [22/100], Step [400/1250], Loss: 0.033829, Train Accuracy: 0.987422\n",
      "Epoch [22/100], Step [500/1250], Loss: 0.041263, Train Accuracy: 0.986313\n",
      "Epoch [22/100], Step [600/1250], Loss: 0.009775, Train Accuracy: 0.986927\n",
      "Epoch [22/100], Step [700/1250], Loss: 0.004536, Train Accuracy: 0.987009\n",
      "Epoch [22/100], Step [800/1250], Loss: 0.047032, Train Accuracy: 0.987109\n",
      "Epoch [22/100], Step [900/1250], Loss: 0.076802, Train Accuracy: 0.986632\n",
      "Epoch [22/100], Step [1000/1250], Loss: 0.040150, Train Accuracy: 0.986375\n",
      "Epoch [22/100], Step [1100/1250], Loss: 0.052086, Train Accuracy: 0.986335\n",
      "Epoch [22/100], Step [1200/1250], Loss: 0.011097, Train Accuracy: 0.986120\n",
      "Epoch 22/100, Loss: 0.043050, Train Accuracy: 0.985975, Validation Accuracy: 0.770300\n",
      "Epoch [23/100], Step [100/1250], Loss: 0.024638, Train Accuracy: 0.989375\n",
      "Epoch [23/100], Step [200/1250], Loss: 0.002406, Train Accuracy: 0.991094\n",
      "Epoch [23/100], Step [300/1250], Loss: 0.011946, Train Accuracy: 0.992188\n",
      "Epoch [23/100], Step [400/1250], Loss: 0.041517, Train Accuracy: 0.992344\n",
      "Epoch [23/100], Step [500/1250], Loss: 0.001991, Train Accuracy: 0.992000\n",
      "Epoch [23/100], Step [600/1250], Loss: 0.002003, Train Accuracy: 0.991302\n",
      "Epoch [23/100], Step [700/1250], Loss: 0.009485, Train Accuracy: 0.990938\n",
      "Epoch [23/100], Step [800/1250], Loss: 0.001443, Train Accuracy: 0.990547\n",
      "Epoch [23/100], Step [900/1250], Loss: 0.016522, Train Accuracy: 0.989896\n",
      "Epoch [23/100], Step [1000/1250], Loss: 0.002423, Train Accuracy: 0.989000\n",
      "Epoch [23/100], Step [1100/1250], Loss: 0.095648, Train Accuracy: 0.988722\n",
      "Epoch [23/100], Step [1200/1250], Loss: 0.018838, Train Accuracy: 0.988385\n",
      "Epoch 23/100, Loss: 0.037554, Train Accuracy: 0.988075, Validation Accuracy: 0.775300\n",
      "Epoch [24/100], Step [100/1250], Loss: 0.036151, Train Accuracy: 0.983750\n",
      "Epoch [24/100], Step [200/1250], Loss: 0.018899, Train Accuracy: 0.986719\n",
      "Epoch [24/100], Step [300/1250], Loss: 0.016207, Train Accuracy: 0.988021\n",
      "Epoch [24/100], Step [400/1250], Loss: 0.098728, Train Accuracy: 0.988437\n",
      "Epoch [24/100], Step [500/1250], Loss: 0.015059, Train Accuracy: 0.988750\n",
      "Epoch [24/100], Step [600/1250], Loss: 0.005021, Train Accuracy: 0.987969\n",
      "Epoch [24/100], Step [700/1250], Loss: 0.007457, Train Accuracy: 0.988437\n",
      "Epoch [24/100], Step [800/1250], Loss: 0.002348, Train Accuracy: 0.988516\n",
      "Epoch [24/100], Step [900/1250], Loss: 0.026788, Train Accuracy: 0.988160\n",
      "Epoch [24/100], Step [1000/1250], Loss: 0.006869, Train Accuracy: 0.988219\n",
      "Epoch [24/100], Step [1100/1250], Loss: 0.019164, Train Accuracy: 0.988040\n",
      "Epoch [24/100], Step [1200/1250], Loss: 0.136261, Train Accuracy: 0.987630\n",
      "Epoch 24/100, Loss: 0.036504, Train Accuracy: 0.987500, Validation Accuracy: 0.773700\n",
      "Epoch [25/100], Step [100/1250], Loss: 0.003546, Train Accuracy: 0.992500\n",
      "Epoch [25/100], Step [200/1250], Loss: 0.005934, Train Accuracy: 0.991719\n",
      "Epoch [25/100], Step [300/1250], Loss: 0.086400, Train Accuracy: 0.991667\n",
      "Epoch [25/100], Step [400/1250], Loss: 0.000895, Train Accuracy: 0.990625\n",
      "Epoch [25/100], Step [500/1250], Loss: 0.045941, Train Accuracy: 0.991000\n",
      "Epoch [25/100], Step [600/1250], Loss: 0.105233, Train Accuracy: 0.990938\n",
      "Epoch [25/100], Step [700/1250], Loss: 0.001875, Train Accuracy: 0.990759\n",
      "Epoch [25/100], Step [800/1250], Loss: 0.026099, Train Accuracy: 0.990508\n",
      "Epoch [25/100], Step [900/1250], Loss: 0.014702, Train Accuracy: 0.989965\n",
      "Epoch [25/100], Step [1000/1250], Loss: 0.023284, Train Accuracy: 0.989969\n",
      "Epoch [25/100], Step [1100/1250], Loss: 0.025607, Train Accuracy: 0.989801\n",
      "Epoch [25/100], Step [1200/1250], Loss: 0.042486, Train Accuracy: 0.989531\n",
      "Epoch 25/100, Loss: 0.032938, Train Accuracy: 0.989375, Validation Accuracy: 0.776800\n",
      "Epoch [26/100], Step [100/1250], Loss: 0.002793, Train Accuracy: 0.992812\n",
      "Epoch [26/100], Step [200/1250], Loss: 0.071457, Train Accuracy: 0.992812\n",
      "Epoch [26/100], Step [300/1250], Loss: 0.021247, Train Accuracy: 0.991875\n",
      "Epoch [26/100], Step [400/1250], Loss: 0.014389, Train Accuracy: 0.991016\n",
      "Epoch [26/100], Step [500/1250], Loss: 0.074655, Train Accuracy: 0.990125\n",
      "Epoch [26/100], Step [600/1250], Loss: 0.065783, Train Accuracy: 0.989219\n",
      "Epoch [26/100], Step [700/1250], Loss: 0.007557, Train Accuracy: 0.988929\n",
      "Epoch [26/100], Step [800/1250], Loss: 0.043864, Train Accuracy: 0.988867\n",
      "Epoch [26/100], Step [900/1250], Loss: 0.009202, Train Accuracy: 0.988542\n",
      "Epoch [26/100], Step [1000/1250], Loss: 0.007752, Train Accuracy: 0.988688\n",
      "Epoch [26/100], Step [1100/1250], Loss: 0.006739, Train Accuracy: 0.988636\n",
      "Epoch [26/100], Step [1200/1250], Loss: 0.070623, Train Accuracy: 0.988568\n",
      "Epoch 26/100, Loss: 0.034125, Train Accuracy: 0.988400, Validation Accuracy: 0.775300\n",
      "Epoch [27/100], Step [100/1250], Loss: 0.004901, Train Accuracy: 0.994375\n",
      "Epoch [27/100], Step [200/1250], Loss: 0.006570, Train Accuracy: 0.991875\n",
      "Epoch [27/100], Step [300/1250], Loss: 0.010212, Train Accuracy: 0.991354\n",
      "Epoch [27/100], Step [400/1250], Loss: 0.011255, Train Accuracy: 0.991406\n",
      "Epoch [27/100], Step [500/1250], Loss: 0.025671, Train Accuracy: 0.991750\n",
      "Epoch [27/100], Step [600/1250], Loss: 0.003525, Train Accuracy: 0.991406\n",
      "Epoch [27/100], Step [700/1250], Loss: 0.074745, Train Accuracy: 0.991205\n",
      "Epoch [27/100], Step [800/1250], Loss: 0.023645, Train Accuracy: 0.991016\n",
      "Epoch [27/100], Step [900/1250], Loss: 0.002806, Train Accuracy: 0.990972\n",
      "Epoch [27/100], Step [1000/1250], Loss: 0.001986, Train Accuracy: 0.990375\n",
      "Epoch [27/100], Step [1100/1250], Loss: 0.013460, Train Accuracy: 0.990369\n",
      "Epoch [27/100], Step [1200/1250], Loss: 0.010052, Train Accuracy: 0.990104\n",
      "Epoch 27/100, Loss: 0.030686, Train Accuracy: 0.990075, Validation Accuracy: 0.771300\n",
      "Epoch [28/100], Step [100/1250], Loss: 0.008783, Train Accuracy: 0.993125\n",
      "Epoch [28/100], Step [200/1250], Loss: 0.002524, Train Accuracy: 0.991719\n",
      "Epoch [28/100], Step [300/1250], Loss: 0.008446, Train Accuracy: 0.991354\n",
      "Epoch [28/100], Step [400/1250], Loss: 0.002043, Train Accuracy: 0.990859\n",
      "Epoch [28/100], Step [500/1250], Loss: 0.005624, Train Accuracy: 0.991187\n",
      "Epoch [28/100], Step [600/1250], Loss: 0.029802, Train Accuracy: 0.991563\n",
      "Epoch [28/100], Step [700/1250], Loss: 0.006442, Train Accuracy: 0.991429\n",
      "Epoch [28/100], Step [800/1250], Loss: 0.035199, Train Accuracy: 0.991406\n",
      "Epoch [28/100], Step [900/1250], Loss: 0.004939, Train Accuracy: 0.991354\n",
      "Epoch [28/100], Step [1000/1250], Loss: 0.013630, Train Accuracy: 0.991406\n",
      "Epoch [28/100], Step [1100/1250], Loss: 0.029657, Train Accuracy: 0.991449\n",
      "Epoch [28/100], Step [1200/1250], Loss: 0.009541, Train Accuracy: 0.991484\n",
      "Epoch 28/100, Loss: 0.026065, Train Accuracy: 0.991625, Validation Accuracy: 0.780800\n",
      "Epoch [29/100], Step [100/1250], Loss: 0.002430, Train Accuracy: 0.990000\n",
      "Epoch [29/100], Step [200/1250], Loss: 0.001361, Train Accuracy: 0.989062\n",
      "Epoch [29/100], Step [300/1250], Loss: 0.029306, Train Accuracy: 0.990104\n",
      "Epoch [29/100], Step [400/1250], Loss: 0.007615, Train Accuracy: 0.991484\n",
      "Epoch [29/100], Step [500/1250], Loss: 0.037089, Train Accuracy: 0.991750\n",
      "Epoch [29/100], Step [600/1250], Loss: 0.008985, Train Accuracy: 0.991927\n",
      "Epoch [29/100], Step [700/1250], Loss: 0.004935, Train Accuracy: 0.992054\n",
      "Epoch [29/100], Step [800/1250], Loss: 0.059337, Train Accuracy: 0.991758\n",
      "Epoch [29/100], Step [900/1250], Loss: 0.010894, Train Accuracy: 0.991806\n",
      "Epoch [29/100], Step [1000/1250], Loss: 0.004014, Train Accuracy: 0.991469\n",
      "Epoch [29/100], Step [1100/1250], Loss: 0.139489, Train Accuracy: 0.990909\n",
      "Epoch [29/100], Step [1200/1250], Loss: 0.009023, Train Accuracy: 0.990599\n",
      "Epoch 29/100, Loss: 0.028464, Train Accuracy: 0.990600, Validation Accuracy: 0.782500\n",
      "Epoch [30/100], Step [100/1250], Loss: 0.007618, Train Accuracy: 0.991563\n",
      "Epoch [30/100], Step [200/1250], Loss: 0.016187, Train Accuracy: 0.992812\n",
      "Epoch [30/100], Step [300/1250], Loss: 0.003497, Train Accuracy: 0.993333\n",
      "Epoch [30/100], Step [400/1250], Loss: 0.010546, Train Accuracy: 0.993906\n",
      "Epoch [30/100], Step [500/1250], Loss: 0.016001, Train Accuracy: 0.993875\n",
      "Epoch [30/100], Step [600/1250], Loss: 0.007953, Train Accuracy: 0.993177\n",
      "Epoch [30/100], Step [700/1250], Loss: 0.004422, Train Accuracy: 0.992723\n",
      "Epoch [30/100], Step [800/1250], Loss: 0.013805, Train Accuracy: 0.992227\n",
      "Epoch [30/100], Step [900/1250], Loss: 0.017872, Train Accuracy: 0.992292\n",
      "Epoch [30/100], Step [1000/1250], Loss: 0.024454, Train Accuracy: 0.991938\n",
      "Epoch [30/100], Step [1100/1250], Loss: 0.005843, Train Accuracy: 0.992131\n",
      "Epoch [30/100], Step [1200/1250], Loss: 0.008570, Train Accuracy: 0.992083\n",
      "Epoch 30/100, Loss: 0.023401, Train Accuracy: 0.991975, Validation Accuracy: 0.777800\n",
      "Epoch [31/100], Step [100/1250], Loss: 0.004560, Train Accuracy: 0.994375\n",
      "Epoch [31/100], Step [200/1250], Loss: 0.003359, Train Accuracy: 0.992500\n",
      "Epoch [31/100], Step [300/1250], Loss: 0.004475, Train Accuracy: 0.991458\n",
      "Epoch [31/100], Step [400/1250], Loss: 0.003593, Train Accuracy: 0.991094\n",
      "Epoch [31/100], Step [500/1250], Loss: 0.003944, Train Accuracy: 0.991313\n",
      "Epoch [31/100], Step [600/1250], Loss: 0.045532, Train Accuracy: 0.991510\n",
      "Epoch [31/100], Step [700/1250], Loss: 0.014553, Train Accuracy: 0.991563\n",
      "Epoch [31/100], Step [800/1250], Loss: 0.005495, Train Accuracy: 0.991758\n",
      "Epoch [31/100], Step [900/1250], Loss: 0.003847, Train Accuracy: 0.991840\n",
      "Epoch [31/100], Step [1000/1250], Loss: 0.232225, Train Accuracy: 0.991875\n",
      "Epoch [31/100], Step [1100/1250], Loss: 0.003284, Train Accuracy: 0.992045\n",
      "Epoch [31/100], Step [1200/1250], Loss: 0.003504, Train Accuracy: 0.992370\n",
      "Epoch 31/100, Loss: 0.023260, Train Accuracy: 0.992550, Validation Accuracy: 0.784600\n",
      "Epoch [32/100], Step [100/1250], Loss: 0.016767, Train Accuracy: 0.995625\n",
      "Epoch [32/100], Step [200/1250], Loss: 0.002099, Train Accuracy: 0.995000\n",
      "Epoch [32/100], Step [300/1250], Loss: 0.071250, Train Accuracy: 0.995000\n",
      "Epoch [32/100], Step [400/1250], Loss: 0.004257, Train Accuracy: 0.995469\n",
      "Epoch [32/100], Step [500/1250], Loss: 0.001242, Train Accuracy: 0.995375\n",
      "Epoch [32/100], Step [600/1250], Loss: 0.064610, Train Accuracy: 0.995000\n",
      "Epoch [32/100], Step [700/1250], Loss: 0.011124, Train Accuracy: 0.994018\n",
      "Epoch [32/100], Step [800/1250], Loss: 0.007929, Train Accuracy: 0.993711\n",
      "Epoch [32/100], Step [900/1250], Loss: 0.028646, Train Accuracy: 0.993090\n",
      "Epoch [32/100], Step [1000/1250], Loss: 0.021396, Train Accuracy: 0.992844\n",
      "Epoch [32/100], Step [1100/1250], Loss: 0.195277, Train Accuracy: 0.992898\n",
      "Epoch [32/100], Step [1200/1250], Loss: 0.104890, Train Accuracy: 0.992630\n",
      "Epoch 32/100, Loss: 0.022143, Train Accuracy: 0.992525, Validation Accuracy: 0.774100\n",
      "Epoch [33/100], Step [100/1250], Loss: 0.001064, Train Accuracy: 0.993750\n",
      "Epoch [33/100], Step [200/1250], Loss: 0.043203, Train Accuracy: 0.992188\n",
      "Epoch [33/100], Step [300/1250], Loss: 0.064112, Train Accuracy: 0.992708\n",
      "Epoch [33/100], Step [400/1250], Loss: 0.096113, Train Accuracy: 0.992344\n",
      "Epoch [33/100], Step [500/1250], Loss: 0.006728, Train Accuracy: 0.992812\n",
      "Epoch [33/100], Step [600/1250], Loss: 0.000644, Train Accuracy: 0.992969\n",
      "Epoch [33/100], Step [700/1250], Loss: 0.042533, Train Accuracy: 0.993125\n",
      "Epoch [33/100], Step [800/1250], Loss: 0.008057, Train Accuracy: 0.992891\n",
      "Epoch [33/100], Step [900/1250], Loss: 0.008771, Train Accuracy: 0.992743\n",
      "Epoch [33/100], Step [1000/1250], Loss: 0.038070, Train Accuracy: 0.992750\n",
      "Epoch [33/100], Step [1100/1250], Loss: 0.000471, Train Accuracy: 0.992869\n",
      "Epoch [33/100], Step [1200/1250], Loss: 0.001091, Train Accuracy: 0.992917\n",
      "Epoch 33/100, Loss: 0.022085, Train Accuracy: 0.992950, Validation Accuracy: 0.773900\n",
      "Epoch [34/100], Step [100/1250], Loss: 0.000516, Train Accuracy: 0.994062\n",
      "Epoch [34/100], Step [200/1250], Loss: 0.042110, Train Accuracy: 0.993750\n",
      "Epoch [34/100], Step [300/1250], Loss: 0.090509, Train Accuracy: 0.994375\n",
      "Epoch [34/100], Step [400/1250], Loss: 0.016261, Train Accuracy: 0.994375\n",
      "Epoch [34/100], Step [500/1250], Loss: 0.000435, Train Accuracy: 0.994687\n",
      "Epoch [34/100], Step [600/1250], Loss: 0.000841, Train Accuracy: 0.994896\n",
      "Epoch [34/100], Step [700/1250], Loss: 0.001257, Train Accuracy: 0.994554\n",
      "Epoch [34/100], Step [800/1250], Loss: 0.115591, Train Accuracy: 0.994336\n",
      "Epoch [34/100], Step [900/1250], Loss: 0.038775, Train Accuracy: 0.994236\n",
      "Epoch [34/100], Step [1000/1250], Loss: 0.004680, Train Accuracy: 0.994437\n",
      "Epoch [34/100], Step [1100/1250], Loss: 0.002467, Train Accuracy: 0.994489\n",
      "Epoch [34/100], Step [1200/1250], Loss: 0.004871, Train Accuracy: 0.994115\n",
      "Epoch 34/100, Loss: 0.019395, Train Accuracy: 0.994000, Validation Accuracy: 0.779700\n",
      "Epoch [35/100], Step [100/1250], Loss: 0.007735, Train Accuracy: 0.994375\n",
      "Epoch [35/100], Step [200/1250], Loss: 0.010919, Train Accuracy: 0.993281\n",
      "Epoch [35/100], Step [300/1250], Loss: 0.181406, Train Accuracy: 0.993125\n",
      "Epoch [35/100], Step [400/1250], Loss: 0.022537, Train Accuracy: 0.993359\n",
      "Epoch [35/100], Step [500/1250], Loss: 0.009004, Train Accuracy: 0.993375\n",
      "Epoch [35/100], Step [600/1250], Loss: 0.000328, Train Accuracy: 0.993281\n",
      "Epoch [35/100], Step [700/1250], Loss: 0.023944, Train Accuracy: 0.993348\n",
      "Epoch [35/100], Step [800/1250], Loss: 0.007017, Train Accuracy: 0.993320\n",
      "Epoch [35/100], Step [900/1250], Loss: 0.002458, Train Accuracy: 0.993160\n",
      "Epoch [35/100], Step [1000/1250], Loss: 0.117192, Train Accuracy: 0.993062\n",
      "Epoch [35/100], Step [1100/1250], Loss: 0.046945, Train Accuracy: 0.993097\n",
      "Epoch [35/100], Step [1200/1250], Loss: 0.001006, Train Accuracy: 0.993073\n",
      "Epoch 35/100, Loss: 0.021534, Train Accuracy: 0.993125, Validation Accuracy: 0.781200\n",
      "Epoch [36/100], Step [100/1250], Loss: 0.002936, Train Accuracy: 0.992812\n",
      "Epoch [36/100], Step [200/1250], Loss: 0.001923, Train Accuracy: 0.995156\n",
      "Epoch [36/100], Step [300/1250], Loss: 0.084440, Train Accuracy: 0.994896\n",
      "Epoch [36/100], Step [400/1250], Loss: 0.000787, Train Accuracy: 0.994609\n",
      "Epoch [36/100], Step [500/1250], Loss: 0.014380, Train Accuracy: 0.994062\n",
      "Epoch [36/100], Step [600/1250], Loss: 0.003730, Train Accuracy: 0.994115\n",
      "Epoch [36/100], Step [700/1250], Loss: 0.008993, Train Accuracy: 0.994330\n",
      "Epoch [36/100], Step [800/1250], Loss: 0.001448, Train Accuracy: 0.994297\n",
      "Epoch [36/100], Step [900/1250], Loss: 0.026562, Train Accuracy: 0.994410\n",
      "Epoch [36/100], Step [1000/1250], Loss: 0.010451, Train Accuracy: 0.994250\n",
      "Epoch [36/100], Step [1100/1250], Loss: 0.001521, Train Accuracy: 0.994205\n",
      "Epoch [36/100], Step [1200/1250], Loss: 0.026827, Train Accuracy: 0.994036\n",
      "Epoch 36/100, Loss: 0.018240, Train Accuracy: 0.994125, Validation Accuracy: 0.784700\n",
      "Epoch [37/100], Step [100/1250], Loss: 0.001372, Train Accuracy: 0.995938\n",
      "Epoch [37/100], Step [200/1250], Loss: 0.010423, Train Accuracy: 0.995000\n",
      "Epoch [37/100], Step [300/1250], Loss: 0.008188, Train Accuracy: 0.995104\n",
      "Epoch [37/100], Step [400/1250], Loss: 0.005224, Train Accuracy: 0.995156\n",
      "Epoch [37/100], Step [500/1250], Loss: 0.003598, Train Accuracy: 0.994812\n",
      "Epoch [37/100], Step [600/1250], Loss: 0.081062, Train Accuracy: 0.994844\n",
      "Epoch [37/100], Step [700/1250], Loss: 0.001388, Train Accuracy: 0.994554\n",
      "Epoch [37/100], Step [800/1250], Loss: 0.000735, Train Accuracy: 0.994297\n",
      "Epoch [37/100], Step [900/1250], Loss: 0.006384, Train Accuracy: 0.994028\n",
      "Epoch [37/100], Step [1000/1250], Loss: 0.003969, Train Accuracy: 0.993687\n",
      "Epoch [37/100], Step [1100/1250], Loss: 0.002074, Train Accuracy: 0.993920\n",
      "Epoch [37/100], Step [1200/1250], Loss: 0.000587, Train Accuracy: 0.993828\n",
      "Epoch 37/100, Loss: 0.017934, Train Accuracy: 0.993825, Validation Accuracy: 0.776400\n",
      "Epoch [38/100], Step [100/1250], Loss: 0.062529, Train Accuracy: 0.995938\n",
      "Epoch [38/100], Step [200/1250], Loss: 0.000353, Train Accuracy: 0.997344\n",
      "Epoch [38/100], Step [300/1250], Loss: 0.000148, Train Accuracy: 0.997188\n",
      "Epoch [38/100], Step [400/1250], Loss: 0.000700, Train Accuracy: 0.997031\n",
      "Epoch [38/100], Step [500/1250], Loss: 0.003436, Train Accuracy: 0.995875\n",
      "Epoch [38/100], Step [600/1250], Loss: 0.000173, Train Accuracy: 0.995781\n",
      "Epoch [38/100], Step [700/1250], Loss: 0.010290, Train Accuracy: 0.995714\n",
      "Epoch [38/100], Step [800/1250], Loss: 0.000174, Train Accuracy: 0.995508\n",
      "Epoch [38/100], Step [900/1250], Loss: 0.001602, Train Accuracy: 0.995382\n",
      "Epoch [38/100], Step [1000/1250], Loss: 0.019170, Train Accuracy: 0.995313\n",
      "Epoch [38/100], Step [1100/1250], Loss: 0.002741, Train Accuracy: 0.995369\n",
      "Epoch [38/100], Step [1200/1250], Loss: 0.017764, Train Accuracy: 0.995365\n",
      "Epoch 38/100, Loss: 0.015179, Train Accuracy: 0.995450, Validation Accuracy: 0.778400\n",
      "Epoch [39/100], Step [100/1250], Loss: 0.000370, Train Accuracy: 0.995000\n",
      "Epoch [39/100], Step [200/1250], Loss: 0.002738, Train Accuracy: 0.995156\n",
      "Epoch [39/100], Step [300/1250], Loss: 0.001886, Train Accuracy: 0.995417\n",
      "Epoch [39/100], Step [400/1250], Loss: 0.088162, Train Accuracy: 0.995234\n",
      "Epoch [39/100], Step [500/1250], Loss: 0.001742, Train Accuracy: 0.995062\n",
      "Epoch [39/100], Step [600/1250], Loss: 0.010798, Train Accuracy: 0.994583\n",
      "Epoch [39/100], Step [700/1250], Loss: 0.022516, Train Accuracy: 0.994464\n",
      "Epoch [39/100], Step [800/1250], Loss: 0.010033, Train Accuracy: 0.994727\n",
      "Epoch [39/100], Step [900/1250], Loss: 0.003881, Train Accuracy: 0.994618\n",
      "Epoch [39/100], Step [1000/1250], Loss: 0.019198, Train Accuracy: 0.994625\n",
      "Epoch [39/100], Step [1100/1250], Loss: 0.002193, Train Accuracy: 0.994659\n",
      "Epoch [39/100], Step [1200/1250], Loss: 0.000401, Train Accuracy: 0.994505\n",
      "Epoch 39/100, Loss: 0.017305, Train Accuracy: 0.994375, Validation Accuracy: 0.776800\n",
      "Epoch [40/100], Step [100/1250], Loss: 0.006596, Train Accuracy: 0.996563\n",
      "Epoch [40/100], Step [200/1250], Loss: 0.002287, Train Accuracy: 0.996875\n",
      "Epoch [40/100], Step [300/1250], Loss: 0.000434, Train Accuracy: 0.996771\n",
      "Epoch [40/100], Step [400/1250], Loss: 0.008784, Train Accuracy: 0.996641\n",
      "Epoch [40/100], Step [500/1250], Loss: 0.011927, Train Accuracy: 0.996437\n",
      "Epoch [40/100], Step [600/1250], Loss: 0.004247, Train Accuracy: 0.995677\n",
      "Epoch [40/100], Step [700/1250], Loss: 0.008419, Train Accuracy: 0.995625\n",
      "Epoch [40/100], Step [800/1250], Loss: 0.000832, Train Accuracy: 0.995195\n",
      "Epoch [40/100], Step [900/1250], Loss: 0.001052, Train Accuracy: 0.995035\n",
      "Epoch [40/100], Step [1000/1250], Loss: 0.001451, Train Accuracy: 0.995094\n",
      "Epoch [40/100], Step [1100/1250], Loss: 0.000415, Train Accuracy: 0.995398\n",
      "Epoch [40/100], Step [1200/1250], Loss: 0.001476, Train Accuracy: 0.995417\n",
      "Epoch 40/100, Loss: 0.014503, Train Accuracy: 0.995500, Validation Accuracy: 0.779400\n",
      "Epoch [41/100], Step [100/1250], Loss: 0.000172, Train Accuracy: 0.996250\n",
      "Epoch [41/100], Step [200/1250], Loss: 0.003335, Train Accuracy: 0.996875\n",
      "Epoch [41/100], Step [300/1250], Loss: 0.006278, Train Accuracy: 0.996042\n",
      "Epoch [41/100], Step [400/1250], Loss: 0.002485, Train Accuracy: 0.996016\n",
      "Epoch [41/100], Step [500/1250], Loss: 0.001352, Train Accuracy: 0.995625\n",
      "Epoch [41/100], Step [600/1250], Loss: 0.009054, Train Accuracy: 0.995208\n",
      "Epoch [41/100], Step [700/1250], Loss: 0.009234, Train Accuracy: 0.995446\n",
      "Epoch [41/100], Step [800/1250], Loss: 0.001176, Train Accuracy: 0.995508\n",
      "Epoch [41/100], Step [900/1250], Loss: 0.110127, Train Accuracy: 0.995313\n",
      "Epoch [41/100], Step [1000/1250], Loss: 0.003040, Train Accuracy: 0.995437\n",
      "Epoch [41/100], Step [1100/1250], Loss: 0.030107, Train Accuracy: 0.995284\n",
      "Epoch [41/100], Step [1200/1250], Loss: 0.043620, Train Accuracy: 0.995365\n",
      "Epoch 41/100, Loss: 0.013970, Train Accuracy: 0.995375, Validation Accuracy: 0.783900\n",
      "Epoch [42/100], Step [100/1250], Loss: 0.000367, Train Accuracy: 0.997188\n",
      "Epoch [42/100], Step [200/1250], Loss: 0.014318, Train Accuracy: 0.997188\n",
      "Epoch [42/100], Step [300/1250], Loss: 0.001552, Train Accuracy: 0.996458\n",
      "Epoch [42/100], Step [400/1250], Loss: 0.003103, Train Accuracy: 0.995703\n",
      "Epoch [42/100], Step [500/1250], Loss: 0.000519, Train Accuracy: 0.995687\n",
      "Epoch [42/100], Step [600/1250], Loss: 0.000628, Train Accuracy: 0.995208\n",
      "Epoch [42/100], Step [700/1250], Loss: 0.000600, Train Accuracy: 0.995045\n",
      "Epoch [42/100], Step [800/1250], Loss: 0.000811, Train Accuracy: 0.995078\n",
      "Epoch [42/100], Step [900/1250], Loss: 0.005786, Train Accuracy: 0.994861\n",
      "Epoch [42/100], Step [1000/1250], Loss: 0.017644, Train Accuracy: 0.994656\n",
      "Epoch [42/100], Step [1100/1250], Loss: 0.029636, Train Accuracy: 0.994773\n",
      "Epoch [42/100], Step [1200/1250], Loss: 0.000433, Train Accuracy: 0.994844\n",
      "Epoch 42/100, Loss: 0.015886, Train Accuracy: 0.994875, Validation Accuracy: 0.782700\n",
      "Epoch [43/100], Step [100/1250], Loss: 0.000198, Train Accuracy: 0.999062\n",
      "Epoch [43/100], Step [200/1250], Loss: 0.037327, Train Accuracy: 0.998125\n",
      "Epoch [43/100], Step [300/1250], Loss: 0.011553, Train Accuracy: 0.997396\n",
      "Epoch [43/100], Step [400/1250], Loss: 0.006137, Train Accuracy: 0.996953\n",
      "Epoch [43/100], Step [500/1250], Loss: 0.001442, Train Accuracy: 0.996875\n",
      "Epoch [43/100], Step [600/1250], Loss: 0.000454, Train Accuracy: 0.996667\n",
      "Epoch [43/100], Step [700/1250], Loss: 0.000848, Train Accuracy: 0.996518\n",
      "Epoch [43/100], Step [800/1250], Loss: 0.018773, Train Accuracy: 0.996523\n",
      "Epoch [43/100], Step [900/1250], Loss: 0.004472, Train Accuracy: 0.996528\n",
      "Epoch [43/100], Step [1000/1250], Loss: 0.060105, Train Accuracy: 0.996594\n",
      "Epoch [43/100], Step [1100/1250], Loss: 0.037814, Train Accuracy: 0.996506\n",
      "Epoch [43/100], Step [1200/1250], Loss: 0.037717, Train Accuracy: 0.996224\n",
      "Epoch 43/100, Loss: 0.012741, Train Accuracy: 0.996250, Validation Accuracy: 0.776600\n",
      "Epoch [44/100], Step [100/1250], Loss: 0.004975, Train Accuracy: 0.994062\n",
      "Epoch [44/100], Step [200/1250], Loss: 0.006270, Train Accuracy: 0.994531\n",
      "Epoch [44/100], Step [300/1250], Loss: 0.023878, Train Accuracy: 0.994896\n",
      "Epoch [44/100], Step [400/1250], Loss: 0.010394, Train Accuracy: 0.995625\n",
      "Epoch [44/100], Step [500/1250], Loss: 0.001013, Train Accuracy: 0.995750\n",
      "Epoch [44/100], Step [600/1250], Loss: 0.003201, Train Accuracy: 0.995833\n",
      "Epoch [44/100], Step [700/1250], Loss: 0.000435, Train Accuracy: 0.995982\n",
      "Epoch [44/100], Step [800/1250], Loss: 0.000456, Train Accuracy: 0.996016\n",
      "Epoch [44/100], Step [900/1250], Loss: 0.007591, Train Accuracy: 0.995938\n",
      "Epoch [44/100], Step [1000/1250], Loss: 0.001006, Train Accuracy: 0.996031\n",
      "Epoch [44/100], Step [1100/1250], Loss: 0.001333, Train Accuracy: 0.996023\n",
      "Epoch [44/100], Step [1200/1250], Loss: 0.020280, Train Accuracy: 0.995833\n",
      "Epoch 44/100, Loss: 0.012382, Train Accuracy: 0.995825, Validation Accuracy: 0.773200\n",
      "Epoch [45/100], Step [100/1250], Loss: 0.001512, Train Accuracy: 0.995938\n",
      "Epoch [45/100], Step [200/1250], Loss: 0.115363, Train Accuracy: 0.994687\n",
      "Epoch [45/100], Step [300/1250], Loss: 0.015085, Train Accuracy: 0.995729\n",
      "Epoch [45/100], Step [400/1250], Loss: 0.000393, Train Accuracy: 0.995469\n",
      "Epoch [45/100], Step [500/1250], Loss: 0.002546, Train Accuracy: 0.995812\n",
      "Epoch [45/100], Step [600/1250], Loss: 0.005804, Train Accuracy: 0.996042\n",
      "Epoch [45/100], Step [700/1250], Loss: 0.001170, Train Accuracy: 0.996027\n",
      "Epoch [45/100], Step [800/1250], Loss: 0.000756, Train Accuracy: 0.996211\n",
      "Epoch [45/100], Step [900/1250], Loss: 0.015135, Train Accuracy: 0.996146\n",
      "Epoch [45/100], Step [1000/1250], Loss: 0.001479, Train Accuracy: 0.996125\n",
      "Epoch [45/100], Step [1100/1250], Loss: 0.001549, Train Accuracy: 0.996108\n",
      "Epoch [45/100], Step [1200/1250], Loss: 0.002687, Train Accuracy: 0.996094\n",
      "Epoch 45/100, Loss: 0.013082, Train Accuracy: 0.996150, Validation Accuracy: 0.781600\n",
      "Epoch [46/100], Step [100/1250], Loss: 0.016028, Train Accuracy: 0.997188\n",
      "Epoch [46/100], Step [200/1250], Loss: 0.002113, Train Accuracy: 0.997344\n",
      "Epoch [46/100], Step [300/1250], Loss: 0.005537, Train Accuracy: 0.996771\n",
      "Epoch [46/100], Step [400/1250], Loss: 0.000410, Train Accuracy: 0.996406\n",
      "Epoch [46/100], Step [500/1250], Loss: 0.003051, Train Accuracy: 0.996375\n",
      "Epoch [46/100], Step [600/1250], Loss: 0.005056, Train Accuracy: 0.996406\n",
      "Epoch [46/100], Step [700/1250], Loss: 0.002890, Train Accuracy: 0.996563\n",
      "Epoch [46/100], Step [800/1250], Loss: 0.001435, Train Accuracy: 0.996680\n",
      "Epoch [46/100], Step [900/1250], Loss: 0.005281, Train Accuracy: 0.996701\n",
      "Epoch [46/100], Step [1000/1250], Loss: 0.013440, Train Accuracy: 0.996656\n",
      "Epoch [46/100], Step [1100/1250], Loss: 0.001608, Train Accuracy: 0.996449\n",
      "Epoch [46/100], Step [1200/1250], Loss: 0.004471, Train Accuracy: 0.996276\n",
      "Epoch 46/100, Loss: 0.011702, Train Accuracy: 0.996275, Validation Accuracy: 0.778800\n",
      "Epoch [47/100], Step [100/1250], Loss: 0.002148, Train Accuracy: 0.998125\n",
      "Epoch [47/100], Step [200/1250], Loss: 0.003134, Train Accuracy: 0.996250\n",
      "Epoch [47/100], Step [300/1250], Loss: 0.007611, Train Accuracy: 0.996458\n",
      "Epoch [47/100], Step [400/1250], Loss: 0.103331, Train Accuracy: 0.996641\n",
      "Epoch [47/100], Step [500/1250], Loss: 0.000966, Train Accuracy: 0.996563\n",
      "Epoch [47/100], Step [600/1250], Loss: 0.005479, Train Accuracy: 0.996354\n",
      "Epoch [47/100], Step [700/1250], Loss: 0.008960, Train Accuracy: 0.995893\n",
      "Epoch [47/100], Step [800/1250], Loss: 0.002487, Train Accuracy: 0.995664\n",
      "Epoch [47/100], Step [900/1250], Loss: 0.017066, Train Accuracy: 0.995694\n",
      "Epoch [47/100], Step [1000/1250], Loss: 0.001079, Train Accuracy: 0.995719\n",
      "Epoch [47/100], Step [1100/1250], Loss: 0.005950, Train Accuracy: 0.995653\n",
      "Epoch [47/100], Step [1200/1250], Loss: 0.001432, Train Accuracy: 0.995807\n",
      "Epoch 47/100, Loss: 0.012900, Train Accuracy: 0.995900, Validation Accuracy: 0.780600\n",
      "Epoch [48/100], Step [100/1250], Loss: 0.004659, Train Accuracy: 0.997812\n",
      "Epoch [48/100], Step [200/1250], Loss: 0.004307, Train Accuracy: 0.997500\n",
      "Epoch [48/100], Step [300/1250], Loss: 0.003911, Train Accuracy: 0.996979\n",
      "Epoch [48/100], Step [400/1250], Loss: 0.002960, Train Accuracy: 0.996719\n",
      "Epoch [48/100], Step [500/1250], Loss: 0.045417, Train Accuracy: 0.996750\n",
      "Epoch [48/100], Step [600/1250], Loss: 0.001907, Train Accuracy: 0.996823\n",
      "Epoch [48/100], Step [700/1250], Loss: 0.000133, Train Accuracy: 0.996964\n",
      "Epoch [48/100], Step [800/1250], Loss: 0.025480, Train Accuracy: 0.997070\n",
      "Epoch [48/100], Step [900/1250], Loss: 0.036501, Train Accuracy: 0.996701\n",
      "Epoch [48/100], Step [1000/1250], Loss: 0.000491, Train Accuracy: 0.996531\n",
      "Epoch [48/100], Step [1100/1250], Loss: 0.009242, Train Accuracy: 0.996278\n",
      "Epoch [48/100], Step [1200/1250], Loss: 0.000390, Train Accuracy: 0.996250\n",
      "Epoch 48/100, Loss: 0.012036, Train Accuracy: 0.996250, Validation Accuracy: 0.778400\n",
      "Epoch [49/100], Step [100/1250], Loss: 0.000674, Train Accuracy: 0.996875\n",
      "Epoch [49/100], Step [200/1250], Loss: 0.009571, Train Accuracy: 0.996719\n",
      "Epoch [49/100], Step [300/1250], Loss: 0.001055, Train Accuracy: 0.996875\n",
      "Epoch [49/100], Step [400/1250], Loss: 0.000543, Train Accuracy: 0.996797\n",
      "Epoch [49/100], Step [500/1250], Loss: 0.000174, Train Accuracy: 0.997125\n",
      "Epoch [49/100], Step [600/1250], Loss: 0.002769, Train Accuracy: 0.996875\n",
      "Epoch [49/100], Step [700/1250], Loss: 0.000744, Train Accuracy: 0.997054\n",
      "Epoch [49/100], Step [800/1250], Loss: 0.001421, Train Accuracy: 0.997070\n",
      "Epoch [49/100], Step [900/1250], Loss: 0.000386, Train Accuracy: 0.997014\n",
      "Epoch [49/100], Step [1000/1250], Loss: 0.001049, Train Accuracy: 0.997062\n",
      "Epoch [49/100], Step [1100/1250], Loss: 0.006470, Train Accuracy: 0.997188\n",
      "Epoch [49/100], Step [1200/1250], Loss: 0.000448, Train Accuracy: 0.997240\n",
      "Epoch 49/100, Loss: 0.008783, Train Accuracy: 0.997325, Validation Accuracy: 0.782800\n",
      "Epoch [50/100], Step [100/1250], Loss: 0.000425, Train Accuracy: 0.997812\n",
      "Epoch [50/100], Step [200/1250], Loss: 0.006975, Train Accuracy: 0.997031\n",
      "Epoch [50/100], Step [300/1250], Loss: 0.110777, Train Accuracy: 0.996771\n",
      "Epoch [50/100], Step [400/1250], Loss: 0.006278, Train Accuracy: 0.996641\n",
      "Epoch [50/100], Step [500/1250], Loss: 0.000036, Train Accuracy: 0.996313\n",
      "Epoch [50/100], Step [600/1250], Loss: 0.000738, Train Accuracy: 0.996198\n",
      "Epoch [50/100], Step [700/1250], Loss: 0.011185, Train Accuracy: 0.996071\n",
      "Epoch [50/100], Step [800/1250], Loss: 0.048366, Train Accuracy: 0.995898\n",
      "Epoch [50/100], Step [900/1250], Loss: 0.018871, Train Accuracy: 0.995694\n",
      "Epoch [50/100], Step [1000/1250], Loss: 0.018603, Train Accuracy: 0.995812\n",
      "Epoch [50/100], Step [1100/1250], Loss: 0.002182, Train Accuracy: 0.995909\n",
      "Epoch [50/100], Step [1200/1250], Loss: 0.002086, Train Accuracy: 0.995885\n",
      "Epoch 50/100, Loss: 0.013548, Train Accuracy: 0.995975, Validation Accuracy: 0.783200\n",
      "Epoch [51/100], Step [100/1250], Loss: 0.000144, Train Accuracy: 0.999062\n",
      "Epoch [51/100], Step [200/1250], Loss: 0.000943, Train Accuracy: 0.998281\n",
      "Epoch [51/100], Step [300/1250], Loss: 0.005833, Train Accuracy: 0.998021\n",
      "Epoch [51/100], Step [400/1250], Loss: 0.000282, Train Accuracy: 0.997891\n",
      "Epoch [51/100], Step [500/1250], Loss: 0.001019, Train Accuracy: 0.998062\n",
      "Epoch [51/100], Step [600/1250], Loss: 0.000859, Train Accuracy: 0.997604\n",
      "Epoch [51/100], Step [700/1250], Loss: 0.089986, Train Accuracy: 0.997500\n",
      "Epoch [51/100], Step [800/1250], Loss: 0.008926, Train Accuracy: 0.997500\n",
      "Epoch [51/100], Step [900/1250], Loss: 0.003341, Train Accuracy: 0.997500\n",
      "Epoch [51/100], Step [1000/1250], Loss: 0.000249, Train Accuracy: 0.997281\n",
      "Epoch [51/100], Step [1100/1250], Loss: 0.006568, Train Accuracy: 0.997131\n",
      "Epoch [51/100], Step [1200/1250], Loss: 0.005021, Train Accuracy: 0.997135\n",
      "Epoch 51/100, Loss: 0.009573, Train Accuracy: 0.997075, Validation Accuracy: 0.780400\n",
      "Epoch [52/100], Step [100/1250], Loss: 0.006263, Train Accuracy: 0.996875\n",
      "Epoch [52/100], Step [200/1250], Loss: 0.069138, Train Accuracy: 0.997031\n",
      "Epoch [52/100], Step [300/1250], Loss: 0.002085, Train Accuracy: 0.997500\n",
      "Epoch [52/100], Step [400/1250], Loss: 0.000343, Train Accuracy: 0.997656\n",
      "Epoch [52/100], Step [500/1250], Loss: 0.040146, Train Accuracy: 0.997812\n",
      "Epoch [52/100], Step [600/1250], Loss: 0.004898, Train Accuracy: 0.997292\n",
      "Epoch [52/100], Step [700/1250], Loss: 0.018954, Train Accuracy: 0.997098\n",
      "Epoch [52/100], Step [800/1250], Loss: 0.006936, Train Accuracy: 0.997031\n",
      "Epoch [52/100], Step [900/1250], Loss: 0.008542, Train Accuracy: 0.997014\n",
      "Epoch [52/100], Step [1000/1250], Loss: 0.000698, Train Accuracy: 0.996781\n",
      "Epoch [52/100], Step [1100/1250], Loss: 0.000733, Train Accuracy: 0.996761\n",
      "Epoch [52/100], Step [1200/1250], Loss: 0.001820, Train Accuracy: 0.996849\n",
      "Epoch 52/100, Loss: 0.009996, Train Accuracy: 0.996900, Validation Accuracy: 0.781500\n",
      "Epoch [53/100], Step [100/1250], Loss: 0.001727, Train Accuracy: 0.998437\n",
      "Epoch [53/100], Step [200/1250], Loss: 0.000870, Train Accuracy: 0.997969\n",
      "Epoch [53/100], Step [300/1250], Loss: 0.000176, Train Accuracy: 0.997604\n",
      "Epoch [53/100], Step [400/1250], Loss: 0.000582, Train Accuracy: 0.997500\n",
      "Epoch [53/100], Step [500/1250], Loss: 0.013512, Train Accuracy: 0.997250\n",
      "Epoch [53/100], Step [600/1250], Loss: 0.006133, Train Accuracy: 0.997292\n",
      "Epoch [53/100], Step [700/1250], Loss: 0.001646, Train Accuracy: 0.997411\n",
      "Epoch [53/100], Step [800/1250], Loss: 0.000969, Train Accuracy: 0.997422\n",
      "Epoch [53/100], Step [900/1250], Loss: 0.059534, Train Accuracy: 0.997361\n",
      "Epoch [53/100], Step [1000/1250], Loss: 0.005722, Train Accuracy: 0.997156\n",
      "Epoch [53/100], Step [1100/1250], Loss: 0.001977, Train Accuracy: 0.997017\n",
      "Epoch [53/100], Step [1200/1250], Loss: 0.002439, Train Accuracy: 0.997083\n",
      "Epoch 53/100, Loss: 0.008951, Train Accuracy: 0.997150, Validation Accuracy: 0.779200\n",
      "Epoch [54/100], Step [100/1250], Loss: 0.023676, Train Accuracy: 0.996875\n",
      "Epoch [54/100], Step [200/1250], Loss: 0.001928, Train Accuracy: 0.997188\n",
      "Epoch [54/100], Step [300/1250], Loss: 0.003120, Train Accuracy: 0.997188\n",
      "Epoch [54/100], Step [400/1250], Loss: 0.001752, Train Accuracy: 0.997344\n",
      "Epoch [54/100], Step [500/1250], Loss: 0.003069, Train Accuracy: 0.997500\n",
      "Epoch [54/100], Step [600/1250], Loss: 0.007691, Train Accuracy: 0.997240\n",
      "Epoch [54/100], Step [700/1250], Loss: 0.002103, Train Accuracy: 0.997009\n",
      "Epoch [54/100], Step [800/1250], Loss: 0.001370, Train Accuracy: 0.997031\n",
      "Epoch [54/100], Step [900/1250], Loss: 0.000751, Train Accuracy: 0.996979\n",
      "Epoch [54/100], Step [1000/1250], Loss: 0.011879, Train Accuracy: 0.997000\n",
      "Epoch [54/100], Step [1100/1250], Loss: 0.000974, Train Accuracy: 0.996932\n",
      "Epoch [54/100], Step [1200/1250], Loss: 0.003174, Train Accuracy: 0.996901\n",
      "Epoch 54/100, Loss: 0.010668, Train Accuracy: 0.996925, Validation Accuracy: 0.773500\n",
      "Epoch [55/100], Step [100/1250], Loss: 0.132141, Train Accuracy: 0.992812\n",
      "Epoch [55/100], Step [200/1250], Loss: 0.001030, Train Accuracy: 0.995156\n",
      "Epoch [55/100], Step [300/1250], Loss: 0.003052, Train Accuracy: 0.996146\n",
      "Epoch [55/100], Step [400/1250], Loss: 0.000727, Train Accuracy: 0.996328\n",
      "Epoch [55/100], Step [500/1250], Loss: 0.001177, Train Accuracy: 0.996437\n",
      "Epoch [55/100], Step [600/1250], Loss: 0.000446, Train Accuracy: 0.996302\n",
      "Epoch [55/100], Step [700/1250], Loss: 0.000470, Train Accuracy: 0.996339\n",
      "Epoch [55/100], Step [800/1250], Loss: 0.000952, Train Accuracy: 0.996250\n",
      "Epoch [55/100], Step [900/1250], Loss: 0.089691, Train Accuracy: 0.996250\n",
      "Epoch [55/100], Step [1000/1250], Loss: 0.006049, Train Accuracy: 0.996437\n",
      "Epoch [55/100], Step [1100/1250], Loss: 0.007515, Train Accuracy: 0.996506\n",
      "Epoch [55/100], Step [1200/1250], Loss: 0.002614, Train Accuracy: 0.996589\n",
      "Epoch 55/100, Loss: 0.010766, Train Accuracy: 0.996550, Validation Accuracy: 0.781400\n",
      "Epoch [56/100], Step [100/1250], Loss: 0.010827, Train Accuracy: 0.999062\n",
      "Epoch [56/100], Step [200/1250], Loss: 0.008988, Train Accuracy: 0.998125\n",
      "Epoch [56/100], Step [300/1250], Loss: 0.021430, Train Accuracy: 0.998021\n",
      "Epoch [56/100], Step [400/1250], Loss: 0.002199, Train Accuracy: 0.997891\n",
      "Epoch [56/100], Step [500/1250], Loss: 0.000198, Train Accuracy: 0.997875\n",
      "Epoch [56/100], Step [600/1250], Loss: 0.000546, Train Accuracy: 0.997812\n",
      "Epoch [56/100], Step [700/1250], Loss: 0.005722, Train Accuracy: 0.997991\n",
      "Epoch [56/100], Step [800/1250], Loss: 0.000151, Train Accuracy: 0.998008\n",
      "Epoch [56/100], Step [900/1250], Loss: 0.000497, Train Accuracy: 0.997882\n",
      "Epoch [56/100], Step [1000/1250], Loss: 0.009456, Train Accuracy: 0.997875\n",
      "Epoch [56/100], Step [1100/1250], Loss: 0.004124, Train Accuracy: 0.997784\n",
      "Epoch [56/100], Step [1200/1250], Loss: 0.001237, Train Accuracy: 0.997760\n",
      "Epoch 56/100, Loss: 0.007391, Train Accuracy: 0.997825, Validation Accuracy: 0.782400\n",
      "Epoch [57/100], Step [100/1250], Loss: 0.000276, Train Accuracy: 0.997188\n",
      "Epoch [57/100], Step [200/1250], Loss: 0.001731, Train Accuracy: 0.997812\n",
      "Epoch [57/100], Step [300/1250], Loss: 0.002688, Train Accuracy: 0.998125\n",
      "Epoch [57/100], Step [400/1250], Loss: 0.000992, Train Accuracy: 0.997734\n",
      "Epoch [57/100], Step [500/1250], Loss: 0.019049, Train Accuracy: 0.997375\n",
      "Epoch [57/100], Step [600/1250], Loss: 0.001399, Train Accuracy: 0.997500\n",
      "Epoch [57/100], Step [700/1250], Loss: 0.002429, Train Accuracy: 0.997188\n",
      "Epoch [57/100], Step [800/1250], Loss: 0.000561, Train Accuracy: 0.997109\n",
      "Epoch [57/100], Step [900/1250], Loss: 0.001633, Train Accuracy: 0.996910\n",
      "Epoch [57/100], Step [1000/1250], Loss: 0.003007, Train Accuracy: 0.996906\n",
      "Epoch [57/100], Step [1100/1250], Loss: 0.007867, Train Accuracy: 0.996989\n",
      "Epoch [57/100], Step [1200/1250], Loss: 0.002147, Train Accuracy: 0.997057\n",
      "Epoch 57/100, Loss: 0.009758, Train Accuracy: 0.997025, Validation Accuracy: 0.783000\n",
      "Epoch [58/100], Step [100/1250], Loss: 0.000252, Train Accuracy: 0.996563\n",
      "Epoch [58/100], Step [200/1250], Loss: 0.004955, Train Accuracy: 0.997188\n",
      "Epoch [58/100], Step [300/1250], Loss: 0.005874, Train Accuracy: 0.997188\n",
      "Epoch [58/100], Step [400/1250], Loss: 0.001068, Train Accuracy: 0.997422\n",
      "Epoch [58/100], Step [500/1250], Loss: 0.000645, Train Accuracy: 0.996875\n",
      "Epoch [58/100], Step [600/1250], Loss: 0.000755, Train Accuracy: 0.996771\n",
      "Epoch [58/100], Step [700/1250], Loss: 0.000335, Train Accuracy: 0.997098\n",
      "Epoch [58/100], Step [800/1250], Loss: 0.000598, Train Accuracy: 0.997383\n",
      "Epoch [58/100], Step [900/1250], Loss: 0.000758, Train Accuracy: 0.997465\n",
      "Epoch [58/100], Step [1000/1250], Loss: 0.000838, Train Accuracy: 0.997531\n",
      "Epoch [58/100], Step [1100/1250], Loss: 0.001223, Train Accuracy: 0.997670\n",
      "Epoch [58/100], Step [1200/1250], Loss: 0.000661, Train Accuracy: 0.997682\n",
      "Epoch 58/100, Loss: 0.008051, Train Accuracy: 0.997600, Validation Accuracy: 0.789800\n",
      "Epoch [59/100], Step [100/1250], Loss: 0.000739, Train Accuracy: 0.996250\n",
      "Epoch [59/100], Step [200/1250], Loss: 0.028084, Train Accuracy: 0.997031\n",
      "Epoch [59/100], Step [300/1250], Loss: 0.004948, Train Accuracy: 0.997083\n",
      "Epoch [59/100], Step [400/1250], Loss: 0.000507, Train Accuracy: 0.996797\n",
      "Epoch [59/100], Step [500/1250], Loss: 0.055670, Train Accuracy: 0.996250\n",
      "Epoch [59/100], Step [600/1250], Loss: 0.005288, Train Accuracy: 0.996094\n",
      "Epoch [59/100], Step [700/1250], Loss: 0.009292, Train Accuracy: 0.996295\n",
      "Epoch [59/100], Step [800/1250], Loss: 0.001030, Train Accuracy: 0.996289\n",
      "Epoch [59/100], Step [900/1250], Loss: 0.009342, Train Accuracy: 0.996250\n",
      "Epoch [59/100], Step [1000/1250], Loss: 0.023135, Train Accuracy: 0.996250\n",
      "Epoch [59/100], Step [1100/1250], Loss: 0.000146, Train Accuracy: 0.996392\n",
      "Epoch [59/100], Step [1200/1250], Loss: 0.000998, Train Accuracy: 0.996458\n",
      "Epoch 59/100, Loss: 0.011702, Train Accuracy: 0.996400, Validation Accuracy: 0.782000\n",
      "Epoch [60/100], Step [100/1250], Loss: 0.012531, Train Accuracy: 0.998125\n",
      "Epoch [60/100], Step [200/1250], Loss: 0.007229, Train Accuracy: 0.998281\n",
      "Epoch [60/100], Step [300/1250], Loss: 0.030327, Train Accuracy: 0.998021\n",
      "Epoch [60/100], Step [400/1250], Loss: 0.040582, Train Accuracy: 0.997734\n",
      "Epoch [60/100], Step [500/1250], Loss: 0.001713, Train Accuracy: 0.997875\n",
      "Epoch [60/100], Step [600/1250], Loss: 0.011692, Train Accuracy: 0.997917\n",
      "Epoch [60/100], Step [700/1250], Loss: 0.000713, Train Accuracy: 0.998125\n",
      "Epoch [60/100], Step [800/1250], Loss: 0.000414, Train Accuracy: 0.998086\n",
      "Epoch [60/100], Step [900/1250], Loss: 0.007905, Train Accuracy: 0.998125\n",
      "Epoch [60/100], Step [1000/1250], Loss: 0.000225, Train Accuracy: 0.998250\n",
      "Epoch [60/100], Step [1100/1250], Loss: 0.000267, Train Accuracy: 0.998295\n",
      "Epoch [60/100], Step [1200/1250], Loss: 0.001854, Train Accuracy: 0.998255\n",
      "Epoch 60/100, Loss: 0.006197, Train Accuracy: 0.998075, Validation Accuracy: 0.777300\n",
      "Epoch [61/100], Step [100/1250], Loss: 0.004052, Train Accuracy: 0.996250\n",
      "Epoch [61/100], Step [200/1250], Loss: 0.001900, Train Accuracy: 0.996563\n",
      "Epoch [61/100], Step [300/1250], Loss: 0.001422, Train Accuracy: 0.996667\n",
      "Epoch [61/100], Step [400/1250], Loss: 0.088573, Train Accuracy: 0.997109\n",
      "Epoch [61/100], Step [500/1250], Loss: 0.000481, Train Accuracy: 0.997313\n",
      "Epoch [61/100], Step [600/1250], Loss: 0.074885, Train Accuracy: 0.997031\n",
      "Epoch [61/100], Step [700/1250], Loss: 0.000866, Train Accuracy: 0.996920\n",
      "Epoch [61/100], Step [800/1250], Loss: 0.002850, Train Accuracy: 0.996992\n",
      "Epoch [61/100], Step [900/1250], Loss: 0.003048, Train Accuracy: 0.996944\n",
      "Epoch [61/100], Step [1000/1250], Loss: 0.057119, Train Accuracy: 0.996875\n",
      "Epoch [61/100], Step [1100/1250], Loss: 0.006542, Train Accuracy: 0.996790\n",
      "Epoch [61/100], Step [1200/1250], Loss: 0.001422, Train Accuracy: 0.996901\n",
      "Epoch 61/100, Loss: 0.009932, Train Accuracy: 0.996975, Validation Accuracy: 0.782500\n",
      "Epoch [62/100], Step [100/1250], Loss: 0.001931, Train Accuracy: 0.999062\n",
      "Epoch [62/100], Step [200/1250], Loss: 0.000161, Train Accuracy: 0.998594\n",
      "Epoch [62/100], Step [300/1250], Loss: 0.000197, Train Accuracy: 0.998854\n",
      "Epoch [62/100], Step [400/1250], Loss: 0.004514, Train Accuracy: 0.998828\n",
      "Epoch [62/100], Step [500/1250], Loss: 0.000336, Train Accuracy: 0.998687\n",
      "Epoch [62/100], Step [600/1250], Loss: 0.001071, Train Accuracy: 0.998698\n",
      "Epoch [62/100], Step [700/1250], Loss: 0.000206, Train Accuracy: 0.998170\n",
      "Epoch [62/100], Step [800/1250], Loss: 0.000095, Train Accuracy: 0.998008\n",
      "Epoch [62/100], Step [900/1250], Loss: 0.000976, Train Accuracy: 0.997986\n",
      "Epoch [62/100], Step [1000/1250], Loss: 0.000743, Train Accuracy: 0.997875\n",
      "Epoch [62/100], Step [1100/1250], Loss: 0.000625, Train Accuracy: 0.997898\n",
      "Epoch [62/100], Step [1200/1250], Loss: 0.000500, Train Accuracy: 0.997812\n",
      "Epoch 62/100, Loss: 0.006833, Train Accuracy: 0.997800, Validation Accuracy: 0.780600\n",
      "Epoch [63/100], Step [100/1250], Loss: 0.006493, Train Accuracy: 0.998437\n",
      "Epoch [63/100], Step [200/1250], Loss: 0.004835, Train Accuracy: 0.998281\n",
      "Epoch [63/100], Step [300/1250], Loss: 0.000525, Train Accuracy: 0.998333\n",
      "Epoch [63/100], Step [400/1250], Loss: 0.007058, Train Accuracy: 0.998359\n",
      "Epoch [63/100], Step [500/1250], Loss: 0.006442, Train Accuracy: 0.998437\n",
      "Epoch [63/100], Step [600/1250], Loss: 0.004166, Train Accuracy: 0.998281\n",
      "Epoch [63/100], Step [700/1250], Loss: 0.000647, Train Accuracy: 0.998214\n",
      "Epoch [63/100], Step [800/1250], Loss: 0.001513, Train Accuracy: 0.998281\n",
      "Epoch [63/100], Step [900/1250], Loss: 0.005746, Train Accuracy: 0.998229\n",
      "Epoch [63/100], Step [1000/1250], Loss: 0.004183, Train Accuracy: 0.998094\n",
      "Epoch [63/100], Step [1100/1250], Loss: 0.048712, Train Accuracy: 0.998097\n",
      "Epoch [63/100], Step [1200/1250], Loss: 0.000490, Train Accuracy: 0.997969\n",
      "Epoch 63/100, Loss: 0.006700, Train Accuracy: 0.997975, Validation Accuracy: 0.783700\n",
      "Epoch [64/100], Step [100/1250], Loss: 0.003730, Train Accuracy: 0.997812\n",
      "Epoch [64/100], Step [200/1250], Loss: 0.000586, Train Accuracy: 0.997344\n",
      "Epoch [64/100], Step [300/1250], Loss: 0.000455, Train Accuracy: 0.997604\n",
      "Epoch [64/100], Step [400/1250], Loss: 0.000421, Train Accuracy: 0.997656\n",
      "Epoch [64/100], Step [500/1250], Loss: 0.140430, Train Accuracy: 0.997625\n",
      "Epoch [64/100], Step [600/1250], Loss: 0.000676, Train Accuracy: 0.997656\n",
      "Epoch [64/100], Step [700/1250], Loss: 0.008938, Train Accuracy: 0.997857\n",
      "Epoch [64/100], Step [800/1250], Loss: 0.004080, Train Accuracy: 0.997773\n",
      "Epoch [64/100], Step [900/1250], Loss: 0.005907, Train Accuracy: 0.997708\n",
      "Epoch [64/100], Step [1000/1250], Loss: 0.004535, Train Accuracy: 0.997750\n",
      "Epoch [64/100], Step [1100/1250], Loss: 0.000132, Train Accuracy: 0.997869\n",
      "Epoch [64/100], Step [1200/1250], Loss: 0.002745, Train Accuracy: 0.997839\n",
      "Epoch 64/100, Loss: 0.007740, Train Accuracy: 0.997850, Validation Accuracy: 0.784700\n",
      "Epoch [65/100], Step [100/1250], Loss: 0.003007, Train Accuracy: 0.997812\n",
      "Epoch [65/100], Step [200/1250], Loss: 0.003645, Train Accuracy: 0.997969\n",
      "Epoch [65/100], Step [300/1250], Loss: 0.005503, Train Accuracy: 0.997812\n",
      "Epoch [65/100], Step [400/1250], Loss: 0.000567, Train Accuracy: 0.997734\n",
      "Epoch [65/100], Step [500/1250], Loss: 0.001480, Train Accuracy: 0.997938\n",
      "Epoch [65/100], Step [600/1250], Loss: 0.002120, Train Accuracy: 0.998177\n",
      "Epoch [65/100], Step [700/1250], Loss: 0.000528, Train Accuracy: 0.998170\n",
      "Epoch [65/100], Step [800/1250], Loss: 0.013073, Train Accuracy: 0.998047\n",
      "Epoch [65/100], Step [900/1250], Loss: 0.000853, Train Accuracy: 0.998125\n",
      "Epoch [65/100], Step [1000/1250], Loss: 0.005571, Train Accuracy: 0.998125\n",
      "Epoch [65/100], Step [1100/1250], Loss: 0.000388, Train Accuracy: 0.997926\n",
      "Epoch [65/100], Step [1200/1250], Loss: 0.000423, Train Accuracy: 0.997708\n",
      "Epoch 65/100, Loss: 0.007315, Train Accuracy: 0.997775, Validation Accuracy: 0.784200\n",
      "Epoch [66/100], Step [100/1250], Loss: 0.000322, Train Accuracy: 0.999375\n",
      "Epoch [66/100], Step [200/1250], Loss: 0.000367, Train Accuracy: 0.999219\n",
      "Epoch [66/100], Step [300/1250], Loss: 0.048625, Train Accuracy: 0.998125\n",
      "Epoch [66/100], Step [400/1250], Loss: 0.002485, Train Accuracy: 0.998281\n",
      "Epoch [66/100], Step [500/1250], Loss: 0.001781, Train Accuracy: 0.997875\n",
      "Epoch [66/100], Step [600/1250], Loss: 0.002024, Train Accuracy: 0.997656\n",
      "Epoch [66/100], Step [700/1250], Loss: 0.001748, Train Accuracy: 0.997768\n",
      "Epoch [66/100], Step [800/1250], Loss: 0.009172, Train Accuracy: 0.997852\n",
      "Epoch [66/100], Step [900/1250], Loss: 0.001564, Train Accuracy: 0.997917\n",
      "Epoch [66/100], Step [1000/1250], Loss: 0.016603, Train Accuracy: 0.997938\n",
      "Epoch [66/100], Step [1100/1250], Loss: 0.000636, Train Accuracy: 0.997955\n",
      "Epoch [66/100], Step [1200/1250], Loss: 0.001155, Train Accuracy: 0.998021\n",
      "Epoch 66/100, Loss: 0.006614, Train Accuracy: 0.998075, Validation Accuracy: 0.787800\n",
      "Epoch [67/100], Step [100/1250], Loss: 0.002048, Train Accuracy: 0.998750\n",
      "Epoch [67/100], Step [200/1250], Loss: 0.000782, Train Accuracy: 0.998125\n",
      "Epoch [67/100], Step [300/1250], Loss: 0.000192, Train Accuracy: 0.998229\n",
      "Epoch [67/100], Step [400/1250], Loss: 0.001670, Train Accuracy: 0.998203\n",
      "Epoch [67/100], Step [500/1250], Loss: 0.000792, Train Accuracy: 0.998188\n",
      "Epoch [67/100], Step [600/1250], Loss: 0.000943, Train Accuracy: 0.998177\n",
      "Epoch [67/100], Step [700/1250], Loss: 0.006603, Train Accuracy: 0.998259\n",
      "Epoch [67/100], Step [800/1250], Loss: 0.000465, Train Accuracy: 0.998320\n",
      "Epoch [67/100], Step [900/1250], Loss: 0.000344, Train Accuracy: 0.998403\n",
      "Epoch [67/100], Step [1000/1250], Loss: 0.002002, Train Accuracy: 0.998313\n",
      "Epoch [67/100], Step [1100/1250], Loss: 0.007274, Train Accuracy: 0.998153\n",
      "Epoch [67/100], Step [1200/1250], Loss: 0.000250, Train Accuracy: 0.998021\n",
      "Epoch 67/100, Loss: 0.006460, Train Accuracy: 0.997950, Validation Accuracy: 0.784000\n",
      "Epoch [68/100], Step [100/1250], Loss: 0.000362, Train Accuracy: 0.998437\n",
      "Epoch [68/100], Step [200/1250], Loss: 0.000134, Train Accuracy: 0.998281\n",
      "Epoch [68/100], Step [300/1250], Loss: 0.000585, Train Accuracy: 0.998437\n",
      "Epoch [68/100], Step [400/1250], Loss: 0.000302, Train Accuracy: 0.998203\n",
      "Epoch [68/100], Step [500/1250], Loss: 0.000324, Train Accuracy: 0.998188\n",
      "Epoch [68/100], Step [600/1250], Loss: 0.012933, Train Accuracy: 0.997812\n",
      "Epoch [68/100], Step [700/1250], Loss: 0.000258, Train Accuracy: 0.997857\n",
      "Epoch [68/100], Step [800/1250], Loss: 0.000151, Train Accuracy: 0.997734\n",
      "Epoch [68/100], Step [900/1250], Loss: 0.001041, Train Accuracy: 0.997847\n",
      "Epoch [68/100], Step [1000/1250], Loss: 0.068942, Train Accuracy: 0.997719\n",
      "Epoch [68/100], Step [1100/1250], Loss: 0.001813, Train Accuracy: 0.997869\n",
      "Epoch [68/100], Step [1200/1250], Loss: 0.000493, Train Accuracy: 0.997891\n",
      "Epoch 68/100, Loss: 0.006359, Train Accuracy: 0.997950, Validation Accuracy: 0.785600\n",
      "Epoch [69/100], Step [100/1250], Loss: 0.000326, Train Accuracy: 0.999375\n",
      "Epoch [69/100], Step [200/1250], Loss: 0.001269, Train Accuracy: 0.998750\n",
      "Epoch [69/100], Step [300/1250], Loss: 0.001073, Train Accuracy: 0.998646\n",
      "Epoch [69/100], Step [400/1250], Loss: 0.001065, Train Accuracy: 0.998594\n",
      "Epoch [69/100], Step [500/1250], Loss: 0.000696, Train Accuracy: 0.998625\n",
      "Epoch [69/100], Step [600/1250], Loss: 0.000326, Train Accuracy: 0.998229\n",
      "Epoch [69/100], Step [700/1250], Loss: 0.000800, Train Accuracy: 0.998304\n",
      "Epoch [69/100], Step [800/1250], Loss: 0.000712, Train Accuracy: 0.998203\n",
      "Epoch [69/100], Step [900/1250], Loss: 0.011889, Train Accuracy: 0.998125\n",
      "Epoch [69/100], Step [1000/1250], Loss: 0.005209, Train Accuracy: 0.998188\n",
      "Epoch [69/100], Step [1100/1250], Loss: 0.000152, Train Accuracy: 0.998182\n",
      "Epoch [69/100], Step [1200/1250], Loss: 0.000197, Train Accuracy: 0.997995\n",
      "Epoch 69/100, Loss: 0.006769, Train Accuracy: 0.997925, Validation Accuracy: 0.783200\n",
      "Epoch [70/100], Step [100/1250], Loss: 0.000383, Train Accuracy: 0.998437\n",
      "Epoch [70/100], Step [200/1250], Loss: 0.000169, Train Accuracy: 0.998437\n",
      "Epoch [70/100], Step [300/1250], Loss: 0.000132, Train Accuracy: 0.998646\n",
      "Epoch [70/100], Step [400/1250], Loss: 0.000063, Train Accuracy: 0.998672\n",
      "Epoch [70/100], Step [500/1250], Loss: 0.003700, Train Accuracy: 0.998875\n",
      "Epoch [70/100], Step [600/1250], Loss: 0.054531, Train Accuracy: 0.998698\n",
      "Epoch [70/100], Step [700/1250], Loss: 0.000665, Train Accuracy: 0.998214\n",
      "Epoch [70/100], Step [800/1250], Loss: 0.000751, Train Accuracy: 0.997930\n",
      "Epoch [70/100], Step [900/1250], Loss: 0.000546, Train Accuracy: 0.997812\n",
      "Epoch [70/100], Step [1000/1250], Loss: 0.000084, Train Accuracy: 0.997969\n",
      "Epoch [70/100], Step [1100/1250], Loss: 0.003270, Train Accuracy: 0.997983\n",
      "Epoch [70/100], Step [1200/1250], Loss: 0.000348, Train Accuracy: 0.997969\n",
      "Epoch 70/100, Loss: 0.006899, Train Accuracy: 0.998000, Validation Accuracy: 0.783300\n",
      "Epoch [71/100], Step [100/1250], Loss: 0.000460, Train Accuracy: 0.997500\n",
      "Epoch [71/100], Step [200/1250], Loss: 0.003203, Train Accuracy: 0.998750\n",
      "Epoch [71/100], Step [300/1250], Loss: 0.004512, Train Accuracy: 0.999062\n",
      "Epoch [71/100], Step [400/1250], Loss: 0.000214, Train Accuracy: 0.998516\n",
      "Epoch [71/100], Step [500/1250], Loss: 0.002530, Train Accuracy: 0.998437\n",
      "Epoch [71/100], Step [600/1250], Loss: 0.002990, Train Accuracy: 0.998542\n",
      "Epoch [71/100], Step [700/1250], Loss: 0.001289, Train Accuracy: 0.998571\n",
      "Epoch [71/100], Step [800/1250], Loss: 0.014017, Train Accuracy: 0.998359\n",
      "Epoch [71/100], Step [900/1250], Loss: 0.007108, Train Accuracy: 0.998403\n",
      "Epoch [71/100], Step [1000/1250], Loss: 0.001275, Train Accuracy: 0.998375\n",
      "Epoch [71/100], Step [1100/1250], Loss: 0.063951, Train Accuracy: 0.998466\n",
      "Epoch [71/100], Step [1200/1250], Loss: 0.000109, Train Accuracy: 0.998307\n",
      "Epoch 71/100, Loss: 0.005792, Train Accuracy: 0.998275, Validation Accuracy: 0.780800\n",
      "Epoch [72/100], Step [100/1250], Loss: 0.002755, Train Accuracy: 0.997188\n",
      "Epoch [72/100], Step [200/1250], Loss: 0.002597, Train Accuracy: 0.997812\n",
      "Epoch [72/100], Step [300/1250], Loss: 0.000152, Train Accuracy: 0.998229\n",
      "Epoch [72/100], Step [400/1250], Loss: 0.065251, Train Accuracy: 0.998203\n",
      "Epoch [72/100], Step [500/1250], Loss: 0.000157, Train Accuracy: 0.998250\n",
      "Epoch [72/100], Step [600/1250], Loss: 0.027159, Train Accuracy: 0.998177\n",
      "Epoch [72/100], Step [700/1250], Loss: 0.001036, Train Accuracy: 0.998080\n",
      "Epoch [72/100], Step [800/1250], Loss: 0.000168, Train Accuracy: 0.998203\n",
      "Epoch [72/100], Step [900/1250], Loss: 0.010305, Train Accuracy: 0.998333\n",
      "Epoch [72/100], Step [1000/1250], Loss: 0.282530, Train Accuracy: 0.998344\n",
      "Epoch [72/100], Step [1100/1250], Loss: 0.001106, Train Accuracy: 0.998295\n",
      "Epoch [72/100], Step [1200/1250], Loss: 0.000482, Train Accuracy: 0.998177\n",
      "Epoch 72/100, Loss: 0.006503, Train Accuracy: 0.998150, Validation Accuracy: 0.779300\n",
      "Epoch [73/100], Step [100/1250], Loss: 0.031679, Train Accuracy: 0.996875\n",
      "Epoch [73/100], Step [200/1250], Loss: 0.000117, Train Accuracy: 0.997188\n",
      "Epoch [73/100], Step [300/1250], Loss: 0.000347, Train Accuracy: 0.997708\n",
      "Epoch [73/100], Step [400/1250], Loss: 0.015022, Train Accuracy: 0.997578\n",
      "Epoch [73/100], Step [500/1250], Loss: 0.002267, Train Accuracy: 0.997875\n",
      "Epoch [73/100], Step [600/1250], Loss: 0.000281, Train Accuracy: 0.997812\n",
      "Epoch [73/100], Step [700/1250], Loss: 0.003665, Train Accuracy: 0.997902\n",
      "Epoch [73/100], Step [800/1250], Loss: 0.002087, Train Accuracy: 0.997930\n",
      "Epoch [73/100], Step [900/1250], Loss: 0.000864, Train Accuracy: 0.998021\n",
      "Epoch [73/100], Step [1000/1250], Loss: 0.001175, Train Accuracy: 0.998031\n",
      "Epoch [73/100], Step [1100/1250], Loss: 0.000165, Train Accuracy: 0.997983\n",
      "Epoch [73/100], Step [1200/1250], Loss: 0.000615, Train Accuracy: 0.998021\n",
      "Epoch 73/100, Loss: 0.006370, Train Accuracy: 0.997950, Validation Accuracy: 0.779800\n",
      "Epoch [74/100], Step [100/1250], Loss: 0.000051, Train Accuracy: 0.997188\n",
      "Epoch [74/100], Step [200/1250], Loss: 0.000854, Train Accuracy: 0.996875\n",
      "Epoch [74/100], Step [300/1250], Loss: 0.000333, Train Accuracy: 0.997500\n",
      "Epoch [74/100], Step [400/1250], Loss: 0.005995, Train Accuracy: 0.997656\n",
      "Epoch [74/100], Step [500/1250], Loss: 0.000870, Train Accuracy: 0.997750\n",
      "Epoch [74/100], Step [600/1250], Loss: 0.000975, Train Accuracy: 0.997708\n",
      "Epoch [74/100], Step [700/1250], Loss: 0.007309, Train Accuracy: 0.997589\n",
      "Epoch [74/100], Step [800/1250], Loss: 0.001718, Train Accuracy: 0.997383\n",
      "Epoch [74/100], Step [900/1250], Loss: 0.006461, Train Accuracy: 0.997292\n",
      "Epoch [74/100], Step [1000/1250], Loss: 0.000683, Train Accuracy: 0.997406\n",
      "Epoch [74/100], Step [1100/1250], Loss: 0.000113, Train Accuracy: 0.997358\n",
      "Epoch [74/100], Step [1200/1250], Loss: 0.000362, Train Accuracy: 0.997266\n",
      "Epoch 74/100, Loss: 0.007261, Train Accuracy: 0.997375, Validation Accuracy: 0.788400\n",
      "Epoch [75/100], Step [100/1250], Loss: 0.001357, Train Accuracy: 0.999062\n",
      "Epoch [75/100], Step [200/1250], Loss: 0.000666, Train Accuracy: 0.998594\n",
      "Epoch [75/100], Step [300/1250], Loss: 0.000297, Train Accuracy: 0.998958\n",
      "Epoch [75/100], Step [400/1250], Loss: 0.000736, Train Accuracy: 0.998906\n",
      "Epoch [75/100], Step [500/1250], Loss: 0.000283, Train Accuracy: 0.998750\n",
      "Epoch [75/100], Step [600/1250], Loss: 0.000241, Train Accuracy: 0.998854\n",
      "Epoch [75/100], Step [700/1250], Loss: 0.000235, Train Accuracy: 0.998884\n",
      "Epoch [75/100], Step [800/1250], Loss: 0.000336, Train Accuracy: 0.998906\n",
      "Epoch [75/100], Step [900/1250], Loss: 0.000765, Train Accuracy: 0.998889\n",
      "Epoch [75/100], Step [1000/1250], Loss: 0.034361, Train Accuracy: 0.998938\n",
      "Epoch [75/100], Step [1100/1250], Loss: 0.001150, Train Accuracy: 0.998864\n",
      "Epoch [75/100], Step [1200/1250], Loss: 0.000490, Train Accuracy: 0.998880\n",
      "Epoch 75/100, Loss: 0.004897, Train Accuracy: 0.998900, Validation Accuracy: 0.788200\n",
      "Epoch [76/100], Step [100/1250], Loss: 0.002214, Train Accuracy: 0.998750\n",
      "Epoch [76/100], Step [200/1250], Loss: 0.005140, Train Accuracy: 0.998281\n",
      "Epoch [76/100], Step [300/1250], Loss: 0.000330, Train Accuracy: 0.998542\n",
      "Epoch [76/100], Step [400/1250], Loss: 0.000418, Train Accuracy: 0.997969\n",
      "Epoch [76/100], Step [500/1250], Loss: 0.009055, Train Accuracy: 0.997563\n",
      "Epoch [76/100], Step [600/1250], Loss: 0.000624, Train Accuracy: 0.997656\n",
      "Epoch [76/100], Step [700/1250], Loss: 0.000154, Train Accuracy: 0.997812\n",
      "Epoch [76/100], Step [800/1250], Loss: 0.000136, Train Accuracy: 0.997773\n",
      "Epoch [76/100], Step [900/1250], Loss: 0.000135, Train Accuracy: 0.997778\n",
      "Epoch [76/100], Step [1000/1250], Loss: 0.000553, Train Accuracy: 0.997625\n",
      "Epoch [76/100], Step [1100/1250], Loss: 0.050648, Train Accuracy: 0.997528\n",
      "Epoch [76/100], Step [1200/1250], Loss: 0.000164, Train Accuracy: 0.997500\n",
      "Epoch 76/100, Loss: 0.007577, Train Accuracy: 0.997550, Validation Accuracy: 0.781700\n",
      "Epoch [77/100], Step [100/1250], Loss: 0.017351, Train Accuracy: 0.999687\n",
      "Epoch [77/100], Step [200/1250], Loss: 0.001753, Train Accuracy: 0.999687\n",
      "Epoch [77/100], Step [300/1250], Loss: 0.001167, Train Accuracy: 0.999479\n",
      "Epoch [77/100], Step [400/1250], Loss: 0.004348, Train Accuracy: 0.999453\n",
      "Epoch [77/100], Step [500/1250], Loss: 0.001644, Train Accuracy: 0.999500\n",
      "Epoch [77/100], Step [600/1250], Loss: 0.000216, Train Accuracy: 0.999427\n",
      "Epoch [77/100], Step [700/1250], Loss: 0.000286, Train Accuracy: 0.999420\n",
      "Epoch [77/100], Step [800/1250], Loss: 0.000446, Train Accuracy: 0.999375\n",
      "Epoch [77/100], Step [900/1250], Loss: 0.000731, Train Accuracy: 0.999236\n",
      "Epoch [77/100], Step [1000/1250], Loss: 0.000173, Train Accuracy: 0.999188\n",
      "Epoch [77/100], Step [1100/1250], Loss: 0.000277, Train Accuracy: 0.999062\n",
      "Epoch [77/100], Step [1200/1250], Loss: 0.001639, Train Accuracy: 0.998984\n",
      "Epoch 77/100, Loss: 0.004448, Train Accuracy: 0.999000, Validation Accuracy: 0.784600\n",
      "Epoch [78/100], Step [100/1250], Loss: 0.000083, Train Accuracy: 0.999062\n",
      "Epoch [78/100], Step [200/1250], Loss: 0.000169, Train Accuracy: 0.998906\n",
      "Epoch [78/100], Step [300/1250], Loss: 0.001630, Train Accuracy: 0.998854\n",
      "Epoch [78/100], Step [400/1250], Loss: 0.000211, Train Accuracy: 0.998906\n",
      "Epoch [78/100], Step [500/1250], Loss: 0.000086, Train Accuracy: 0.998938\n",
      "Epoch [78/100], Step [600/1250], Loss: 0.000629, Train Accuracy: 0.998437\n",
      "Epoch [78/100], Step [700/1250], Loss: 0.001736, Train Accuracy: 0.998170\n",
      "Epoch [78/100], Step [800/1250], Loss: 0.004998, Train Accuracy: 0.998242\n",
      "Epoch [78/100], Step [900/1250], Loss: 0.002605, Train Accuracy: 0.998229\n",
      "Epoch [78/100], Step [1000/1250], Loss: 0.079257, Train Accuracy: 0.998062\n",
      "Epoch [78/100], Step [1100/1250], Loss: 0.000184, Train Accuracy: 0.998210\n",
      "Epoch [78/100], Step [1200/1250], Loss: 0.000152, Train Accuracy: 0.998203\n",
      "Epoch 78/100, Loss: 0.006012, Train Accuracy: 0.998250, Validation Accuracy: 0.787000\n",
      "Epoch [79/100], Step [100/1250], Loss: 0.003626, Train Accuracy: 0.997188\n",
      "Epoch [79/100], Step [200/1250], Loss: 0.002191, Train Accuracy: 0.998281\n",
      "Epoch [79/100], Step [300/1250], Loss: 0.000870, Train Accuracy: 0.998646\n",
      "Epoch [79/100], Step [400/1250], Loss: 0.017679, Train Accuracy: 0.998516\n",
      "Epoch [79/100], Step [500/1250], Loss: 0.000115, Train Accuracy: 0.997938\n",
      "Epoch [79/100], Step [600/1250], Loss: 0.023715, Train Accuracy: 0.997865\n",
      "Epoch [79/100], Step [700/1250], Loss: 0.000945, Train Accuracy: 0.997902\n",
      "Epoch [79/100], Step [800/1250], Loss: 0.003531, Train Accuracy: 0.997852\n",
      "Epoch [79/100], Step [900/1250], Loss: 0.000419, Train Accuracy: 0.997917\n",
      "Epoch [79/100], Step [1000/1250], Loss: 0.000371, Train Accuracy: 0.998062\n",
      "Epoch [79/100], Step [1100/1250], Loss: 0.075722, Train Accuracy: 0.998210\n",
      "Epoch [79/100], Step [1200/1250], Loss: 0.001278, Train Accuracy: 0.998229\n",
      "Epoch 79/100, Loss: 0.006041, Train Accuracy: 0.998225, Validation Accuracy: 0.785300\n",
      "Epoch [80/100], Step [100/1250], Loss: 0.012641, Train Accuracy: 0.999375\n",
      "Epoch [80/100], Step [200/1250], Loss: 0.000194, Train Accuracy: 0.999062\n",
      "Epoch [80/100], Step [300/1250], Loss: 0.000291, Train Accuracy: 0.998646\n",
      "Epoch [80/100], Step [400/1250], Loss: 0.006716, Train Accuracy: 0.998594\n",
      "Epoch [80/100], Step [500/1250], Loss: 0.006702, Train Accuracy: 0.998812\n",
      "Epoch [80/100], Step [600/1250], Loss: 0.000803, Train Accuracy: 0.998854\n",
      "Epoch [80/100], Step [700/1250], Loss: 0.000253, Train Accuracy: 0.998795\n",
      "Epoch [80/100], Step [800/1250], Loss: 0.007344, Train Accuracy: 0.998711\n",
      "Epoch [80/100], Step [900/1250], Loss: 0.000411, Train Accuracy: 0.998785\n",
      "Epoch [80/100], Step [1000/1250], Loss: 0.002864, Train Accuracy: 0.998687\n",
      "Epoch [80/100], Step [1100/1250], Loss: 0.004200, Train Accuracy: 0.998636\n",
      "Epoch [80/100], Step [1200/1250], Loss: 0.000672, Train Accuracy: 0.998698\n",
      "Epoch 80/100, Loss: 0.004288, Train Accuracy: 0.998750, Validation Accuracy: 0.785600\n",
      "Epoch [81/100], Step [100/1250], Loss: 0.000472, Train Accuracy: 0.999375\n",
      "Epoch [81/100], Step [200/1250], Loss: 0.002761, Train Accuracy: 0.998594\n",
      "Epoch [81/100], Step [300/1250], Loss: 0.001344, Train Accuracy: 0.998750\n",
      "Epoch [81/100], Step [400/1250], Loss: 0.000704, Train Accuracy: 0.998750\n",
      "Epoch [81/100], Step [500/1250], Loss: 0.000537, Train Accuracy: 0.998625\n",
      "Epoch [81/100], Step [600/1250], Loss: 0.000193, Train Accuracy: 0.998594\n",
      "Epoch [81/100], Step [700/1250], Loss: 0.000262, Train Accuracy: 0.998482\n",
      "Epoch [81/100], Step [800/1250], Loss: 0.000241, Train Accuracy: 0.998437\n",
      "Epoch [81/100], Step [900/1250], Loss: 0.001109, Train Accuracy: 0.998472\n",
      "Epoch [81/100], Step [1000/1250], Loss: 0.005432, Train Accuracy: 0.998531\n",
      "Epoch [81/100], Step [1100/1250], Loss: 0.000194, Train Accuracy: 0.998665\n",
      "Epoch [81/100], Step [1200/1250], Loss: 0.032584, Train Accuracy: 0.998646\n",
      "Epoch 81/100, Loss: 0.004368, Train Accuracy: 0.998675, Validation Accuracy: 0.784300\n",
      "Epoch [82/100], Step [100/1250], Loss: 0.003539, Train Accuracy: 0.998750\n",
      "Epoch [82/100], Step [200/1250], Loss: 0.004353, Train Accuracy: 0.998437\n",
      "Epoch [82/100], Step [300/1250], Loss: 0.026477, Train Accuracy: 0.998021\n",
      "Epoch [82/100], Step [400/1250], Loss: 0.001106, Train Accuracy: 0.998359\n",
      "Epoch [82/100], Step [500/1250], Loss: 0.000833, Train Accuracy: 0.998375\n",
      "Epoch [82/100], Step [600/1250], Loss: 0.001548, Train Accuracy: 0.998229\n",
      "Epoch [82/100], Step [700/1250], Loss: 0.000165, Train Accuracy: 0.998259\n",
      "Epoch [82/100], Step [800/1250], Loss: 0.001849, Train Accuracy: 0.998086\n",
      "Epoch [82/100], Step [900/1250], Loss: 0.171716, Train Accuracy: 0.997778\n",
      "Epoch [82/100], Step [1000/1250], Loss: 0.005397, Train Accuracy: 0.997750\n",
      "Epoch [82/100], Step [1100/1250], Loss: 0.004458, Train Accuracy: 0.997670\n",
      "Epoch [82/100], Step [1200/1250], Loss: 0.006745, Train Accuracy: 0.997682\n",
      "Epoch 82/100, Loss: 0.007671, Train Accuracy: 0.997725, Validation Accuracy: 0.783300\n",
      "Epoch [83/100], Step [100/1250], Loss: 0.001197, Train Accuracy: 0.998437\n",
      "Epoch [83/100], Step [200/1250], Loss: 0.000503, Train Accuracy: 0.997812\n",
      "Epoch [83/100], Step [300/1250], Loss: 0.000438, Train Accuracy: 0.997917\n",
      "Epoch [83/100], Step [400/1250], Loss: 0.000474, Train Accuracy: 0.997969\n",
      "Epoch [83/100], Step [500/1250], Loss: 0.003763, Train Accuracy: 0.998188\n",
      "Epoch [83/100], Step [600/1250], Loss: 0.009283, Train Accuracy: 0.998229\n",
      "Epoch [83/100], Step [700/1250], Loss: 0.000443, Train Accuracy: 0.998259\n",
      "Epoch [83/100], Step [800/1250], Loss: 0.000223, Train Accuracy: 0.998359\n",
      "Epoch [83/100], Step [900/1250], Loss: 0.000360, Train Accuracy: 0.998333\n",
      "Epoch [83/100], Step [1000/1250], Loss: 0.000334, Train Accuracy: 0.998437\n",
      "Epoch [83/100], Step [1100/1250], Loss: 0.000385, Train Accuracy: 0.998580\n",
      "Epoch [83/100], Step [1200/1250], Loss: 0.016097, Train Accuracy: 0.998620\n",
      "Epoch 83/100, Loss: 0.004682, Train Accuracy: 0.998625, Validation Accuracy: 0.786600\n",
      "Epoch [84/100], Step [100/1250], Loss: 0.000617, Train Accuracy: 0.998437\n",
      "Epoch [84/100], Step [200/1250], Loss: 0.000579, Train Accuracy: 0.998281\n",
      "Epoch [84/100], Step [300/1250], Loss: 0.000420, Train Accuracy: 0.998125\n",
      "Epoch [84/100], Step [400/1250], Loss: 0.000121, Train Accuracy: 0.998281\n",
      "Epoch [84/100], Step [500/1250], Loss: 0.002471, Train Accuracy: 0.998375\n",
      "Epoch [84/100], Step [600/1250], Loss: 0.000457, Train Accuracy: 0.998281\n",
      "Epoch [84/100], Step [700/1250], Loss: 0.000297, Train Accuracy: 0.998348\n",
      "Epoch [84/100], Step [800/1250], Loss: 0.000122, Train Accuracy: 0.998203\n",
      "Epoch [84/100], Step [900/1250], Loss: 0.001355, Train Accuracy: 0.998021\n",
      "Epoch [84/100], Step [1000/1250], Loss: 0.001460, Train Accuracy: 0.998031\n",
      "Epoch [84/100], Step [1100/1250], Loss: 0.003421, Train Accuracy: 0.998097\n",
      "Epoch [84/100], Step [1200/1250], Loss: 0.000864, Train Accuracy: 0.998073\n",
      "Epoch 84/100, Loss: 0.005576, Train Accuracy: 0.998150, Validation Accuracy: 0.782100\n",
      "Epoch [85/100], Step [100/1250], Loss: 0.001297, Train Accuracy: 1.000000\n",
      "Epoch [85/100], Step [200/1250], Loss: 0.000215, Train Accuracy: 0.999219\n",
      "Epoch [85/100], Step [300/1250], Loss: 0.000532, Train Accuracy: 0.999167\n",
      "Epoch [85/100], Step [400/1250], Loss: 0.000106, Train Accuracy: 0.999062\n",
      "Epoch [85/100], Step [500/1250], Loss: 0.003439, Train Accuracy: 0.999250\n",
      "Epoch [85/100], Step [600/1250], Loss: 0.000201, Train Accuracy: 0.999115\n",
      "Epoch [85/100], Step [700/1250], Loss: 0.000682, Train Accuracy: 0.998973\n",
      "Epoch [85/100], Step [800/1250], Loss: 0.000145, Train Accuracy: 0.998867\n",
      "Epoch [85/100], Step [900/1250], Loss: 0.000614, Train Accuracy: 0.998681\n",
      "Epoch [85/100], Step [1000/1250], Loss: 0.000233, Train Accuracy: 0.998687\n",
      "Epoch [85/100], Step [1100/1250], Loss: 0.002559, Train Accuracy: 0.998551\n",
      "Epoch [85/100], Step [1200/1250], Loss: 0.001067, Train Accuracy: 0.998594\n",
      "Epoch 85/100, Loss: 0.004998, Train Accuracy: 0.998575, Validation Accuracy: 0.785900\n",
      "Epoch [86/100], Step [100/1250], Loss: 0.012439, Train Accuracy: 0.998750\n",
      "Epoch [86/100], Step [200/1250], Loss: 0.003389, Train Accuracy: 0.997344\n",
      "Epoch [86/100], Step [300/1250], Loss: 0.000205, Train Accuracy: 0.997604\n",
      "Epoch [86/100], Step [400/1250], Loss: 0.000244, Train Accuracy: 0.997734\n",
      "Epoch [86/100], Step [500/1250], Loss: 0.004179, Train Accuracy: 0.998000\n",
      "Epoch [86/100], Step [600/1250], Loss: 0.003720, Train Accuracy: 0.998229\n",
      "Epoch [86/100], Step [700/1250], Loss: 0.000099, Train Accuracy: 0.998304\n",
      "Epoch [86/100], Step [800/1250], Loss: 0.000530, Train Accuracy: 0.998398\n",
      "Epoch [86/100], Step [900/1250], Loss: 0.000487, Train Accuracy: 0.998368\n",
      "Epoch [86/100], Step [1000/1250], Loss: 0.000778, Train Accuracy: 0.998406\n",
      "Epoch [86/100], Step [1100/1250], Loss: 0.000996, Train Accuracy: 0.998437\n",
      "Epoch [86/100], Step [1200/1250], Loss: 0.000210, Train Accuracy: 0.998464\n",
      "Epoch 86/100, Loss: 0.005328, Train Accuracy: 0.998500, Validation Accuracy: 0.787500\n",
      "Epoch [87/100], Step [100/1250], Loss: 0.000149, Train Accuracy: 0.998750\n",
      "Epoch [87/100], Step [200/1250], Loss: 0.000533, Train Accuracy: 0.998750\n",
      "Epoch [87/100], Step [300/1250], Loss: 0.000490, Train Accuracy: 0.998333\n",
      "Epoch [87/100], Step [400/1250], Loss: 0.001966, Train Accuracy: 0.998672\n",
      "Epoch [87/100], Step [500/1250], Loss: 0.000325, Train Accuracy: 0.998812\n",
      "Epoch [87/100], Step [600/1250], Loss: 0.000081, Train Accuracy: 0.998854\n",
      "Epoch [87/100], Step [700/1250], Loss: 0.002524, Train Accuracy: 0.998929\n",
      "Epoch [87/100], Step [800/1250], Loss: 0.000349, Train Accuracy: 0.998984\n",
      "Epoch [87/100], Step [900/1250], Loss: 0.000742, Train Accuracy: 0.998958\n",
      "Epoch [87/100], Step [1000/1250], Loss: 0.000394, Train Accuracy: 0.998938\n",
      "Epoch [87/100], Step [1100/1250], Loss: 0.001569, Train Accuracy: 0.998807\n",
      "Epoch [87/100], Step [1200/1250], Loss: 0.000471, Train Accuracy: 0.998724\n",
      "Epoch 87/100, Loss: 0.004352, Train Accuracy: 0.998625, Validation Accuracy: 0.787100\n",
      "Epoch [88/100], Step [100/1250], Loss: 0.000125, Train Accuracy: 0.999062\n",
      "Epoch [88/100], Step [200/1250], Loss: 0.014129, Train Accuracy: 0.998437\n",
      "Epoch [88/100], Step [300/1250], Loss: 0.006609, Train Accuracy: 0.998750\n",
      "Epoch [88/100], Step [400/1250], Loss: 0.006172, Train Accuracy: 0.998437\n",
      "Epoch [88/100], Step [500/1250], Loss: 0.001310, Train Accuracy: 0.998437\n",
      "Epoch [88/100], Step [600/1250], Loss: 0.000341, Train Accuracy: 0.998542\n",
      "Epoch [88/100], Step [700/1250], Loss: 0.092523, Train Accuracy: 0.998616\n",
      "Epoch [88/100], Step [800/1250], Loss: 0.009760, Train Accuracy: 0.998594\n",
      "Epoch [88/100], Step [900/1250], Loss: 0.000144, Train Accuracy: 0.998681\n",
      "Epoch [88/100], Step [1000/1250], Loss: 0.000909, Train Accuracy: 0.998219\n",
      "Epoch [88/100], Step [1100/1250], Loss: 0.001152, Train Accuracy: 0.998125\n",
      "Epoch [88/100], Step [1200/1250], Loss: 0.000321, Train Accuracy: 0.998177\n",
      "Epoch 88/100, Loss: 0.005664, Train Accuracy: 0.998200, Validation Accuracy: 0.781500\n",
      "Epoch [89/100], Step [100/1250], Loss: 0.000213, Train Accuracy: 0.998750\n",
      "Epoch [89/100], Step [200/1250], Loss: 0.000327, Train Accuracy: 0.998906\n",
      "Epoch [89/100], Step [300/1250], Loss: 0.007173, Train Accuracy: 0.998646\n",
      "Epoch [89/100], Step [400/1250], Loss: 0.000145, Train Accuracy: 0.998750\n",
      "Epoch [89/100], Step [500/1250], Loss: 0.004644, Train Accuracy: 0.998812\n",
      "Epoch [89/100], Step [600/1250], Loss: 0.000470, Train Accuracy: 0.998802\n",
      "Epoch [89/100], Step [700/1250], Loss: 0.000213, Train Accuracy: 0.998929\n",
      "Epoch [89/100], Step [800/1250], Loss: 0.000681, Train Accuracy: 0.998984\n",
      "Epoch [89/100], Step [900/1250], Loss: 0.000609, Train Accuracy: 0.998958\n",
      "Epoch [89/100], Step [1000/1250], Loss: 0.000540, Train Accuracy: 0.998875\n",
      "Epoch [89/100], Step [1100/1250], Loss: 0.000144, Train Accuracy: 0.998807\n",
      "Epoch [89/100], Step [1200/1250], Loss: 0.001003, Train Accuracy: 0.998750\n",
      "Epoch 89/100, Loss: 0.004244, Train Accuracy: 0.998725, Validation Accuracy: 0.784000\n",
      "Epoch [90/100], Step [100/1250], Loss: 0.000225, Train Accuracy: 0.999687\n",
      "Epoch [90/100], Step [200/1250], Loss: 0.000438, Train Accuracy: 0.998594\n",
      "Epoch [90/100], Step [300/1250], Loss: 0.000325, Train Accuracy: 0.998854\n",
      "Epoch [90/100], Step [400/1250], Loss: 0.005322, Train Accuracy: 0.998672\n",
      "Epoch [90/100], Step [500/1250], Loss: 0.000253, Train Accuracy: 0.998875\n",
      "Epoch [90/100], Step [600/1250], Loss: 0.000340, Train Accuracy: 0.998958\n",
      "Epoch [90/100], Step [700/1250], Loss: 0.001247, Train Accuracy: 0.998929\n",
      "Epoch [90/100], Step [800/1250], Loss: 0.000243, Train Accuracy: 0.998984\n",
      "Epoch [90/100], Step [900/1250], Loss: 0.001468, Train Accuracy: 0.998958\n",
      "Epoch [90/100], Step [1000/1250], Loss: 0.000555, Train Accuracy: 0.998938\n",
      "Epoch [90/100], Step [1100/1250], Loss: 0.009492, Train Accuracy: 0.998807\n",
      "Epoch [90/100], Step [1200/1250], Loss: 0.000061, Train Accuracy: 0.998698\n",
      "Epoch 90/100, Loss: 0.004550, Train Accuracy: 0.998675, Validation Accuracy: 0.783300\n",
      "Epoch [91/100], Step [100/1250], Loss: 0.000503, Train Accuracy: 0.997812\n",
      "Epoch [91/100], Step [200/1250], Loss: 0.002628, Train Accuracy: 0.998125\n",
      "Epoch [91/100], Step [300/1250], Loss: 0.000332, Train Accuracy: 0.998021\n",
      "Epoch [91/100], Step [400/1250], Loss: 0.000840, Train Accuracy: 0.998203\n",
      "Epoch [91/100], Step [500/1250], Loss: 0.000231, Train Accuracy: 0.998062\n",
      "Epoch [91/100], Step [600/1250], Loss: 0.000084, Train Accuracy: 0.998073\n",
      "Epoch [91/100], Step [700/1250], Loss: 0.000106, Train Accuracy: 0.998125\n",
      "Epoch [91/100], Step [800/1250], Loss: 0.000285, Train Accuracy: 0.998086\n",
      "Epoch [91/100], Step [900/1250], Loss: 0.000286, Train Accuracy: 0.998056\n",
      "Epoch [91/100], Step [1000/1250], Loss: 0.033254, Train Accuracy: 0.998156\n",
      "Epoch [91/100], Step [1100/1250], Loss: 0.000175, Train Accuracy: 0.998125\n",
      "Epoch [91/100], Step [1200/1250], Loss: 0.019350, Train Accuracy: 0.998151\n",
      "Epoch 91/100, Loss: 0.006135, Train Accuracy: 0.998175, Validation Accuracy: 0.784800\n",
      "Epoch [92/100], Step [100/1250], Loss: 0.002250, Train Accuracy: 0.999062\n",
      "Epoch [92/100], Step [200/1250], Loss: 0.000224, Train Accuracy: 0.999219\n",
      "Epoch [92/100], Step [300/1250], Loss: 0.001460, Train Accuracy: 0.999375\n",
      "Epoch [92/100], Step [400/1250], Loss: 0.000092, Train Accuracy: 0.999141\n",
      "Epoch [92/100], Step [500/1250], Loss: 0.000083, Train Accuracy: 0.999188\n",
      "Epoch [92/100], Step [600/1250], Loss: 0.000205, Train Accuracy: 0.999167\n",
      "Epoch [92/100], Step [700/1250], Loss: 0.013703, Train Accuracy: 0.998884\n",
      "Epoch [92/100], Step [800/1250], Loss: 0.000544, Train Accuracy: 0.998867\n",
      "Epoch [92/100], Step [900/1250], Loss: 0.025618, Train Accuracy: 0.998854\n",
      "Epoch [92/100], Step [1000/1250], Loss: 0.000586, Train Accuracy: 0.998781\n",
      "Epoch [92/100], Step [1100/1250], Loss: 0.000142, Train Accuracy: 0.998750\n",
      "Epoch [92/100], Step [1200/1250], Loss: 0.007866, Train Accuracy: 0.998802\n",
      "Epoch 92/100, Loss: 0.004237, Train Accuracy: 0.998800, Validation Accuracy: 0.785900\n",
      "Epoch [93/100], Step [100/1250], Loss: 0.001277, Train Accuracy: 0.999375\n",
      "Epoch [93/100], Step [200/1250], Loss: 0.002158, Train Accuracy: 0.998750\n",
      "Epoch [93/100], Step [300/1250], Loss: 0.000341, Train Accuracy: 0.998437\n",
      "Epoch [93/100], Step [400/1250], Loss: 0.000296, Train Accuracy: 0.998594\n",
      "Epoch [93/100], Step [500/1250], Loss: 0.000274, Train Accuracy: 0.998563\n",
      "Epoch [93/100], Step [600/1250], Loss: 0.000112, Train Accuracy: 0.998385\n",
      "Epoch [93/100], Step [700/1250], Loss: 0.000167, Train Accuracy: 0.998393\n",
      "Epoch [93/100], Step [800/1250], Loss: 0.000364, Train Accuracy: 0.998437\n",
      "Epoch [93/100], Step [900/1250], Loss: 0.000237, Train Accuracy: 0.998472\n",
      "Epoch [93/100], Step [1000/1250], Loss: 0.000227, Train Accuracy: 0.998406\n",
      "Epoch [93/100], Step [1100/1250], Loss: 0.000206, Train Accuracy: 0.998466\n",
      "Epoch [93/100], Step [1200/1250], Loss: 0.017535, Train Accuracy: 0.998490\n",
      "Epoch 93/100, Loss: 0.005074, Train Accuracy: 0.998475, Validation Accuracy: 0.788100\n",
      "Epoch [94/100], Step [100/1250], Loss: 0.000281, Train Accuracy: 0.997812\n",
      "Epoch [94/100], Step [200/1250], Loss: 0.007426, Train Accuracy: 0.998437\n",
      "Epoch [94/100], Step [300/1250], Loss: 0.042890, Train Accuracy: 0.998125\n",
      "Epoch [94/100], Step [400/1250], Loss: 0.005185, Train Accuracy: 0.998281\n",
      "Epoch [94/100], Step [500/1250], Loss: 0.000101, Train Accuracy: 0.998313\n",
      "Epoch [94/100], Step [600/1250], Loss: 0.004783, Train Accuracy: 0.998437\n",
      "Epoch [94/100], Step [700/1250], Loss: 0.000455, Train Accuracy: 0.998616\n",
      "Epoch [94/100], Step [800/1250], Loss: 0.000446, Train Accuracy: 0.998750\n",
      "Epoch [94/100], Step [900/1250], Loss: 0.000117, Train Accuracy: 0.998819\n",
      "Epoch [94/100], Step [1000/1250], Loss: 0.000248, Train Accuracy: 0.998719\n",
      "Epoch [94/100], Step [1100/1250], Loss: 0.000304, Train Accuracy: 0.998722\n",
      "Epoch [94/100], Step [1200/1250], Loss: 0.000593, Train Accuracy: 0.998698\n",
      "Epoch 94/100, Loss: 0.004449, Train Accuracy: 0.998625, Validation Accuracy: 0.783400\n",
      "Epoch [95/100], Step [100/1250], Loss: 0.003848, Train Accuracy: 0.998750\n",
      "Epoch [95/100], Step [200/1250], Loss: 0.001387, Train Accuracy: 0.999062\n",
      "Epoch [95/100], Step [300/1250], Loss: 0.000142, Train Accuracy: 0.998542\n",
      "Epoch [95/100], Step [400/1250], Loss: 0.000405, Train Accuracy: 0.998828\n",
      "Epoch [95/100], Step [500/1250], Loss: 0.000565, Train Accuracy: 0.998812\n",
      "Epoch [95/100], Step [600/1250], Loss: 0.000325, Train Accuracy: 0.998906\n",
      "Epoch [95/100], Step [700/1250], Loss: 0.000297, Train Accuracy: 0.998929\n",
      "Epoch [95/100], Step [800/1250], Loss: 0.000672, Train Accuracy: 0.998828\n",
      "Epoch [95/100], Step [900/1250], Loss: 0.001142, Train Accuracy: 0.998750\n",
      "Epoch [95/100], Step [1000/1250], Loss: 0.000137, Train Accuracy: 0.998844\n",
      "Epoch [95/100], Step [1100/1250], Loss: 0.000711, Train Accuracy: 0.998920\n",
      "Epoch [95/100], Step [1200/1250], Loss: 0.000194, Train Accuracy: 0.999010\n",
      "Epoch 95/100, Loss: 0.003859, Train Accuracy: 0.998975, Validation Accuracy: 0.788100\n",
      "Epoch [96/100], Step [100/1250], Loss: 0.000097, Train Accuracy: 0.997188\n",
      "Epoch [96/100], Step [200/1250], Loss: 0.001248, Train Accuracy: 0.997656\n",
      "Epoch [96/100], Step [300/1250], Loss: 0.007627, Train Accuracy: 0.998229\n",
      "Epoch [96/100], Step [400/1250], Loss: 0.004091, Train Accuracy: 0.998437\n",
      "Epoch [96/100], Step [500/1250], Loss: 0.002553, Train Accuracy: 0.998687\n",
      "Epoch [96/100], Step [600/1250], Loss: 0.000167, Train Accuracy: 0.998802\n",
      "Epoch [96/100], Step [700/1250], Loss: 0.000301, Train Accuracy: 0.998973\n",
      "Epoch [96/100], Step [800/1250], Loss: 0.006962, Train Accuracy: 0.998828\n",
      "Epoch [96/100], Step [900/1250], Loss: 0.000184, Train Accuracy: 0.998715\n",
      "Epoch [96/100], Step [1000/1250], Loss: 0.005991, Train Accuracy: 0.998594\n",
      "Epoch [96/100], Step [1100/1250], Loss: 0.000883, Train Accuracy: 0.998636\n",
      "Epoch [96/100], Step [1200/1250], Loss: 0.003316, Train Accuracy: 0.998542\n",
      "Epoch 96/100, Loss: 0.005218, Train Accuracy: 0.998450, Validation Accuracy: 0.782400\n",
      "Epoch [97/100], Step [100/1250], Loss: 0.000960, Train Accuracy: 0.998125\n",
      "Epoch [97/100], Step [200/1250], Loss: 0.000413, Train Accuracy: 0.997656\n",
      "Epoch [97/100], Step [300/1250], Loss: 0.002424, Train Accuracy: 0.998021\n",
      "Epoch [97/100], Step [400/1250], Loss: 0.000470, Train Accuracy: 0.998359\n",
      "Epoch [97/100], Step [500/1250], Loss: 0.001351, Train Accuracy: 0.998500\n",
      "Epoch [97/100], Step [600/1250], Loss: 0.000236, Train Accuracy: 0.998281\n",
      "Epoch [97/100], Step [700/1250], Loss: 0.000957, Train Accuracy: 0.998304\n",
      "Epoch [97/100], Step [800/1250], Loss: 0.000408, Train Accuracy: 0.998125\n",
      "Epoch [97/100], Step [900/1250], Loss: 0.000186, Train Accuracy: 0.998125\n",
      "Epoch [97/100], Step [1000/1250], Loss: 0.007624, Train Accuracy: 0.998094\n",
      "Epoch [97/100], Step [1100/1250], Loss: 0.000316, Train Accuracy: 0.998182\n",
      "Epoch [97/100], Step [1200/1250], Loss: 0.000323, Train Accuracy: 0.998203\n",
      "Epoch 97/100, Loss: 0.005184, Train Accuracy: 0.998250, Validation Accuracy: 0.785000\n",
      "Epoch [98/100], Step [100/1250], Loss: 0.000213, Train Accuracy: 0.999375\n",
      "Epoch [98/100], Step [200/1250], Loss: 0.000174, Train Accuracy: 0.999219\n",
      "Epoch [98/100], Step [300/1250], Loss: 0.000353, Train Accuracy: 0.999479\n",
      "Epoch [98/100], Step [400/1250], Loss: 0.000922, Train Accuracy: 0.999297\n",
      "Epoch [98/100], Step [500/1250], Loss: 0.000408, Train Accuracy: 0.999375\n",
      "Epoch [98/100], Step [600/1250], Loss: 0.000885, Train Accuracy: 0.999479\n",
      "Epoch [98/100], Step [700/1250], Loss: 0.000076, Train Accuracy: 0.999554\n",
      "Epoch [98/100], Step [800/1250], Loss: 0.004126, Train Accuracy: 0.999609\n",
      "Epoch [98/100], Step [900/1250], Loss: 0.001531, Train Accuracy: 0.999549\n",
      "Epoch [98/100], Step [1000/1250], Loss: 0.000289, Train Accuracy: 0.999531\n",
      "Epoch [98/100], Step [1100/1250], Loss: 0.000132, Train Accuracy: 0.999489\n",
      "Epoch [98/100], Step [1200/1250], Loss: 0.000216, Train Accuracy: 0.999505\n",
      "Epoch 98/100, Loss: 0.002269, Train Accuracy: 0.999525, Validation Accuracy: 0.785900\n",
      "Epoch [99/100], Step [100/1250], Loss: 0.000210, Train Accuracy: 0.999687\n",
      "Epoch [99/100], Step [200/1250], Loss: 0.000150, Train Accuracy: 0.999844\n",
      "Epoch [99/100], Step [300/1250], Loss: 0.000210, Train Accuracy: 0.999792\n",
      "Epoch [99/100], Step [400/1250], Loss: 0.000141, Train Accuracy: 0.999766\n",
      "Epoch [99/100], Step [500/1250], Loss: 0.001437, Train Accuracy: 0.999625\n",
      "Epoch [99/100], Step [600/1250], Loss: 0.000209, Train Accuracy: 0.999531\n",
      "Epoch [99/100], Step [700/1250], Loss: 0.008540, Train Accuracy: 0.999330\n",
      "Epoch [99/100], Step [800/1250], Loss: 0.093467, Train Accuracy: 0.999258\n",
      "Epoch [99/100], Step [900/1250], Loss: 0.122719, Train Accuracy: 0.998993\n",
      "Epoch [99/100], Step [1000/1250], Loss: 0.042989, Train Accuracy: 0.998844\n",
      "Epoch [99/100], Step [1100/1250], Loss: 0.009497, Train Accuracy: 0.998608\n",
      "Epoch [99/100], Step [1200/1250], Loss: 0.000911, Train Accuracy: 0.998464\n",
      "Epoch 99/100, Loss: 0.005256, Train Accuracy: 0.998425, Validation Accuracy: 0.778400\n",
      "Epoch [100/100], Step [100/1250], Loss: 0.000273, Train Accuracy: 0.997812\n",
      "Epoch [100/100], Step [200/1250], Loss: 0.000977, Train Accuracy: 0.998750\n",
      "Epoch [100/100], Step [300/1250], Loss: 0.000417, Train Accuracy: 0.998958\n",
      "Epoch [100/100], Step [400/1250], Loss: 0.001460, Train Accuracy: 0.999062\n",
      "Epoch [100/100], Step [500/1250], Loss: 0.000330, Train Accuracy: 0.999062\n",
      "Epoch [100/100], Step [600/1250], Loss: 0.000428, Train Accuracy: 0.999062\n",
      "Epoch [100/100], Step [700/1250], Loss: 0.000789, Train Accuracy: 0.999196\n",
      "Epoch [100/100], Step [800/1250], Loss: 0.001413, Train Accuracy: 0.999219\n",
      "Epoch [100/100], Step [900/1250], Loss: 0.005324, Train Accuracy: 0.999236\n",
      "Epoch [100/100], Step [1000/1250], Loss: 0.000105, Train Accuracy: 0.999313\n",
      "Epoch [100/100], Step [1100/1250], Loss: 0.002080, Train Accuracy: 0.999290\n",
      "Epoch [100/100], Step [1200/1250], Loss: 0.000959, Train Accuracy: 0.999245\n",
      "Epoch 100/100, Loss: 0.003225, Train Accuracy: 0.999150, Validation Accuracy: 0.784400\n"
     ]
    }
   ],
   "source": [
    "list_optimizer = [ \"ADOPT\",\"Adam\"]\n",
    "num_epochs = 100\n",
    "result = {}\n",
    "num_classes = 10\n",
    "for optimizer_type in list_optimizer:\n",
    "    resnet18 = models.resnet18(pretrained=True)\n",
    "    in_features = resnet18.fc.in_features\n",
    "    resnet18.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "    # print(resnet18)\n",
    "    # resnet18.fc = nn.Linear(in_features, num_classes)\n",
    "    model = ResNet18(resnet18, num_classes=10)\n",
    "    history = model.fit(num_epochs=num_epochs, optimizer_type = optimizer_type, train_loader=train_loader, val_loader=val_loader, base_lr= 0.01, verbose=True)\n",
    "    result[optimizer_type] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "id": "zqfGQZqZYiUL",
    "outputId": "c4d4fbd6-8c5f-4da9-987f-523a79c3ea9b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hàm vẽ biểu đồ so sánh\n",
    "def plot_training_validation_accuracy(result, num_epochs):\n",
    "    \"\"\"\n",
    "    Hàm vẽ biểu đồ so sánh độ chính xác huấn luyện và kiểm tra giữa các optimizer.\n",
    "\n",
    "    Args:\n",
    "        result (dict): Lịch sử huấn luyện của các optimizer, chứa các khóa là tên optimizer và giá trị là `history`.\n",
    "        num_epochs (int): Số lượng epoch huấn luyện.\n",
    "    \"\"\"\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for optimizer_type in list_optimizer:\n",
    "        # Vẽ độ chính xác huấn luyện\n",
    "        plt.plot(epochs, result[optimizer_type]['val_accuracy'], label=f'{optimizer_type} - Val Accuracy', linewidth=2)\n",
    "\n",
    "    plt.ylim(0.5, 0.9)\n",
    "    # Thiết lập biểu đồ\n",
    "    plt.title('Optimizer Comparison', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14, fontweight = \"bold\")\n",
    "    plt.ylabel('Accuracy', fontsize=14, fontweight = \"bold\")\n",
    "    plt.legend(fontsize=16, loc='lower right', )\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Vẽ biểu đồ từ kết quả\n",
    "plot_training_validation_accuracy(result, num_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
